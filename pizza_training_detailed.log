2025-05-05 01:12:27,131 - INFO - Verwende Gerät: cuda
2025-05-05 01:12:27,131 - INFO - Analysiere Datensatz in data/augmented...
2025-05-05 01:12:27,186 - INFO - Datensatzanalyse abgeschlossen:
2025-05-05 01:12:27,186 - INFO - Gesamtzahl der Bilder: 57
2025-05-05 01:12:27,186 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-05 01:12:27,186 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-05 01:12:27,186 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-05 01:12:27,186 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-05 01:12:27,187 - INFO - Normalisierungsparameter aus Datensatz: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-05 01:12:27,188 - INFO - Klassenverteilung im Dataset:
2025-05-05 01:12:27,188 - INFO -   basic: 105 Bilder
2025-05-05 01:12:27,188 - INFO -   burnt: 70 Bilder
2025-05-05 01:12:27,188 - INFO -   combined: 17 Bilder
2025-05-05 01:12:27,188 - INFO -   mixed: 7 Bilder
2025-05-05 01:12:27,188 - INFO - Klassengewichte für balanciertes Training:
2025-05-05 01:12:27,188 - INFO -   basic: 0.32
2025-05-05 01:12:27,188 - INFO -   burnt: 0.47
2025-05-05 01:12:27,189 - INFO -   combined: 1.95
2025-05-05 01:12:27,189 - INFO -   mixed: 4.74
2025-05-05 01:12:27,189 - INFO -   progression: 1.00
2025-05-05 01:12:27,189 - INFO -   segment: 1.00
2025-05-05 01:12:27,189 - INFO - Datensatz geladen: 159 Trainingsbilder, 40 Validierungsbilder
2025-05-05 01:12:27,189 - INFO - Erstelle MicroPizzaNet für 6 Klassen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-05 01:12:27,300 - INFO - Starte Training...
2025-05-05 01:12:27,854 - INFO - Epoch 1/30: Train Loss: 1.7525, Train Acc: 27.67% - Val Loss: 1.7698, Val Acc: 47.50%
2025-05-05 01:12:27,854 - INFO - Neues bestes Modell in Epoch 1 mit Validation Accuracy: 47.50%
2025-05-05 01:12:27,981 - INFO - Epoch 2/30: Train Loss: 1.6976, Train Acc: 28.30% - Val Loss: 1.7330, Val Acc: 10.00%
2025-05-05 01:12:28,110 - INFO - Epoch 3/30: Train Loss: 1.6368, Train Acc: 25.16% - Val Loss: 1.6744, Val Acc: 0.00%
2025-05-05 01:12:28,233 - INFO - Epoch 4/30: Train Loss: 1.5800, Train Acc: 27.04% - Val Loss: 1.6261, Val Acc: 0.00%
2025-05-05 01:12:28,367 - INFO - Epoch 5/30: Train Loss: 1.5268, Train Acc: 30.82% - Val Loss: 1.6041, Val Acc: 0.00%
2025-05-05 01:12:28,490 - INFO - Epoch 6/30: Train Loss: 1.5023, Train Acc: 30.82% - Val Loss: 1.5737, Val Acc: 0.00%
2025-05-05 01:12:28,622 - INFO - Epoch 7/30: Train Loss: 1.4757, Train Acc: 28.93% - Val Loss: 1.5378, Val Acc: 5.00%
2025-05-05 01:12:28,747 - INFO - Epoch 8/30: Train Loss: 1.4116, Train Acc: 34.59% - Val Loss: 1.5122, Val Acc: 10.00%
2025-05-05 01:12:28,876 - INFO - Epoch 9/30: Train Loss: 1.4156, Train Acc: 31.45% - Val Loss: 1.4939, Val Acc: 22.50%
2025-05-05 01:12:28,999 - INFO - Epoch 10/30: Train Loss: 1.4263, Train Acc: 29.56% - Val Loss: 1.4662, Val Acc: 22.50%
2025-05-05 01:12:29,127 - INFO - Epoch 11/30: Train Loss: 1.3572, Train Acc: 39.62% - Val Loss: 1.4616, Val Acc: 12.50%
2025-05-05 01:12:29,127 - INFO - Early Stopping in Epoch 11
2025-05-05 01:12:29,127 - INFO - Beste Modellgewichte aus Epoch 1 geladen
2025-05-05 01:12:29,128 - INFO - Modell gespeichert unter output/models/pizza_model_new.pth
2025-05-05 01:12:29,274 - INFO - Trainingshistorie gespeichert unter output/models/training_history.png
2025-05-05 01:12:29,274 - INFO - 
==================================================
2025-05-05 01:12:29,274 - INFO - TRAINING ABGESCHLOSSEN
2025-05-05 01:12:29,274 - INFO - ==================================================
2025-05-05 01:12:29,274 - INFO - Beste Validation Accuracy: 47.50% in Epoch 1
2025-05-05 01:12:29,274 - INFO - Modell gespeichert unter: output/models/pizza_model_new.pth
2025-05-05 01:12:29,274 - INFO - Trainingsvisualisierung: output/models/training_history.png
2025-05-05 12:35:25,280 - INFO - Starte Hyperparameter-Suche für Pizza Erkennung
2025-05-05 12:35:25,285 - INFO - ================================================================================
2025-05-05 12:35:25,285 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-05 12:35:25,285 - INFO - ================================================================================
2025-05-05 12:35:25,285 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-05 12:35:25,285 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-05 12:35:25,285 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-05 12:35:25,286 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-05 12:35:25,286 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-05 12:35:25,286 - INFO - ================================================================================
2025-05-05 12:35:25,286 - INFO - Lade Datensatz aus data/augmented
2025-05-05 12:35:25,287 - INFO - Analysiere Datensatz in data/augmented...
2025-05-05 12:35:25,515 - INFO - Datensatzanalyse abgeschlossen:
2025-05-05 12:35:25,515 - INFO - Gesamtzahl der Bilder: 57
2025-05-05 12:35:25,516 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-05 12:35:25,516 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-05 12:35:25,516 - INFO - RGB-Mittelwerte: [0.4867, 0.4019, 0.3332]
2025-05-05 12:35:25,516 - INFO - RGB-Standardabweichungen: [0.2342, 0.2538, 0.2688]
2025-05-05 12:35:25,517 - INFO - Preparing optimized data loaders...
2025-05-05 12:35:25,518 - INFO - Using dataset-specific normalization: mean=[0.4867387  0.40187253 0.33316298], std=[0.23419387 0.25375593 0.2688303 ]
2025-05-05 12:35:25,523 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-05 12:35:25,523 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-05 12:35:25,523 - INFO - Generiert: 12 Modellkonfigurationen für die Suche
2025-05-05 12:35:25,524 - INFO - 
==================================================
Trainiere Modell 1/12: micro_d0.75_b2_ch8_sep_gpool
==================================================
2025-05-05 12:35:25,585 - INFO - Speicheranalyse:
2025-05-05 12:35:25,585 - INFO -   Modellgröße (Float32): 1.82 KB
2025-05-05 12:35:25,585 - INFO -   Modellgröße (Int8): 0.45 KB (0.0% des Flash)
2025-05-05 12:35:25,585 - INFO -   Aktivierungsspeicher: 76.05 KB
2025-05-05 12:35:25,585 - INFO -   Gesamter Laufzeitspeicher: 76.51 KB (29.0% des RAM)
2025-05-05 12:35:25,586 - INFO - Modell hat 414 Parameter
2025-05-05 12:35:25,586 - INFO - Geschätzte Modellgröße: 1.82 KB (float32), 0.45 KB (int8)
2025-05-05 12:35:27,640 - INFO - Epoch 1/25 - Train Loss: 1.7891, Train Acc: 20.00% - Val Loss: 1.7957, Val Acc: 8.33%
2025-05-05 12:35:28,259 - INFO - Epoch 2/25 - Train Loss: 1.7860, Train Acc: 31.11% - Val Loss: 1.7986, Val Acc: 8.33%
2025-05-05 12:35:28,862 - INFO - Epoch 3/25 - Train Loss: 1.7832, Train Acc: 31.11% - Val Loss: 1.7997, Val Acc: 8.33%
2025-05-05 12:35:29,399 - INFO - Epoch 4/25 - Train Loss: 1.7894, Train Acc: 24.44% - Val Loss: 1.7978, Val Acc: 8.33%
2025-05-05 12:35:29,999 - INFO - Epoch 5/25 - Train Loss: 1.7687, Train Acc: 31.11% - Val Loss: 1.7937, Val Acc: 8.33%
2025-05-05 12:35:30,643 - INFO - Epoch 6/25 - Train Loss: 1.7618, Train Acc: 22.22% - Val Loss: 1.7886, Val Acc: 8.33%
2025-05-05 12:35:31,267 - INFO - Epoch 7/25 - Train Loss: 1.7452, Train Acc: 26.67% - Val Loss: 1.7810, Val Acc: 8.33%
2025-05-05 12:35:31,802 - INFO - Epoch 8/25 - Train Loss: 1.7321, Train Acc: 24.44% - Val Loss: 1.7709, Val Acc: 8.33%
2025-05-05 12:35:32,451 - INFO - Epoch 9/25 - Train Loss: 1.7110, Train Acc: 24.44% - Val Loss: 1.7594, Val Acc: 8.33%
2025-05-05 12:35:33,099 - INFO - Epoch 10/25 - Train Loss: 1.6943, Train Acc: 28.89% - Val Loss: 1.7515, Val Acc: 8.33%
2025-05-05 12:35:33,610 - INFO - Epoch 11/25 - Train Loss: 1.6767, Train Acc: 20.00% - Val Loss: 1.7414, Val Acc: 8.33%
2025-05-05 12:35:34,176 - INFO - Epoch 12/25 - Train Loss: 1.6694, Train Acc: 17.78% - Val Loss: 1.7297, Val Acc: 8.33%
2025-05-05 12:35:34,825 - INFO - Epoch 13/25 - Train Loss: 1.6457, Train Acc: 28.89% - Val Loss: 1.7179, Val Acc: 8.33%
2025-05-05 12:35:35,372 - INFO - Epoch 14/25 - Train Loss: 1.6372, Train Acc: 13.33% - Val Loss: 1.7060, Val Acc: 8.33%
2025-05-05 12:35:35,971 - INFO - Epoch 15/25 - Train Loss: 1.6195, Train Acc: 28.89% - Val Loss: 1.6957, Val Acc: 0.00%
2025-05-05 12:35:36,626 - INFO - Epoch 16/25 - Train Loss: 1.6100, Train Acc: 35.56% - Val Loss: 1.6857, Val Acc: 0.00%
2025-05-05 12:35:37,267 - INFO - Epoch 17/25 - Train Loss: 1.6052, Train Acc: 26.67% - Val Loss: 1.6770, Val Acc: 0.00%
2025-05-05 12:35:37,873 - INFO - Epoch 18/25 - Train Loss: 1.5984, Train Acc: 28.89% - Val Loss: 1.6696, Val Acc: 0.00%
2025-05-05 12:35:38,525 - INFO - Epoch 19/25 - Train Loss: 1.5880, Train Acc: 33.33% - Val Loss: 1.6638, Val Acc: 0.00%
2025-05-05 12:35:39,074 - INFO - Epoch 20/25 - Train Loss: 1.5780, Train Acc: 40.00% - Val Loss: 1.6591, Val Acc: 0.00%
2025-05-05 12:35:39,702 - INFO - Epoch 21/25 - Train Loss: 1.5709, Train Acc: 42.22% - Val Loss: 1.6558, Val Acc: 0.00%
2025-05-05 12:35:40,322 - INFO - Epoch 22/25 - Train Loss: 1.5745, Train Acc: 31.11% - Val Loss: 1.6529, Val Acc: 0.00%
2025-05-05 12:35:40,933 - INFO - Epoch 23/25 - Train Loss: 1.5812, Train Acc: 26.67% - Val Loss: 1.6498, Val Acc: 0.00%
2025-05-05 12:35:41,475 - INFO - Epoch 24/25 - Train Loss: 1.5805, Train Acc: 33.33% - Val Loss: 1.6481, Val Acc: 0.00%
2025-05-05 12:35:42,103 - INFO - Epoch 25/25 - Train Loss: 1.5676, Train Acc: 37.78% - Val Loss: 1.6462, Val Acc: 0.00%
2025-05-05 12:35:42,108 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:35:42,443 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d0.75_b2_ch8_sep_gpool.pth
2025-05-05 12:35:44,363 - INFO - 
==================================================
Trainiere Modell 2/12: micro_d0.75_b2_ch16_sep_gpool
==================================================
2025-05-05 12:35:44,377 - INFO - Speicheranalyse:
2025-05-05 12:35:44,378 - INFO -   Modellgröße (Float32): 4.16 KB
2025-05-05 12:35:44,378 - INFO -   Modellgröße (Int8): 1.04 KB (0.1% des Flash)
2025-05-05 12:35:44,378 - INFO -   Aktivierungsspeicher: 152.09 KB
2025-05-05 12:35:44,378 - INFO -   Gesamter Laufzeitspeicher: 153.13 KB (58.0% des RAM)
2025-05-05 12:35:44,378 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (153.13KB > 100KB)
2025-05-05 12:35:44,379 - INFO - Modell hat 966 Parameter
2025-05-05 12:35:44,379 - INFO - Geschätzte Modellgröße: 4.16 KB (float32), 1.04 KB (int8)
2025-05-05 12:35:45,110 - INFO - Epoch 1/25 - Train Loss: 1.7952, Train Acc: 22.22% - Val Loss: 1.7941, Val Acc: 8.33%
2025-05-05 12:35:45,770 - INFO - Epoch 2/25 - Train Loss: 1.7970, Train Acc: 17.78% - Val Loss: 1.7899, Val Acc: 25.00%
2025-05-05 12:35:46,432 - INFO - Epoch 3/25 - Train Loss: 1.7928, Train Acc: 33.33% - Val Loss: 1.7850, Val Acc: 50.00%
2025-05-05 12:35:47,061 - INFO - Epoch 4/25 - Train Loss: 1.7828, Train Acc: 17.78% - Val Loss: 1.7781, Val Acc: 58.33%
2025-05-05 12:35:47,690 - INFO - Epoch 5/25 - Train Loss: 1.7666, Train Acc: 24.44% - Val Loss: 1.7700, Val Acc: 50.00%
2025-05-05 12:35:48,158 - INFO - Epoch 6/25 - Train Loss: 1.7482, Train Acc: 22.22% - Val Loss: 1.7623, Val Acc: 16.67%
2025-05-05 12:35:48,793 - INFO - Epoch 7/25 - Train Loss: 1.7230, Train Acc: 26.67% - Val Loss: 1.7543, Val Acc: 0.00%
2025-05-05 12:35:49,424 - INFO - Epoch 8/25 - Train Loss: 1.6797, Train Acc: 35.56% - Val Loss: 1.7451, Val Acc: 0.00%
2025-05-05 12:35:50,064 - INFO - Epoch 9/25 - Train Loss: 1.6376, Train Acc: 40.00% - Val Loss: 1.7379, Val Acc: 0.00%
2025-05-05 12:35:50,742 - INFO - Epoch 10/25 - Train Loss: 1.6326, Train Acc: 26.67% - Val Loss: 1.7312, Val Acc: 0.00%
2025-05-05 12:35:51,407 - INFO - Epoch 11/25 - Train Loss: 1.5949, Train Acc: 26.67% - Val Loss: 1.7257, Val Acc: 0.00%
2025-05-05 12:35:52,058 - INFO - Epoch 12/25 - Train Loss: 1.6218, Train Acc: 26.67% - Val Loss: 1.7125, Val Acc: 0.00%
2025-05-05 12:35:52,591 - INFO - Epoch 13/25 - Train Loss: 1.5621, Train Acc: 28.89% - Val Loss: 1.6986, Val Acc: 0.00%
2025-05-05 12:35:53,247 - INFO - Epoch 14/25 - Train Loss: 1.5340, Train Acc: 28.89% - Val Loss: 1.6895, Val Acc: 0.00%
2025-05-05 12:35:53,909 - INFO - Epoch 15/25 - Train Loss: 1.5134, Train Acc: 33.33% - Val Loss: 1.6812, Val Acc: 16.67%
2025-05-05 12:35:54,544 - INFO - Epoch 16/25 - Train Loss: 1.5076, Train Acc: 20.00% - Val Loss: 1.6775, Val Acc: 25.00%
2025-05-05 12:35:55,175 - INFO - Epoch 17/25 - Train Loss: 1.4947, Train Acc: 40.00% - Val Loss: 1.6748, Val Acc: 25.00%
2025-05-05 12:35:55,767 - INFO - Epoch 18/25 - Train Loss: 1.5068, Train Acc: 35.56% - Val Loss: 1.6716, Val Acc: 25.00%
2025-05-05 12:35:56,350 - INFO - Epoch 19/25 - Train Loss: 1.5134, Train Acc: 28.89% - Val Loss: 1.6703, Val Acc: 25.00%
2025-05-05 12:35:56,945 - INFO - Epoch 20/25 - Train Loss: 1.5302, Train Acc: 22.22% - Val Loss: 1.6670, Val Acc: 25.00%
2025-05-05 12:35:57,421 - INFO - Epoch 21/25 - Train Loss: 1.5240, Train Acc: 26.67% - Val Loss: 1.6656, Val Acc: 25.00%
2025-05-05 12:35:58,038 - INFO - Epoch 22/25 - Train Loss: 1.4665, Train Acc: 26.67% - Val Loss: 1.6634, Val Acc: 25.00%
2025-05-05 12:35:58,695 - INFO - Epoch 23/25 - Train Loss: 1.4378, Train Acc: 40.00% - Val Loss: 1.6627, Val Acc: 25.00%
2025-05-05 12:35:59,361 - INFO - Epoch 24/25 - Train Loss: 1.4830, Train Acc: 28.89% - Val Loss: 1.6625, Val Acc: 25.00%
2025-05-05 12:35:59,949 - INFO - Epoch 25/25 - Train Loss: 1.4762, Train Acc: 31.11% - Val Loss: 1.6622, Val Acc: 25.00%
2025-05-05 12:35:59,954 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:36:00,340 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d0.75_b2_ch16_sep_gpool.pth
2025-05-05 12:36:01,563 - INFO - 
==================================================
Trainiere Modell 3/12: micro_d0.75_b3_ch8_sep_gpool
==================================================
2025-05-05 12:36:01,575 - INFO - Speicheranalyse:
2025-05-05 12:36:01,575 - INFO -   Modellgröße (Float32): 4.21 KB
2025-05-05 12:36:01,575 - INFO -   Modellgröße (Int8): 1.05 KB (0.1% des Flash)
2025-05-05 12:36:01,575 - INFO -   Aktivierungsspeicher: 92.18 KB
2025-05-05 12:36:01,575 - INFO -   Gesamter Laufzeitspeicher: 93.23 KB (35.3% des RAM)
2025-05-05 12:36:01,576 - INFO - Modell hat 954 Parameter
2025-05-05 12:36:01,576 - INFO - Geschätzte Modellgröße: 4.21 KB (float32), 1.05 KB (int8)
2025-05-05 12:36:02,238 - INFO - Epoch 1/25 - Train Loss: 1.7903, Train Acc: 26.67% - Val Loss: 1.7914, Val Acc: 0.00%
2025-05-05 12:36:02,897 - INFO - Epoch 2/25 - Train Loss: 1.7949, Train Acc: 11.11% - Val Loss: 1.7901, Val Acc: 8.33%
2025-05-05 12:36:03,466 - INFO - Epoch 3/25 - Train Loss: 1.7843, Train Acc: 22.22% - Val Loss: 1.7875, Val Acc: 25.00%
2025-05-05 12:36:04,138 - INFO - Epoch 4/25 - Train Loss: 1.7660, Train Acc: 33.33% - Val Loss: 1.7827, Val Acc: 58.33%
2025-05-05 12:36:04,775 - INFO - Epoch 5/25 - Train Loss: 1.7498, Train Acc: 35.56% - Val Loss: 1.7752, Val Acc: 66.67%
2025-05-05 12:36:05,416 - INFO - Epoch 6/25 - Train Loss: 1.7297, Train Acc: 24.44% - Val Loss: 1.7642, Val Acc: 16.67%
2025-05-05 12:36:06,043 - INFO - Epoch 7/25 - Train Loss: 1.7115, Train Acc: 24.44% - Val Loss: 1.7473, Val Acc: 33.33%
2025-05-05 12:36:06,657 - INFO - Epoch 8/25 - Train Loss: 1.6751, Train Acc: 22.22% - Val Loss: 1.7285, Val Acc: 16.67%
2025-05-05 12:36:07,301 - INFO - Epoch 9/25 - Train Loss: 1.6336, Train Acc: 42.22% - Val Loss: 1.7086, Val Acc: 8.33%
2025-05-05 12:36:07,941 - INFO - Epoch 10/25 - Train Loss: 1.5854, Train Acc: 55.56% - Val Loss: 1.6949, Val Acc: 8.33%
2025-05-05 12:36:08,591 - INFO - Epoch 11/25 - Train Loss: 1.5798, Train Acc: 46.67% - Val Loss: 1.6853, Val Acc: 8.33%
2025-05-05 12:36:09,095 - INFO - Epoch 12/25 - Train Loss: 1.5490, Train Acc: 37.78% - Val Loss: 1.6759, Val Acc: 8.33%
2025-05-05 12:36:09,653 - INFO - Epoch 13/25 - Train Loss: 1.5650, Train Acc: 24.44% - Val Loss: 1.6670, Val Acc: 8.33%
2025-05-05 12:36:10,285 - INFO - Epoch 14/25 - Train Loss: 1.5604, Train Acc: 26.67% - Val Loss: 1.6547, Val Acc: 0.00%
2025-05-05 12:36:10,956 - INFO - Epoch 15/25 - Train Loss: 1.4966, Train Acc: 33.33% - Val Loss: 1.6435, Val Acc: 0.00%
2025-05-05 12:36:11,534 - INFO - Epoch 16/25 - Train Loss: 1.4564, Train Acc: 51.11% - Val Loss: 1.6391, Val Acc: 0.00%
2025-05-05 12:36:12,221 - INFO - Epoch 17/25 - Train Loss: 1.4905, Train Acc: 28.89% - Val Loss: 1.6365, Val Acc: 0.00%
2025-05-05 12:36:12,861 - INFO - Epoch 18/25 - Train Loss: 1.4810, Train Acc: 31.11% - Val Loss: 1.6340, Val Acc: 0.00%
2025-05-05 12:36:13,536 - INFO - Epoch 19/25 - Train Loss: 1.5000, Train Acc: 22.22% - Val Loss: 1.6301, Val Acc: 0.00%
2025-05-05 12:36:14,116 - INFO - Epoch 20/25 - Train Loss: 1.4579, Train Acc: 42.22% - Val Loss: 1.6261, Val Acc: 0.00%
2025-05-05 12:36:14,745 - INFO - Epoch 21/25 - Train Loss: 1.4238, Train Acc: 46.67% - Val Loss: 1.6233, Val Acc: 0.00%
2025-05-05 12:36:15,360 - INFO - Epoch 22/25 - Train Loss: 1.4558, Train Acc: 28.89% - Val Loss: 1.6216, Val Acc: 0.00%
2025-05-05 12:36:15,887 - INFO - Epoch 23/25 - Train Loss: 1.4667, Train Acc: 28.89% - Val Loss: 1.6213, Val Acc: 0.00%
2025-05-05 12:36:16,269 - INFO - Epoch 24/25 - Train Loss: 1.4783, Train Acc: 33.33% - Val Loss: 1.6208, Val Acc: 0.00%
2025-05-05 12:36:16,925 - INFO - Epoch 25/25 - Train Loss: 1.4643, Train Acc: 26.67% - Val Loss: 1.6201, Val Acc: 0.00%
2025-05-05 12:36:16,935 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:36:17,330 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d0.75_b3_ch8_sep_gpool.pth
2025-05-05 12:36:18,229 - INFO - 
==================================================
Trainiere Modell 4/12: micro_d0.75_b3_ch16_sep_gpool
==================================================
2025-05-05 12:36:18,237 - INFO - Speicheranalyse:
2025-05-05 12:36:18,237 - INFO -   Modellgröße (Float32): 11.20 KB
2025-05-05 12:36:18,237 - INFO -   Modellgröße (Int8): 2.80 KB (0.1% des Flash)
2025-05-05 12:36:18,237 - INFO -   Aktivierungsspeicher: 184.34 KB
2025-05-05 12:36:18,237 - INFO -   Gesamter Laufzeitspeicher: 187.14 KB (70.9% des RAM)
2025-05-05 12:36:18,237 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (187.14KB > 100KB)
2025-05-05 12:36:18,238 - INFO - Modell hat 2,622 Parameter
2025-05-05 12:36:18,238 - INFO - Geschätzte Modellgröße: 11.20 KB (float32), 2.80 KB (int8)
2025-05-05 12:36:18,827 - INFO - Epoch 1/25 - Train Loss: 1.7915, Train Acc: 22.22% - Val Loss: 1.7925, Val Acc: 0.00%
2025-05-05 12:36:19,506 - INFO - Epoch 2/25 - Train Loss: 1.7971, Train Acc: 22.22% - Val Loss: 1.7932, Val Acc: 0.00%
2025-05-05 12:36:19,942 - INFO - Epoch 3/25 - Train Loss: 1.7779, Train Acc: 28.89% - Val Loss: 1.7931, Val Acc: 0.00%
2025-05-05 12:36:20,603 - INFO - Epoch 4/25 - Train Loss: 1.7703, Train Acc: 22.22% - Val Loss: 1.7916, Val Acc: 0.00%
2025-05-05 12:36:21,057 - INFO - Epoch 5/25 - Train Loss: 1.7280, Train Acc: 24.44% - Val Loss: 1.7865, Val Acc: 0.00%
2025-05-05 12:36:21,466 - INFO - Epoch 6/25 - Train Loss: 1.6837, Train Acc: 37.78% - Val Loss: 1.7776, Val Acc: 0.00%
2025-05-05 12:36:22,017 - INFO - Epoch 7/25 - Train Loss: 1.6392, Train Acc: 33.33% - Val Loss: 1.7626, Val Acc: 0.00%
2025-05-05 12:36:22,574 - INFO - Epoch 8/25 - Train Loss: 1.5564, Train Acc: 35.56% - Val Loss: 1.7480, Val Acc: 0.00%
2025-05-05 12:36:23,257 - INFO - Epoch 9/25 - Train Loss: 1.5651, Train Acc: 26.67% - Val Loss: 1.7309, Val Acc: 0.00%
2025-05-05 12:36:23,932 - INFO - Epoch 10/25 - Train Loss: 1.5171, Train Acc: 35.56% - Val Loss: 1.7072, Val Acc: 8.33%
2025-05-05 12:36:24,604 - INFO - Epoch 11/25 - Train Loss: 1.4685, Train Acc: 28.89% - Val Loss: 1.6834, Val Acc: 8.33%
2025-05-05 12:36:25,202 - INFO - Epoch 12/25 - Train Loss: 1.4104, Train Acc: 42.22% - Val Loss: 1.6667, Val Acc: 8.33%
2025-05-05 12:36:25,876 - INFO - Epoch 13/25 - Train Loss: 1.4376, Train Acc: 33.33% - Val Loss: 1.6533, Val Acc: 16.67%
2025-05-05 12:36:26,555 - INFO - Epoch 14/25 - Train Loss: 1.4410, Train Acc: 20.00% - Val Loss: 1.6491, Val Acc: 8.33%
2025-05-05 12:36:27,009 - INFO - Epoch 15/25 - Train Loss: 1.3951, Train Acc: 26.67% - Val Loss: 1.6491, Val Acc: 8.33%
2025-05-05 12:36:27,686 - INFO - Epoch 16/25 - Train Loss: 1.4427, Train Acc: 26.67% - Val Loss: 1.6462, Val Acc: 8.33%
2025-05-05 12:36:28,260 - INFO - Epoch 17/25 - Train Loss: 1.3202, Train Acc: 51.11% - Val Loss: 1.6481, Val Acc: 8.33%
2025-05-05 12:36:28,890 - INFO - Epoch 18/25 - Train Loss: 1.3440, Train Acc: 40.00% - Val Loss: 1.6514, Val Acc: 8.33%
2025-05-05 12:36:29,550 - INFO - Epoch 19/25 - Train Loss: 1.3283, Train Acc: 48.89% - Val Loss: 1.6551, Val Acc: 8.33%
2025-05-05 12:36:30,128 - INFO - Epoch 20/25 - Train Loss: 1.4477, Train Acc: 35.56% - Val Loss: 1.6585, Val Acc: 8.33%
2025-05-05 12:36:30,649 - INFO - Epoch 21/25 - Train Loss: 1.4091, Train Acc: 28.89% - Val Loss: 1.6617, Val Acc: 8.33%
2025-05-05 12:36:30,650 - INFO - Early Stopping in Epoche 21
2025-05-05 12:36:30,653 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:36:30,983 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d0.75_b3_ch16_sep_gpool.pth
2025-05-05 12:36:31,912 - INFO - 
==================================================
Trainiere Modell 5/12: micro_d1.0_b2_ch8_sep_gpool
==================================================
2025-05-05 12:36:31,918 - INFO - Speicheranalyse:
2025-05-05 12:36:31,918 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-05 12:36:31,918 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-05 12:36:31,918 - INFO -   Aktivierungsspeicher: 101.40 KB
2025-05-05 12:36:31,918 - INFO -   Gesamter Laufzeitspeicher: 102.03 KB (38.6% des RAM)
2025-05-05 12:36:31,919 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.03KB > 100KB)
2025-05-05 12:36:31,919 - INFO - Modell hat 582 Parameter
2025-05-05 12:36:31,919 - INFO - Geschätzte Modellgröße: 2.54 KB (float32), 0.63 KB (int8)
2025-05-05 12:36:32,496 - INFO - Epoch 1/25 - Train Loss: 1.7901, Train Acc: 22.22% - Val Loss: 1.7797, Val Acc: 66.67%
2025-05-05 12:36:33,091 - INFO - Epoch 2/25 - Train Loss: 1.7904, Train Acc: 24.44% - Val Loss: 1.7780, Val Acc: 66.67%
2025-05-05 12:36:33,689 - INFO - Epoch 3/25 - Train Loss: 1.8022, Train Acc: 8.89% - Val Loss: 1.7761, Val Acc: 66.67%
2025-05-05 12:36:34,233 - INFO - Epoch 4/25 - Train Loss: 1.7779, Train Acc: 24.44% - Val Loss: 1.7735, Val Acc: 66.67%
2025-05-05 12:36:34,854 - INFO - Epoch 5/25 - Train Loss: 1.7710, Train Acc: 15.56% - Val Loss: 1.7706, Val Acc: 66.67%
2025-05-05 12:36:35,416 - INFO - Epoch 6/25 - Train Loss: 1.7497, Train Acc: 28.89% - Val Loss: 1.7660, Val Acc: 66.67%
2025-05-05 12:36:35,961 - INFO - Epoch 7/25 - Train Loss: 1.7324, Train Acc: 24.44% - Val Loss: 1.7579, Val Acc: 75.00%
2025-05-05 12:36:36,581 - INFO - Epoch 8/25 - Train Loss: 1.7142, Train Acc: 17.78% - Val Loss: 1.7497, Val Acc: 25.00%
2025-05-05 12:36:37,155 - INFO - Epoch 9/25 - Train Loss: 1.6901, Train Acc: 31.11% - Val Loss: 1.7420, Val Acc: 16.67%
2025-05-05 12:36:37,735 - INFO - Epoch 10/25 - Train Loss: 1.6580, Train Acc: 33.33% - Val Loss: 1.7357, Val Acc: 16.67%
2025-05-05 12:36:38,335 - INFO - Epoch 11/25 - Train Loss: 1.6501, Train Acc: 22.22% - Val Loss: 1.7294, Val Acc: 16.67%
2025-05-05 12:36:38,963 - INFO - Epoch 12/25 - Train Loss: 1.6311, Train Acc: 28.89% - Val Loss: 1.7214, Val Acc: 16.67%
2025-05-05 12:36:39,495 - INFO - Epoch 13/25 - Train Loss: 1.6017, Train Acc: 37.78% - Val Loss: 1.7134, Val Acc: 8.33%
2025-05-05 12:36:40,054 - INFO - Epoch 14/25 - Train Loss: 1.5959, Train Acc: 33.33% - Val Loss: 1.7058, Val Acc: 8.33%
2025-05-05 12:36:40,569 - INFO - Epoch 15/25 - Train Loss: 1.5906, Train Acc: 26.67% - Val Loss: 1.6973, Val Acc: 8.33%
2025-05-05 12:36:41,111 - INFO - Epoch 16/25 - Train Loss: 1.5716, Train Acc: 26.67% - Val Loss: 1.6898, Val Acc: 8.33%
2025-05-05 12:36:41,611 - INFO - Epoch 17/25 - Train Loss: 1.5576, Train Acc: 35.56% - Val Loss: 1.6844, Val Acc: 8.33%
2025-05-05 12:36:42,140 - INFO - Epoch 18/25 - Train Loss: 1.5559, Train Acc: 44.44% - Val Loss: 1.6802, Val Acc: 8.33%
2025-05-05 12:36:42,720 - INFO - Epoch 19/25 - Train Loss: 1.5748, Train Acc: 22.22% - Val Loss: 1.6768, Val Acc: 8.33%
2025-05-05 12:36:43,234 - INFO - Epoch 20/25 - Train Loss: 1.5277, Train Acc: 35.56% - Val Loss: 1.6746, Val Acc: 8.33%
2025-05-05 12:36:43,847 - INFO - Epoch 21/25 - Train Loss: 1.5596, Train Acc: 22.22% - Val Loss: 1.6720, Val Acc: 8.33%
2025-05-05 12:36:44,432 - INFO - Epoch 22/25 - Train Loss: 1.5495, Train Acc: 33.33% - Val Loss: 1.6697, Val Acc: 8.33%
2025-05-05 12:36:44,979 - INFO - Epoch 23/25 - Train Loss: 1.5509, Train Acc: 31.11% - Val Loss: 1.6676, Val Acc: 8.33%
2025-05-05 12:36:45,591 - INFO - Epoch 24/25 - Train Loss: 1.5378, Train Acc: 37.78% - Val Loss: 1.6659, Val Acc: 8.33%
2025-05-05 12:36:46,118 - INFO - Epoch 25/25 - Train Loss: 1.5528, Train Acc: 28.89% - Val Loss: 1.6636, Val Acc: 8.33%
2025-05-05 12:36:46,123 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:36:46,346 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d1.0_b2_ch8_sep_gpool.pth
2025-05-05 12:36:46,879 - INFO - 
==================================================
Trainiere Modell 6/12: micro_d1.0_b2_ch16_sep_gpool
==================================================
2025-05-05 12:36:46,882 - INFO - Speicheranalyse:
2025-05-05 12:36:46,882 - INFO -   Modellgröße (Float32): 6.04 KB
2025-05-05 12:36:46,882 - INFO -   Modellgröße (Int8): 1.51 KB (0.1% des Flash)
2025-05-05 12:36:46,882 - INFO -   Aktivierungsspeicher: 202.77 KB
2025-05-05 12:36:46,882 - INFO -   Gesamter Laufzeitspeicher: 204.28 KB (77.4% des RAM)
2025-05-05 12:36:46,882 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (204.28KB > 100KB)
2025-05-05 12:36:46,882 - INFO - Modell hat 1,414 Parameter
2025-05-05 12:36:46,882 - INFO - Geschätzte Modellgröße: 6.04 KB (float32), 1.51 KB (int8)
2025-05-05 12:36:47,441 - INFO - Epoch 1/25 - Train Loss: 1.7765, Train Acc: 15.56% - Val Loss: 1.7890, Val Acc: 0.00%
2025-05-05 12:36:48,066 - INFO - Epoch 2/25 - Train Loss: 1.7718, Train Acc: 28.89% - Val Loss: 1.7891, Val Acc: 0.00%
2025-05-05 12:36:48,618 - INFO - Epoch 3/25 - Train Loss: 1.7621, Train Acc: 24.44% - Val Loss: 1.7885, Val Acc: 0.00%
2025-05-05 12:36:49,116 - INFO - Epoch 4/25 - Train Loss: 1.7490, Train Acc: 28.89% - Val Loss: 1.7855, Val Acc: 0.00%
2025-05-05 12:36:49,676 - INFO - Epoch 5/25 - Train Loss: 1.7340, Train Acc: 24.44% - Val Loss: 1.7801, Val Acc: 0.00%
2025-05-05 12:36:50,220 - INFO - Epoch 6/25 - Train Loss: 1.7075, Train Acc: 24.44% - Val Loss: 1.7709, Val Acc: 8.33%
2025-05-05 12:36:50,597 - INFO - Epoch 7/25 - Train Loss: 1.6644, Train Acc: 31.11% - Val Loss: 1.7597, Val Acc: 8.33%
2025-05-05 12:36:51,113 - INFO - Epoch 8/25 - Train Loss: 1.6396, Train Acc: 26.67% - Val Loss: 1.7438, Val Acc: 16.67%
2025-05-05 12:36:51,564 - INFO - Epoch 9/25 - Train Loss: 1.5888, Train Acc: 28.89% - Val Loss: 1.7281, Val Acc: 25.00%
2025-05-05 12:36:52,079 - INFO - Epoch 10/25 - Train Loss: 1.5806, Train Acc: 22.22% - Val Loss: 1.7083, Val Acc: 25.00%
2025-05-05 12:36:52,519 - INFO - Epoch 11/25 - Train Loss: 1.5405, Train Acc: 28.89% - Val Loss: 1.6886, Val Acc: 25.00%
2025-05-05 12:36:53,052 - INFO - Epoch 12/25 - Train Loss: 1.5372, Train Acc: 20.00% - Val Loss: 1.6716, Val Acc: 16.67%
2025-05-05 12:36:53,655 - INFO - Epoch 13/25 - Train Loss: 1.4874, Train Acc: 31.11% - Val Loss: 1.6568, Val Acc: 8.33%
2025-05-05 12:36:54,228 - INFO - Epoch 14/25 - Train Loss: 1.5099, Train Acc: 26.67% - Val Loss: 1.6434, Val Acc: 8.33%
2025-05-05 12:36:54,809 - INFO - Epoch 15/25 - Train Loss: 1.4651, Train Acc: 26.67% - Val Loss: 1.6322, Val Acc: 8.33%
2025-05-05 12:36:55,380 - INFO - Epoch 16/25 - Train Loss: 1.4726, Train Acc: 22.22% - Val Loss: 1.6264, Val Acc: 8.33%
2025-05-05 12:36:55,679 - INFO - Epoch 17/25 - Train Loss: 1.5197, Train Acc: 13.33% - Val Loss: 1.6234, Val Acc: 8.33%
2025-05-05 12:36:56,165 - INFO - Epoch 18/25 - Train Loss: 1.5236, Train Acc: 20.00% - Val Loss: 1.6220, Val Acc: 8.33%
2025-05-05 12:36:56,735 - INFO - Epoch 19/25 - Train Loss: 1.4379, Train Acc: 40.00% - Val Loss: 1.6215, Val Acc: 8.33%
2025-05-05 12:36:57,309 - INFO - Epoch 20/25 - Train Loss: 1.4183, Train Acc: 42.22% - Val Loss: 1.6209, Val Acc: 8.33%
2025-05-05 12:36:57,901 - INFO - Epoch 21/25 - Train Loss: 1.4469, Train Acc: 35.56% - Val Loss: 1.6200, Val Acc: 8.33%
2025-05-05 12:36:58,295 - INFO - Epoch 22/25 - Train Loss: 1.4655, Train Acc: 22.22% - Val Loss: 1.6190, Val Acc: 8.33%
2025-05-05 12:36:58,763 - INFO - Epoch 23/25 - Train Loss: 1.4256, Train Acc: 37.78% - Val Loss: 1.6172, Val Acc: 8.33%
2025-05-05 12:36:59,302 - INFO - Epoch 24/25 - Train Loss: 1.4289, Train Acc: 35.56% - Val Loss: 1.6151, Val Acc: 8.33%
2025-05-05 12:36:59,905 - INFO - Epoch 25/25 - Train Loss: 1.4286, Train Acc: 40.00% - Val Loss: 1.6155, Val Acc: 8.33%
2025-05-05 12:36:59,909 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:37:00,257 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d1.0_b2_ch16_sep_gpool.pth
2025-05-05 12:37:00,762 - INFO - 
==================================================
Trainiere Modell 7/12: micro_d1.0_b3_ch8_sep_gpool
==================================================
2025-05-05 12:37:00,770 - INFO - Speicheranalyse:
2025-05-05 12:37:00,770 - INFO -   Modellgröße (Float32): 6.23 KB
2025-05-05 12:37:00,770 - INFO -   Modellgröße (Int8): 1.56 KB (0.1% des Flash)
2025-05-05 12:37:00,770 - INFO -   Aktivierungsspeicher: 122.90 KB
2025-05-05 12:37:00,770 - INFO -   Gesamter Laufzeitspeicher: 124.46 KB (47.1% des RAM)
2025-05-05 12:37:00,770 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (124.46KB > 100KB)
2025-05-05 12:37:00,770 - INFO - Modell hat 1,430 Parameter
2025-05-05 12:37:00,770 - INFO - Geschätzte Modellgröße: 6.23 KB (float32), 1.56 KB (int8)
2025-05-05 12:37:01,324 - INFO - Epoch 1/25 - Train Loss: 1.8038, Train Acc: 4.44% - Val Loss: 1.7939, Val Acc: 0.00%
2025-05-05 12:37:01,923 - INFO - Epoch 2/25 - Train Loss: 1.7966, Train Acc: 4.44% - Val Loss: 1.7938, Val Acc: 0.00%
2025-05-05 12:37:02,398 - INFO - Epoch 3/25 - Train Loss: 1.7774, Train Acc: 22.22% - Val Loss: 1.7918, Val Acc: 0.00%
2025-05-05 12:37:03,029 - INFO - Epoch 4/25 - Train Loss: 1.7806, Train Acc: 20.00% - Val Loss: 1.7878, Val Acc: 0.00%
2025-05-05 12:37:03,603 - INFO - Epoch 5/25 - Train Loss: 1.7506, Train Acc: 37.78% - Val Loss: 1.7799, Val Acc: 0.00%
2025-05-05 12:37:04,232 - INFO - Epoch 6/25 - Train Loss: 1.7214, Train Acc: 31.11% - Val Loss: 1.7674, Val Acc: 8.33%
2025-05-05 12:37:04,664 - INFO - Epoch 7/25 - Train Loss: 1.6792, Train Acc: 33.33% - Val Loss: 1.7569, Val Acc: 0.00%
2025-05-05 12:37:05,049 - INFO - Epoch 8/25 - Train Loss: 1.6393, Train Acc: 40.00% - Val Loss: 1.7472, Val Acc: 0.00%
2025-05-05 12:37:05,647 - INFO - Epoch 9/25 - Train Loss: 1.5909, Train Acc: 26.67% - Val Loss: 1.7393, Val Acc: 0.00%
2025-05-05 12:37:06,213 - INFO - Epoch 10/25 - Train Loss: 1.5827, Train Acc: 31.11% - Val Loss: 1.7308, Val Acc: 8.33%
2025-05-05 12:37:06,655 - INFO - Epoch 11/25 - Train Loss: 1.5229, Train Acc: 44.44% - Val Loss: 1.7251, Val Acc: 8.33%
2025-05-05 12:37:07,158 - INFO - Epoch 12/25 - Train Loss: 1.5153, Train Acc: 35.56% - Val Loss: 1.7209, Val Acc: 0.00%
2025-05-05 12:37:07,737 - INFO - Epoch 13/25 - Train Loss: 1.5026, Train Acc: 35.56% - Val Loss: 1.7158, Val Acc: 0.00%
2025-05-05 12:37:08,355 - INFO - Epoch 14/25 - Train Loss: 1.4744, Train Acc: 31.11% - Val Loss: 1.7075, Val Acc: 0.00%
2025-05-05 12:37:08,882 - INFO - Epoch 15/25 - Train Loss: 1.4888, Train Acc: 24.44% - Val Loss: 1.7020, Val Acc: 0.00%
2025-05-05 12:37:09,556 - INFO - Epoch 16/25 - Train Loss: 1.4691, Train Acc: 20.00% - Val Loss: 1.6957, Val Acc: 0.00%
2025-05-05 12:37:10,184 - INFO - Epoch 17/25 - Train Loss: 1.5185, Train Acc: 31.11% - Val Loss: 1.6846, Val Acc: 0.00%
2025-05-05 12:37:10,760 - INFO - Epoch 18/25 - Train Loss: 1.4978, Train Acc: 22.22% - Val Loss: 1.6761, Val Acc: 0.00%
2025-05-05 12:37:11,384 - INFO - Epoch 19/25 - Train Loss: 1.5102, Train Acc: 20.00% - Val Loss: 1.6665, Val Acc: 0.00%
2025-05-05 12:37:11,971 - INFO - Epoch 20/25 - Train Loss: 1.4700, Train Acc: 37.78% - Val Loss: 1.6586, Val Acc: 0.00%
2025-05-05 12:37:12,490 - INFO - Epoch 21/25 - Train Loss: 1.4764, Train Acc: 15.56% - Val Loss: 1.6532, Val Acc: 0.00%
2025-05-05 12:37:13,094 - INFO - Epoch 22/25 - Train Loss: 1.4403, Train Acc: 42.22% - Val Loss: 1.6501, Val Acc: 0.00%
2025-05-05 12:37:13,715 - INFO - Epoch 23/25 - Train Loss: 1.4819, Train Acc: 24.44% - Val Loss: 1.6508, Val Acc: 0.00%
2025-05-05 12:37:14,341 - INFO - Epoch 24/25 - Train Loss: 1.4370, Train Acc: 33.33% - Val Loss: 1.6558, Val Acc: 0.00%
2025-05-05 12:37:14,886 - INFO - Epoch 25/25 - Train Loss: 1.4835, Train Acc: 26.67% - Val Loss: 1.6573, Val Acc: 0.00%
2025-05-05 12:37:14,890 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:37:15,276 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d1.0_b3_ch8_sep_gpool.pth
2025-05-05 12:37:15,778 - INFO - 
==================================================
Trainiere Modell 8/12: micro_d1.0_b3_ch16_sep_gpool
==================================================
2025-05-05 12:37:15,782 - INFO - Speicheranalyse:
2025-05-05 12:37:15,782 - INFO -   Modellgröße (Float32): 17.42 KB
2025-05-05 12:37:15,782 - INFO -   Modellgröße (Int8): 4.35 KB (0.2% des Flash)
2025-05-05 12:37:15,782 - INFO -   Aktivierungsspeicher: 245.77 KB
2025-05-05 12:37:15,782 - INFO -   Gesamter Laufzeitspeicher: 250.13 KB (94.7% des RAM)
2025-05-05 12:37:15,782 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (250.13KB > 100KB)
2025-05-05 12:37:15,782 - INFO - Modell hat 4,134 Parameter
2025-05-05 12:37:15,782 - INFO - Geschätzte Modellgröße: 17.42 KB (float32), 4.35 KB (int8)
2025-05-05 12:37:16,290 - INFO - Epoch 1/25 - Train Loss: 1.7691, Train Acc: 20.00% - Val Loss: 1.7853, Val Acc: 66.67%
2025-05-05 12:37:16,863 - INFO - Epoch 2/25 - Train Loss: 1.7634, Train Acc: 17.78% - Val Loss: 1.7811, Val Acc: 66.67%
2025-05-05 12:37:17,412 - INFO - Epoch 3/25 - Train Loss: 1.7470, Train Acc: 20.00% - Val Loss: 1.7757, Val Acc: 66.67%
2025-05-05 12:37:22,932 - INFO - Epoch 4/25 - Train Loss: 1.7279, Train Acc: 26.67% - Val Loss: 1.7699, Val Acc: 66.67%
2025-05-05 12:37:23,540 - INFO - Epoch 5/25 - Train Loss: 1.6804, Train Acc: 37.78% - Val Loss: 1.7650, Val Acc: 8.33%
2025-05-05 12:37:24,160 - INFO - Epoch 6/25 - Train Loss: 1.6387, Train Acc: 22.22% - Val Loss: 1.7549, Val Acc: 8.33%
2025-05-05 12:37:24,557 - INFO - Epoch 7/25 - Train Loss: 1.5795, Train Acc: 28.89% - Val Loss: 1.7373, Val Acc: 8.33%
2025-05-05 12:37:25,181 - INFO - Epoch 8/25 - Train Loss: 1.5527, Train Acc: 24.44% - Val Loss: 1.7138, Val Acc: 8.33%
2025-05-05 12:37:25,733 - INFO - Epoch 9/25 - Train Loss: 1.4932, Train Acc: 28.89% - Val Loss: 1.6972, Val Acc: 8.33%
2025-05-05 12:37:26,321 - INFO - Epoch 10/25 - Train Loss: 1.4683, Train Acc: 33.33% - Val Loss: 1.6848, Val Acc: 8.33%
2025-05-05 12:37:26,901 - INFO - Epoch 11/25 - Train Loss: 1.4188, Train Acc: 33.33% - Val Loss: 1.6666, Val Acc: 8.33%
2025-05-05 12:37:27,496 - INFO - Epoch 12/25 - Train Loss: 1.5085, Train Acc: 22.22% - Val Loss: 1.6457, Val Acc: 8.33%
2025-05-05 12:37:27,935 - INFO - Epoch 13/25 - Train Loss: 1.5416, Train Acc: 20.00% - Val Loss: 1.6282, Val Acc: 8.33%
2025-05-05 12:37:28,538 - INFO - Epoch 14/25 - Train Loss: 1.3908, Train Acc: 26.67% - Val Loss: 1.6136, Val Acc: 8.33%
2025-05-05 12:37:29,208 - INFO - Epoch 15/25 - Train Loss: 1.4184, Train Acc: 22.22% - Val Loss: 1.5954, Val Acc: 0.00%
2025-05-05 12:37:29,793 - INFO - Epoch 16/25 - Train Loss: 1.4061, Train Acc: 33.33% - Val Loss: 1.5766, Val Acc: 0.00%
2025-05-05 12:37:30,053 - INFO - Epoch 17/25 - Train Loss: 1.4181, Train Acc: 33.33% - Val Loss: 1.5611, Val Acc: 0.00%
2025-05-05 12:37:30,605 - INFO - Epoch 18/25 - Train Loss: 1.3409, Train Acc: 40.00% - Val Loss: 1.5468, Val Acc: 0.00%
2025-05-05 12:37:31,212 - INFO - Epoch 19/25 - Train Loss: 1.3789, Train Acc: 26.67% - Val Loss: 1.5326, Val Acc: 0.00%
2025-05-05 12:37:31,605 - INFO - Epoch 20/25 - Train Loss: 1.3911, Train Acc: 22.22% - Val Loss: 1.5237, Val Acc: 0.00%
2025-05-05 12:37:32,148 - INFO - Epoch 21/25 - Train Loss: 1.3959, Train Acc: 26.67% - Val Loss: 1.5202, Val Acc: 0.00%
2025-05-05 12:37:32,712 - INFO - Epoch 22/25 - Train Loss: 1.3728, Train Acc: 35.56% - Val Loss: 1.5113, Val Acc: 0.00%
2025-05-05 12:37:33,256 - INFO - Epoch 23/25 - Train Loss: 1.3936, Train Acc: 31.11% - Val Loss: 1.5049, Val Acc: 0.00%
2025-05-05 12:37:33,700 - INFO - Epoch 24/25 - Train Loss: 1.3696, Train Acc: 37.78% - Val Loss: 1.5004, Val Acc: 0.00%
2025-05-05 12:37:34,332 - INFO - Epoch 25/25 - Train Loss: 1.3546, Train Acc: 42.22% - Val Loss: 1.4935, Val Acc: 0.00%
2025-05-05 12:37:34,338 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:37:34,674 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d1.0_b3_ch16_sep_gpool.pth
2025-05-05 12:37:35,296 - INFO - 
==================================================
Trainiere Modell 9/12: micro_d1.25_b2_ch8_sep_gpool
==================================================
2025-05-05 12:37:35,302 - INFO - Speicheranalyse:
2025-05-05 12:37:35,302 - INFO -   Modellgröße (Float32): 3.32 KB
2025-05-05 12:37:35,302 - INFO -   Modellgröße (Int8): 0.83 KB (0.0% des Flash)
2025-05-05 12:37:35,302 - INFO -   Aktivierungsspeicher: 126.74 KB
2025-05-05 12:37:35,302 - INFO -   Gesamter Laufzeitspeicher: 127.57 KB (48.3% des RAM)
2025-05-05 12:37:35,302 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (127.57KB > 100KB)
2025-05-05 12:37:35,302 - INFO - Modell hat 766 Parameter
2025-05-05 12:37:35,303 - INFO - Geschätzte Modellgröße: 3.32 KB (float32), 0.83 KB (int8)
2025-05-05 12:37:35,836 - INFO - Epoch 1/25 - Train Loss: 1.7788, Train Acc: 40.00% - Val Loss: 1.7986, Val Acc: 0.00%
2025-05-05 12:37:36,324 - INFO - Epoch 2/25 - Train Loss: 1.7897, Train Acc: 28.89% - Val Loss: 1.7992, Val Acc: 0.00%
2025-05-05 12:37:36,874 - INFO - Epoch 3/25 - Train Loss: 1.7803, Train Acc: 28.89% - Val Loss: 1.7978, Val Acc: 0.00%
2025-05-05 12:37:37,498 - INFO - Epoch 4/25 - Train Loss: 1.7764, Train Acc: 26.67% - Val Loss: 1.7937, Val Acc: 0.00%
2025-05-05 12:37:38,083 - INFO - Epoch 5/25 - Train Loss: 1.7624, Train Acc: 24.44% - Val Loss: 1.7848, Val Acc: 0.00%
2025-05-05 12:37:38,620 - INFO - Epoch 6/25 - Train Loss: 1.7515, Train Acc: 15.56% - Val Loss: 1.7701, Val Acc: 16.67%
2025-05-05 12:37:39,242 - INFO - Epoch 7/25 - Train Loss: 1.7197, Train Acc: 31.11% - Val Loss: 1.7523, Val Acc: 16.67%
2025-05-05 12:40:12,378 - INFO - Starte Hyperparameter-Suche für Pizza Erkennung
2025-05-05 12:40:12,378 - INFO - ================================================================================
2025-05-05 12:40:12,378 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-05 12:40:12,378 - INFO - ================================================================================
2025-05-05 12:40:12,378 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-05 12:40:12,379 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-05 12:40:12,379 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-05 12:40:12,379 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-05 12:40:12,379 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-05 12:40:12,379 - INFO - ================================================================================
2025-05-05 12:40:12,379 - INFO - Lade Datensatz aus data/augmented
2025-05-05 12:40:12,379 - INFO - Analysiere Datensatz in data/augmented...
2025-05-05 12:40:12,412 - INFO - Datensatzanalyse abgeschlossen:
2025-05-05 12:40:12,412 - INFO - Gesamtzahl der Bilder: 57
2025-05-05 12:40:12,412 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-05 12:40:12,412 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-05 12:40:12,412 - INFO - RGB-Mittelwerte: [0.4847, 0.4025, 0.3333]
2025-05-05 12:40:12,412 - INFO - RGB-Standardabweichungen: [0.2399, 0.2575, 0.2710]
2025-05-05 12:40:12,412 - INFO - Preparing optimized data loaders...
2025-05-05 12:40:12,412 - INFO - Using dataset-specific normalization: mean=[0.48468599 0.4025237  0.33328085], std=[0.23994533 0.25754207 0.27102478]
2025-05-05 12:40:12,413 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-05 12:40:12,413 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-05 12:40:12,413 - INFO - Generiert: 12 Modellkonfigurationen für die Suche
2025-05-05 12:40:12,414 - INFO - 
==================================================
Trainiere Modell 1/12: micro_d0.75_b2_ch8_sep_gpool
==================================================
2025-05-05 12:40:12,417 - INFO - Speicheranalyse:
2025-05-05 12:40:12,417 - INFO -   Modellgröße (Float32): 1.82 KB
2025-05-05 12:40:12,417 - INFO -   Modellgröße (Int8): 0.45 KB (0.0% des Flash)
2025-05-05 12:40:12,417 - INFO -   Aktivierungsspeicher: 76.05 KB
2025-05-05 12:40:12,417 - INFO -   Gesamter Laufzeitspeicher: 76.51 KB (29.0% des RAM)
2025-05-05 12:40:12,417 - INFO - Modell hat 414 Parameter
2025-05-05 12:40:12,417 - INFO - Geschätzte Modellgröße: 1.82 KB (float32), 0.45 KB (int8)
2025-05-05 12:40:13,374 - INFO - Epoch 1/15 - Train Loss: 1.7930, Train Acc: 20.00% - Val Loss: 1.7917, Val Acc: 25.00%
2025-05-05 12:40:13,787 - INFO - Epoch 2/15 - Train Loss: 1.7959, Train Acc: 20.00% - Val Loss: 1.7910, Val Acc: 25.00%
2025-05-05 12:40:14,395 - INFO - Epoch 3/15 - Train Loss: 1.7835, Train Acc: 20.00% - Val Loss: 1.7889, Val Acc: 25.00%
2025-05-05 12:40:14,913 - INFO - Epoch 4/15 - Train Loss: 1.7728, Train Acc: 22.22% - Val Loss: 1.7846, Val Acc: 25.00%
2025-05-05 12:40:15,366 - INFO - Epoch 5/15 - Train Loss: 1.7547, Train Acc: 35.56% - Val Loss: 1.7768, Val Acc: 25.00%
2025-05-05 12:40:15,819 - INFO - Epoch 6/15 - Train Loss: 1.7423, Train Acc: 24.44% - Val Loss: 1.7678, Val Acc: 25.00%
2025-05-05 12:40:16,097 - INFO - Epoch 7/15 - Train Loss: 1.7243, Train Acc: 17.78% - Val Loss: 1.7601, Val Acc: 25.00%
2025-05-05 12:40:16,607 - INFO - Epoch 8/15 - Train Loss: 1.7165, Train Acc: 17.78% - Val Loss: 1.7514, Val Acc: 25.00%
2025-05-05 12:40:17,172 - INFO - Epoch 9/15 - Train Loss: 1.6920, Train Acc: 17.78% - Val Loss: 1.7430, Val Acc: 25.00%
2025-05-05 12:40:17,729 - INFO - Epoch 10/15 - Train Loss: 1.6865, Train Acc: 26.67% - Val Loss: 1.7358, Val Acc: 25.00%
2025-05-05 12:40:18,281 - INFO - Epoch 11/15 - Train Loss: 1.6720, Train Acc: 37.78% - Val Loss: 1.7297, Val Acc: 25.00%
2025-05-05 12:40:18,711 - INFO - Epoch 12/15 - Train Loss: 1.6616, Train Acc: 37.78% - Val Loss: 1.7251, Val Acc: 25.00%
2025-05-05 12:40:19,276 - INFO - Epoch 13/15 - Train Loss: 1.6541, Train Acc: 44.44% - Val Loss: 1.7211, Val Acc: 25.00%
2025-05-05 12:40:19,863 - INFO - Epoch 14/15 - Train Loss: 1.6627, Train Acc: 28.89% - Val Loss: 1.7180, Val Acc: 25.00%
2025-05-05 12:40:20,377 - INFO - Epoch 15/15 - Train Loss: 1.6479, Train Acc: 35.56% - Val Loss: 1.7158, Val Acc: 16.67%
2025-05-05 12:40:20,383 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:40:20,693 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d0.75_b2_ch8_sep_gpool.pth
2025-05-05 12:40:21,278 - INFO - 
==================================================
Trainiere Modell 2/12: micro_d0.75_b2_ch16_sep_gpool
==================================================
2025-05-05 12:40:21,281 - INFO - Speicheranalyse:
2025-05-05 12:40:21,281 - INFO -   Modellgröße (Float32): 4.16 KB
2025-05-05 12:40:21,281 - INFO -   Modellgröße (Int8): 1.04 KB (0.1% des Flash)
2025-05-05 12:40:21,281 - INFO -   Aktivierungsspeicher: 152.09 KB
2025-05-05 12:40:21,281 - INFO -   Gesamter Laufzeitspeicher: 153.13 KB (58.0% des RAM)
2025-05-05 12:40:21,281 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (153.13KB > 100KB)
2025-05-05 12:40:21,281 - INFO - Modell hat 966 Parameter
2025-05-05 12:40:21,281 - INFO - Geschätzte Modellgröße: 4.16 KB (float32), 1.04 KB (int8)
2025-05-05 12:40:21,798 - INFO - Epoch 1/15 - Train Loss: 1.7814, Train Acc: 17.78% - Val Loss: 1.7896, Val Acc: 8.33%
2025-05-05 12:40:22,348 - INFO - Epoch 2/15 - Train Loss: 1.7825, Train Acc: 17.78% - Val Loss: 1.7864, Val Acc: 8.33%
2025-05-05 12:40:22,778 - INFO - Epoch 3/15 - Train Loss: 1.7680, Train Acc: 26.67% - Val Loss: 1.7810, Val Acc: 0.00%
2025-05-05 12:40:23,201 - INFO - Epoch 4/15 - Train Loss: 1.7399, Train Acc: 33.33% - Val Loss: 1.7723, Val Acc: 8.33%
2025-05-05 12:40:23,778 - INFO - Epoch 5/15 - Train Loss: 1.7166, Train Acc: 28.89% - Val Loss: 1.7656, Val Acc: 0.00%
2025-05-05 12:40:24,306 - INFO - Epoch 6/15 - Train Loss: 1.6906, Train Acc: 40.00% - Val Loss: 1.7600, Val Acc: 0.00%
2025-05-05 12:40:24,912 - INFO - Epoch 7/15 - Train Loss: 1.6550, Train Acc: 37.78% - Val Loss: 1.7557, Val Acc: 0.00%
2025-05-05 12:40:25,359 - INFO - Epoch 8/15 - Train Loss: 1.6368, Train Acc: 28.89% - Val Loss: 1.7515, Val Acc: 0.00%
2025-05-05 12:40:25,884 - INFO - Epoch 9/15 - Train Loss: 1.5914, Train Acc: 42.22% - Val Loss: 1.7473, Val Acc: 0.00%
2025-05-05 12:40:26,448 - INFO - Epoch 10/15 - Train Loss: 1.5702, Train Acc: 37.78% - Val Loss: 1.7434, Val Acc: 0.00%
2025-05-05 12:40:26,953 - INFO - Epoch 11/15 - Train Loss: 1.5911, Train Acc: 26.67% - Val Loss: 1.7398, Val Acc: 0.00%
2025-05-05 12:40:27,559 - INFO - Epoch 12/15 - Train Loss: 1.6101, Train Acc: 26.67% - Val Loss: 1.7354, Val Acc: 0.00%
2025-05-05 12:40:28,153 - INFO - Epoch 13/15 - Train Loss: 1.5727, Train Acc: 28.89% - Val Loss: 1.7307, Val Acc: 0.00%
2025-05-05 12:40:28,645 - INFO - Epoch 14/15 - Train Loss: 1.5633, Train Acc: 35.56% - Val Loss: 1.7278, Val Acc: 0.00%
2025-05-05 12:40:29,219 - INFO - Epoch 15/15 - Train Loss: 1.5720, Train Acc: 33.33% - Val Loss: 1.7244, Val Acc: 0.00%
2025-05-05 12:40:29,224 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:40:29,573 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d0.75_b2_ch16_sep_gpool.pth
2025-05-05 12:40:30,128 - INFO - 
==================================================
Trainiere Modell 3/12: micro_d0.75_b3_ch8_sep_gpool
==================================================
2025-05-05 12:40:30,136 - INFO - Speicheranalyse:
2025-05-05 12:40:30,136 - INFO -   Modellgröße (Float32): 4.21 KB
2025-05-05 12:40:30,137 - INFO -   Modellgröße (Int8): 1.05 KB (0.1% des Flash)
2025-05-05 12:40:30,137 - INFO -   Aktivierungsspeicher: 92.18 KB
2025-05-05 12:40:30,137 - INFO -   Gesamter Laufzeitspeicher: 93.23 KB (35.3% des RAM)
2025-05-05 12:40:30,137 - INFO - Modell hat 954 Parameter
2025-05-05 12:40:30,137 - INFO - Geschätzte Modellgröße: 4.21 KB (float32), 1.05 KB (int8)
2025-05-05 12:40:30,687 - INFO - Epoch 1/15 - Train Loss: 1.7920, Train Acc: 13.33% - Val Loss: 1.7907, Val Acc: 0.00%
2025-05-05 12:40:31,182 - INFO - Epoch 2/15 - Train Loss: 1.7880, Train Acc: 22.22% - Val Loss: 1.7881, Val Acc: 66.67%
2025-05-05 12:40:31,616 - INFO - Epoch 3/15 - Train Loss: 1.7671, Train Acc: 37.78% - Val Loss: 1.7822, Val Acc: 66.67%
2025-05-05 12:40:32,194 - INFO - Epoch 4/15 - Train Loss: 1.7455, Train Acc: 33.33% - Val Loss: 1.7750, Val Acc: 66.67%
2025-05-05 12:40:32,708 - INFO - Epoch 5/15 - Train Loss: 1.7277, Train Acc: 22.22% - Val Loss: 1.7697, Val Acc: 0.00%
2025-05-05 12:40:33,265 - INFO - Epoch 6/15 - Train Loss: 1.6818, Train Acc: 40.00% - Val Loss: 1.7654, Val Acc: 0.00%
2025-05-05 12:40:33,797 - INFO - Epoch 7/15 - Train Loss: 1.6560, Train Acc: 33.33% - Val Loss: 1.7612, Val Acc: 0.00%
2025-05-05 12:40:34,402 - INFO - Epoch 8/15 - Train Loss: 1.6345, Train Acc: 33.33% - Val Loss: 1.7569, Val Acc: 0.00%
2025-05-05 12:40:35,023 - INFO - Epoch 9/15 - Train Loss: 1.6336, Train Acc: 28.89% - Val Loss: 1.7495, Val Acc: 0.00%
2025-05-05 12:40:35,575 - INFO - Epoch 10/15 - Train Loss: 1.5952, Train Acc: 28.89% - Val Loss: 1.7407, Val Acc: 0.00%
2025-05-05 12:40:36,112 - INFO - Epoch 11/15 - Train Loss: 1.6097, Train Acc: 17.78% - Val Loss: 1.7333, Val Acc: 0.00%
2025-05-05 12:40:36,648 - INFO - Epoch 12/15 - Train Loss: 1.5893, Train Acc: 24.44% - Val Loss: 1.7275, Val Acc: 0.00%
2025-05-05 12:40:37,180 - INFO - Epoch 13/15 - Train Loss: 1.5799, Train Acc: 31.11% - Val Loss: 1.7229, Val Acc: 0.00%
2025-05-05 12:40:37,578 - INFO - Epoch 14/15 - Train Loss: 1.5719, Train Acc: 22.22% - Val Loss: 1.7202, Val Acc: 0.00%
2025-05-05 12:40:38,084 - INFO - Epoch 15/15 - Train Loss: 1.5610, Train Acc: 28.89% - Val Loss: 1.7182, Val Acc: 0.00%
2025-05-05 12:40:38,089 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:40:38,475 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d0.75_b3_ch8_sep_gpool.pth
2025-05-05 12:40:38,859 - INFO - 
==================================================
Trainiere Modell 4/12: micro_d0.75_b3_ch16_sep_gpool
==================================================
2025-05-05 12:40:38,862 - INFO - Speicheranalyse:
2025-05-05 12:40:38,862 - INFO -   Modellgröße (Float32): 11.20 KB
2025-05-05 12:40:38,862 - INFO -   Modellgröße (Int8): 2.80 KB (0.1% des Flash)
2025-05-05 12:40:38,862 - INFO -   Aktivierungsspeicher: 184.34 KB
2025-05-05 12:40:38,862 - INFO -   Gesamter Laufzeitspeicher: 187.14 KB (70.9% des RAM)
2025-05-05 12:40:38,862 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (187.14KB > 100KB)
2025-05-05 12:40:38,862 - INFO - Modell hat 2,622 Parameter
2025-05-05 12:40:38,862 - INFO - Geschätzte Modellgröße: 11.20 KB (float32), 2.80 KB (int8)
2025-05-05 12:40:39,342 - INFO - Epoch 1/15 - Train Loss: 1.8062, Train Acc: 22.22% - Val Loss: 1.7947, Val Acc: 8.33%
2025-05-05 12:40:39,953 - INFO - Epoch 2/15 - Train Loss: 1.8190, Train Acc: 15.56% - Val Loss: 1.7942, Val Acc: 8.33%
2025-05-05 12:40:40,564 - INFO - Epoch 3/15 - Train Loss: 1.7450, Train Acc: 31.11% - Val Loss: 1.7903, Val Acc: 8.33%
2025-05-05 12:40:41,151 - INFO - Epoch 4/15 - Train Loss: 1.7136, Train Acc: 26.67% - Val Loss: 1.7835, Val Acc: 0.00%
2025-05-05 12:40:41,570 - INFO - Epoch 5/15 - Train Loss: 1.6577, Train Acc: 31.11% - Val Loss: 1.7705, Val Acc: 0.00%
2025-05-05 12:40:42,173 - INFO - Epoch 6/15 - Train Loss: 1.5843, Train Acc: 37.78% - Val Loss: 1.7552, Val Acc: 0.00%
2025-05-05 12:40:42,793 - INFO - Epoch 7/15 - Train Loss: 1.6067, Train Acc: 31.11% - Val Loss: 1.7405, Val Acc: 0.00%
2025-05-05 12:40:43,298 - INFO - Epoch 8/15 - Train Loss: 1.5678, Train Acc: 26.67% - Val Loss: 1.7259, Val Acc: 0.00%
2025-05-05 12:40:43,888 - INFO - Epoch 9/15 - Train Loss: 1.5118, Train Acc: 31.11% - Val Loss: 1.7134, Val Acc: 0.00%
2025-05-05 12:40:44,501 - INFO - Epoch 10/15 - Train Loss: 1.5105, Train Acc: 28.89% - Val Loss: 1.7022, Val Acc: 0.00%
2025-05-05 12:40:44,946 - INFO - Epoch 11/15 - Train Loss: 1.5124, Train Acc: 24.44% - Val Loss: 1.6931, Val Acc: 0.00%
2025-05-05 12:40:45,524 - INFO - Epoch 12/15 - Train Loss: 1.4395, Train Acc: 33.33% - Val Loss: 1.6851, Val Acc: 0.00%
2025-05-05 12:40:45,998 - INFO - Epoch 13/15 - Train Loss: 1.4638, Train Acc: 31.11% - Val Loss: 1.6782, Val Acc: 0.00%
2025-05-05 12:40:46,479 - INFO - Epoch 14/15 - Train Loss: 1.4299, Train Acc: 33.33% - Val Loss: 1.6728, Val Acc: 0.00%
2025-05-05 12:40:47,110 - INFO - Epoch 15/15 - Train Loss: 1.4447, Train Acc: 33.33% - Val Loss: 1.6668, Val Acc: 0.00%
2025-05-05 12:40:47,116 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:40:47,314 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d0.75_b3_ch16_sep_gpool.pth
2025-05-05 12:40:47,659 - INFO - 
==================================================
Trainiere Modell 5/12: micro_d1.0_b2_ch8_sep_gpool
==================================================
2025-05-05 12:40:47,661 - INFO - Speicheranalyse:
2025-05-05 12:40:47,661 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-05 12:40:47,661 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-05 12:40:47,661 - INFO -   Aktivierungsspeicher: 101.40 KB
2025-05-05 12:40:47,661 - INFO -   Gesamter Laufzeitspeicher: 102.03 KB (38.6% des RAM)
2025-05-05 12:40:47,661 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.03KB > 100KB)
2025-05-05 12:40:47,661 - INFO - Modell hat 582 Parameter
2025-05-05 12:40:47,661 - INFO - Geschätzte Modellgröße: 2.54 KB (float32), 0.63 KB (int8)
2025-05-05 12:40:48,117 - INFO - Epoch 1/15 - Train Loss: 1.7840, Train Acc: 15.56% - Val Loss: 1.7975, Val Acc: 8.33%
2025-05-05 12:40:48,694 - INFO - Epoch 2/15 - Train Loss: 1.7788, Train Acc: 17.78% - Val Loss: 1.7954, Val Acc: 8.33%
2025-05-05 12:40:49,307 - INFO - Epoch 3/15 - Train Loss: 1.7962, Train Acc: 17.78% - Val Loss: 1.7909, Val Acc: 8.33%
2025-05-05 12:40:49,917 - INFO - Epoch 4/15 - Train Loss: 1.7777, Train Acc: 20.00% - Val Loss: 1.7843, Val Acc: 16.67%
2025-05-05 12:40:50,547 - INFO - Epoch 5/15 - Train Loss: 1.7503, Train Acc: 20.00% - Val Loss: 1.7771, Val Acc: 25.00%
2025-05-05 12:40:51,035 - INFO - Epoch 6/15 - Train Loss: 1.7308, Train Acc: 20.00% - Val Loss: 1.7689, Val Acc: 25.00%
2025-05-05 12:40:51,617 - INFO - Epoch 7/15 - Train Loss: 1.7029, Train Acc: 26.67% - Val Loss: 1.7629, Val Acc: 25.00%
2025-05-05 12:40:52,264 - INFO - Epoch 8/15 - Train Loss: 1.6918, Train Acc: 24.44% - Val Loss: 1.7566, Val Acc: 25.00%
2025-05-05 12:40:52,900 - INFO - Epoch 9/15 - Train Loss: 1.6708, Train Acc: 15.56% - Val Loss: 1.7481, Val Acc: 16.67%
2025-05-05 12:40:53,451 - INFO - Epoch 10/15 - Train Loss: 1.6562, Train Acc: 24.44% - Val Loss: 1.7398, Val Acc: 8.33%
2025-05-05 12:40:54,070 - INFO - Epoch 11/15 - Train Loss: 1.6378, Train Acc: 33.33% - Val Loss: 1.7315, Val Acc: 8.33%
2025-05-05 12:40:54,623 - INFO - Epoch 12/15 - Train Loss: 1.6515, Train Acc: 20.00% - Val Loss: 1.7240, Val Acc: 8.33%
2025-05-05 12:40:55,115 - INFO - Epoch 13/15 - Train Loss: 1.6281, Train Acc: 33.33% - Val Loss: 1.7183, Val Acc: 8.33%
2025-05-05 12:40:55,712 - INFO - Epoch 14/15 - Train Loss: 1.6278, Train Acc: 22.22% - Val Loss: 1.7145, Val Acc: 8.33%
2025-05-05 12:40:56,261 - INFO - Epoch 15/15 - Train Loss: 1.6117, Train Acc: 40.00% - Val Loss: 1.7113, Val Acc: 8.33%
2025-05-05 12:40:56,265 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:40:56,530 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d1.0_b2_ch8_sep_gpool.pth
2025-05-05 12:40:57,079 - INFO - 
==================================================
Trainiere Modell 6/12: micro_d1.0_b2_ch16_sep_gpool
==================================================
2025-05-05 12:40:57,081 - INFO - Speicheranalyse:
2025-05-05 12:40:57,082 - INFO -   Modellgröße (Float32): 6.04 KB
2025-05-05 12:40:57,082 - INFO -   Modellgröße (Int8): 1.51 KB (0.1% des Flash)
2025-05-05 12:40:57,082 - INFO -   Aktivierungsspeicher: 202.77 KB
2025-05-05 12:40:57,082 - INFO -   Gesamter Laufzeitspeicher: 204.28 KB (77.4% des RAM)
2025-05-05 12:40:57,082 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (204.28KB > 100KB)
2025-05-05 12:40:57,082 - INFO - Modell hat 1,414 Parameter
2025-05-05 12:40:57,082 - INFO - Geschätzte Modellgröße: 6.04 KB (float32), 1.51 KB (int8)
2025-05-05 12:40:57,494 - INFO - Epoch 1/15 - Train Loss: 1.7654, Train Acc: 33.33% - Val Loss: 1.7925, Val Acc: 16.67%
2025-05-05 12:40:58,021 - INFO - Epoch 2/15 - Train Loss: 1.7723, Train Acc: 26.67% - Val Loss: 1.7917, Val Acc: 16.67%
2025-05-05 12:40:58,503 - INFO - Epoch 3/15 - Train Loss: 1.7514, Train Acc: 20.00% - Val Loss: 1.7880, Val Acc: 25.00%
2025-05-05 12:40:59,110 - INFO - Epoch 4/15 - Train Loss: 1.7365, Train Acc: 28.89% - Val Loss: 1.7805, Val Acc: 25.00%
2025-05-05 12:40:59,712 - INFO - Epoch 5/15 - Train Loss: 1.6981, Train Acc: 24.44% - Val Loss: 1.7713, Val Acc: 8.33%
2025-05-05 12:41:00,265 - INFO - Epoch 6/15 - Train Loss: 1.6614, Train Acc: 33.33% - Val Loss: 1.7616, Val Acc: 0.00%
2025-05-05 12:41:00,769 - INFO - Epoch 7/15 - Train Loss: 1.6190, Train Acc: 35.56% - Val Loss: 1.7505, Val Acc: 0.00%
2025-05-05 12:41:01,322 - INFO - Epoch 8/15 - Train Loss: 1.5903, Train Acc: 40.00% - Val Loss: 1.7439, Val Acc: 0.00%
2025-05-05 12:41:01,824 - INFO - Epoch 9/15 - Train Loss: 1.5837, Train Acc: 37.78% - Val Loss: 1.7333, Val Acc: 0.00%
2025-05-05 12:41:02,031 - INFO - Epoch 10/15 - Train Loss: 1.5601, Train Acc: 28.89% - Val Loss: 1.7219, Val Acc: 0.00%
2025-05-05 12:41:02,563 - INFO - Epoch 11/15 - Train Loss: 1.5196, Train Acc: 35.56% - Val Loss: 1.7112, Val Acc: 0.00%
2025-05-05 12:41:03,133 - INFO - Epoch 12/15 - Train Loss: 1.5554, Train Acc: 20.00% - Val Loss: 1.7016, Val Acc: 0.00%
2025-05-05 12:41:03,731 - INFO - Epoch 13/15 - Train Loss: 1.5237, Train Acc: 33.33% - Val Loss: 1.6928, Val Acc: 0.00%
2025-05-05 12:41:04,350 - INFO - Epoch 14/15 - Train Loss: 1.5048, Train Acc: 40.00% - Val Loss: 1.6841, Val Acc: 0.00%
2025-05-05 12:41:04,877 - INFO - Epoch 15/15 - Train Loss: 1.5127, Train Acc: 31.11% - Val Loss: 1.6775, Val Acc: 0.00%
2025-05-05 12:41:04,879 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:41:04,991 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d1.0_b2_ch16_sep_gpool.pth
2025-05-05 12:41:05,329 - INFO - 
==================================================
Trainiere Modell 7/12: micro_d1.0_b3_ch8_sep_gpool
==================================================
2025-05-05 12:41:05,331 - INFO - Speicheranalyse:
2025-05-05 12:41:05,331 - INFO -   Modellgröße (Float32): 6.23 KB
2025-05-05 12:41:05,331 - INFO -   Modellgröße (Int8): 1.56 KB (0.1% des Flash)
2025-05-05 12:41:05,331 - INFO -   Aktivierungsspeicher: 122.90 KB
2025-05-05 12:41:05,331 - INFO -   Gesamter Laufzeitspeicher: 124.46 KB (47.1% des RAM)
2025-05-05 12:41:05,331 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (124.46KB > 100KB)
2025-05-05 12:41:05,331 - INFO - Modell hat 1,430 Parameter
2025-05-05 12:41:05,332 - INFO - Geschätzte Modellgröße: 6.23 KB (float32), 1.56 KB (int8)
2025-05-05 12:41:05,701 - INFO - Epoch 1/15 - Train Loss: 1.7725, Train Acc: 33.33% - Val Loss: 1.7980, Val Acc: 8.33%
2025-05-05 12:41:05,946 - INFO - Epoch 2/15 - Train Loss: 1.7929, Train Acc: 22.22% - Val Loss: 1.7997, Val Acc: 8.33%
2025-05-05 12:41:06,191 - INFO - Epoch 3/15 - Train Loss: 1.7754, Train Acc: 22.22% - Val Loss: 1.7958, Val Acc: 8.33%
2025-05-05 12:41:06,603 - INFO - Epoch 4/15 - Train Loss: 1.7369, Train Acc: 28.89% - Val Loss: 1.7864, Val Acc: 8.33%
2025-05-05 12:41:07,167 - INFO - Epoch 5/15 - Train Loss: 1.6905, Train Acc: 26.67% - Val Loss: 1.7704, Val Acc: 8.33%
2025-05-05 12:41:07,751 - INFO - Epoch 6/15 - Train Loss: 1.6448, Train Acc: 33.33% - Val Loss: 1.7505, Val Acc: 25.00%
2025-05-05 12:41:08,413 - INFO - Epoch 7/15 - Train Loss: 1.5911, Train Acc: 37.78% - Val Loss: 1.7322, Val Acc: 25.00%
2025-05-05 12:41:09,035 - INFO - Epoch 8/15 - Train Loss: 1.6110, Train Acc: 22.22% - Val Loss: 1.7153, Val Acc: 25.00%
2025-05-05 12:41:09,614 - INFO - Epoch 9/15 - Train Loss: 1.5961, Train Acc: 13.33% - Val Loss: 1.7033, Val Acc: 25.00%
2025-05-05 12:41:10,252 - INFO - Epoch 10/15 - Train Loss: 1.5634, Train Acc: 24.44% - Val Loss: 1.6903, Val Acc: 25.00%
2025-05-05 12:41:10,878 - INFO - Epoch 11/15 - Train Loss: 1.5461, Train Acc: 20.00% - Val Loss: 1.6804, Val Acc: 25.00%
2025-05-05 12:41:11,447 - INFO - Epoch 12/15 - Train Loss: 1.5046, Train Acc: 28.89% - Val Loss: 1.6727, Val Acc: 25.00%
2025-05-05 12:41:12,027 - INFO - Epoch 13/15 - Train Loss: 1.5129, Train Acc: 31.11% - Val Loss: 1.6659, Val Acc: 8.33%
2025-05-05 12:41:12,491 - INFO - Epoch 14/15 - Train Loss: 1.5075, Train Acc: 31.11% - Val Loss: 1.6605, Val Acc: 8.33%
2025-05-05 12:41:13,108 - INFO - Epoch 15/15 - Train Loss: 1.5140, Train Acc: 31.11% - Val Loss: 1.6557, Val Acc: 8.33%
2025-05-05 12:41:13,116 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:41:13,485 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d1.0_b3_ch8_sep_gpool.pth
2025-05-05 12:41:13,728 - INFO - 
==================================================
Trainiere Modell 8/12: micro_d1.0_b3_ch16_sep_gpool
==================================================
2025-05-05 12:41:13,730 - INFO - Speicheranalyse:
2025-05-05 12:41:13,730 - INFO -   Modellgröße (Float32): 17.42 KB
2025-05-05 12:41:13,730 - INFO -   Modellgröße (Int8): 4.35 KB (0.2% des Flash)
2025-05-05 12:41:13,730 - INFO -   Aktivierungsspeicher: 245.77 KB
2025-05-05 12:41:13,731 - INFO -   Gesamter Laufzeitspeicher: 250.13 KB (94.7% des RAM)
2025-05-05 12:41:13,731 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (250.13KB > 100KB)
2025-05-05 12:41:13,731 - INFO - Modell hat 4,134 Parameter
2025-05-05 12:41:13,731 - INFO - Geschätzte Modellgröße: 17.42 KB (float32), 4.35 KB (int8)
2025-05-05 12:41:14,104 - INFO - Epoch 1/15 - Train Loss: 1.7694, Train Acc: 20.00% - Val Loss: 1.7916, Val Acc: 8.33%
2025-05-05 12:41:14,624 - INFO - Epoch 2/15 - Train Loss: 1.7509, Train Acc: 35.56% - Val Loss: 1.7906, Val Acc: 8.33%
2025-05-05 12:41:15,161 - INFO - Epoch 3/15 - Train Loss: 1.7311, Train Acc: 26.67% - Val Loss: 1.7885, Val Acc: 0.00%
2025-05-05 12:41:15,733 - INFO - Epoch 4/15 - Train Loss: 1.6584, Train Acc: 42.22% - Val Loss: 1.7864, Val Acc: 0.00%
2025-05-05 12:41:16,174 - INFO - Epoch 5/15 - Train Loss: 1.6162, Train Acc: 24.44% - Val Loss: 1.7796, Val Acc: 0.00%
2025-05-05 12:41:16,726 - INFO - Epoch 6/15 - Train Loss: 1.5237, Train Acc: 35.56% - Val Loss: 1.7731, Val Acc: 0.00%
2025-05-05 12:41:17,343 - INFO - Epoch 7/15 - Train Loss: 1.5379, Train Acc: 28.89% - Val Loss: 1.7655, Val Acc: 0.00%
2025-05-05 12:41:17,755 - INFO - Epoch 8/15 - Train Loss: 1.4937, Train Acc: 22.22% - Val Loss: 1.7533, Val Acc: 0.00%
2025-05-05 12:41:18,369 - INFO - Epoch 9/15 - Train Loss: 1.4502, Train Acc: 40.00% - Val Loss: 1.7422, Val Acc: 8.33%
2025-05-05 12:41:18,996 - INFO - Epoch 10/15 - Train Loss: 1.4498, Train Acc: 35.56% - Val Loss: 1.7308, Val Acc: 8.33%
2025-05-05 12:41:19,581 - INFO - Epoch 11/15 - Train Loss: 1.4592, Train Acc: 28.89% - Val Loss: 1.7193, Val Acc: 8.33%
2025-05-05 12:41:20,140 - INFO - Epoch 12/15 - Train Loss: 1.4165, Train Acc: 31.11% - Val Loss: 1.7086, Val Acc: 8.33%
2025-05-05 12:41:20,750 - INFO - Epoch 13/15 - Train Loss: 1.4776, Train Acc: 20.00% - Val Loss: 1.6979, Val Acc: 8.33%
2025-05-05 12:41:21,200 - INFO - Epoch 14/15 - Train Loss: 1.3919, Train Acc: 48.89% - Val Loss: 1.6875, Val Acc: 8.33%
2025-05-05 12:41:21,800 - INFO - Epoch 15/15 - Train Loss: 1.4386, Train Acc: 26.67% - Val Loss: 1.6771, Val Acc: 8.33%
2025-05-05 12:41:21,805 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:41:22,166 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d1.0_b3_ch16_sep_gpool.pth
2025-05-05 12:41:22,722 - INFO - 
==================================================
Trainiere Modell 9/12: micro_d1.25_b2_ch8_sep_gpool
==================================================
2025-05-05 12:41:22,724 - INFO - Speicheranalyse:
2025-05-05 12:41:22,724 - INFO -   Modellgröße (Float32): 3.32 KB
2025-05-05 12:41:22,724 - INFO -   Modellgröße (Int8): 0.83 KB (0.0% des Flash)
2025-05-05 12:41:22,724 - INFO -   Aktivierungsspeicher: 126.74 KB
2025-05-05 12:41:22,724 - INFO -   Gesamter Laufzeitspeicher: 127.57 KB (48.3% des RAM)
2025-05-05 12:41:22,724 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (127.57KB > 100KB)
2025-05-05 12:41:22,724 - INFO - Modell hat 766 Parameter
2025-05-05 12:41:22,724 - INFO - Geschätzte Modellgröße: 3.32 KB (float32), 0.83 KB (int8)
2025-05-05 12:41:23,258 - INFO - Epoch 1/15 - Train Loss: 1.7773, Train Acc: 17.78% - Val Loss: 1.7916, Val Acc: 8.33%
2025-05-05 12:41:23,860 - INFO - Epoch 2/15 - Train Loss: 1.7645, Train Acc: 33.33% - Val Loss: 1.7915, Val Acc: 0.00%
2025-05-05 12:41:24,423 - INFO - Epoch 3/15 - Train Loss: 1.7637, Train Acc: 20.00% - Val Loss: 1.7888, Val Acc: 0.00%
2025-05-05 12:41:25,064 - INFO - Epoch 4/15 - Train Loss: 1.7409, Train Acc: 26.67% - Val Loss: 1.7852, Val Acc: 0.00%
2025-05-05 12:41:25,676 - INFO - Epoch 5/15 - Train Loss: 1.7167, Train Acc: 31.11% - Val Loss: 1.7800, Val Acc: 0.00%
2025-05-05 12:41:26,282 - INFO - Epoch 6/15 - Train Loss: 1.6958, Train Acc: 33.33% - Val Loss: 1.7712, Val Acc: 0.00%
2025-05-05 12:41:26,856 - INFO - Epoch 7/15 - Train Loss: 1.6646, Train Acc: 26.67% - Val Loss: 1.7615, Val Acc: 0.00%
2025-05-05 12:41:27,468 - INFO - Epoch 8/15 - Train Loss: 1.6659, Train Acc: 17.78% - Val Loss: 1.7516, Val Acc: 0.00%
2025-05-05 12:41:28,069 - INFO - Epoch 9/15 - Train Loss: 1.6293, Train Acc: 28.89% - Val Loss: 1.7413, Val Acc: 0.00%
2025-05-05 12:41:28,744 - INFO - Epoch 10/15 - Train Loss: 1.6137, Train Acc: 26.67% - Val Loss: 1.7313, Val Acc: 0.00%
2025-05-05 12:41:29,345 - INFO - Epoch 11/15 - Train Loss: 1.5880, Train Acc: 33.33% - Val Loss: 1.7230, Val Acc: 0.00%
2025-05-05 12:41:29,855 - INFO - Epoch 12/15 - Train Loss: 1.6157, Train Acc: 17.78% - Val Loss: 1.7157, Val Acc: 0.00%
2025-05-05 12:41:30,412 - INFO - Epoch 13/15 - Train Loss: 1.5946, Train Acc: 17.78% - Val Loss: 1.7100, Val Acc: 0.00%
2025-05-05 12:41:30,986 - INFO - Epoch 14/15 - Train Loss: 1.5662, Train Acc: 33.33% - Val Loss: 1.7054, Val Acc: 0.00%
2025-05-05 12:41:31,612 - INFO - Epoch 15/15 - Train Loss: 1.5977, Train Acc: 20.00% - Val Loss: 1.7023, Val Acc: 0.00%
2025-05-05 12:41:31,617 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:41:31,923 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d1.25_b2_ch8_sep_gpool.pth
2025-05-05 12:41:32,542 - INFO - 
==================================================
Trainiere Modell 10/12: micro_d1.25_b2_ch16_sep_gpool
==================================================
2025-05-05 12:41:32,544 - INFO - Speicheranalyse:
2025-05-05 12:41:32,544 - INFO -   Modellgröße (Float32): 8.16 KB
2025-05-05 12:41:32,544 - INFO -   Modellgröße (Int8): 2.04 KB (0.1% des Flash)
2025-05-05 12:41:32,544 - INFO -   Aktivierungsspeicher: 253.46 KB
2025-05-05 12:41:32,544 - INFO -   Gesamter Laufzeitspeicher: 255.50 KB (96.8% des RAM)
2025-05-05 12:41:32,544 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (255.50KB > 100KB)
2025-05-05 12:41:32,544 - INFO - Modell hat 1,926 Parameter
2025-05-05 12:41:32,544 - INFO - Geschätzte Modellgröße: 8.16 KB (float32), 2.04 KB (int8)
2025-05-05 12:41:33,050 - INFO - Epoch 1/15 - Train Loss: 1.7483, Train Acc: 37.78% - Val Loss: 1.7993, Val Acc: 8.33%
2025-05-05 12:41:33,691 - INFO - Epoch 2/15 - Train Loss: 1.7686, Train Acc: 24.44% - Val Loss: 1.7994, Val Acc: 8.33%
2025-05-05 12:41:34,340 - INFO - Epoch 3/15 - Train Loss: 1.7488, Train Acc: 31.11% - Val Loss: 1.7954, Val Acc: 0.00%
2025-05-05 12:41:34,930 - INFO - Epoch 4/15 - Train Loss: 1.7117, Train Acc: 35.56% - Val Loss: 1.7849, Val Acc: 0.00%
2025-05-05 12:41:35,415 - INFO - Epoch 5/15 - Train Loss: 1.6754, Train Acc: 33.33% - Val Loss: 1.7676, Val Acc: 0.00%
2025-05-05 12:41:35,898 - INFO - Epoch 6/15 - Train Loss: 1.6665, Train Acc: 15.56% - Val Loss: 1.7468, Val Acc: 0.00%
2025-05-05 12:41:36,508 - INFO - Epoch 7/15 - Train Loss: 1.5892, Train Acc: 35.56% - Val Loss: 1.7282, Val Acc: 0.00%
2025-05-05 12:41:37,026 - INFO - Epoch 8/15 - Train Loss: 1.5377, Train Acc: 42.22% - Val Loss: 1.7128, Val Acc: 0.00%
2025-05-05 12:41:37,587 - INFO - Epoch 9/15 - Train Loss: 1.5468, Train Acc: 28.89% - Val Loss: 1.6969, Val Acc: 0.00%
2025-05-05 12:41:38,215 - INFO - Epoch 10/15 - Train Loss: 1.5297, Train Acc: 24.44% - Val Loss: 1.6815, Val Acc: 0.00%
2025-05-05 12:41:38,724 - INFO - Epoch 11/15 - Train Loss: 1.4664, Train Acc: 42.22% - Val Loss: 1.6699, Val Acc: 0.00%
2025-05-05 12:41:39,301 - INFO - Epoch 12/15 - Train Loss: 1.5061, Train Acc: 24.44% - Val Loss: 1.6624, Val Acc: 0.00%
2025-05-05 12:41:39,826 - INFO - Epoch 13/15 - Train Loss: 1.5084, Train Acc: 26.67% - Val Loss: 1.6556, Val Acc: 0.00%
2025-05-05 12:41:40,318 - INFO - Epoch 14/15 - Train Loss: 1.4808, Train Acc: 31.11% - Val Loss: 1.6502, Val Acc: 0.00%
2025-05-05 12:41:40,947 - INFO - Epoch 15/15 - Train Loss: 1.4699, Train Acc: 35.56% - Val Loss: 1.6457, Val Acc: 0.00%
2025-05-05 12:41:40,952 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:41:41,294 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d1.25_b2_ch16_sep_gpool.pth
2025-05-05 12:41:41,813 - INFO - 
==================================================
Trainiere Modell 11/12: micro_d1.25_b3_ch8_sep_gpool
==================================================
2025-05-05 12:41:41,816 - INFO - Speicheranalyse:
2025-05-05 12:41:41,816 - INFO -   Modellgröße (Float32): 8.56 KB
2025-05-05 12:41:41,816 - INFO -   Modellgröße (Int8): 2.14 KB (0.1% des Flash)
2025-05-05 12:41:41,816 - INFO -   Aktivierungsspeicher: 153.62 KB
2025-05-05 12:41:41,816 - INFO -   Gesamter Laufzeitspeicher: 155.76 KB (59.0% des RAM)
2025-05-05 12:41:41,816 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (155.76KB > 100KB)
2025-05-05 12:41:41,816 - INFO - Modell hat 1,986 Parameter
2025-05-05 12:41:41,816 - INFO - Geschätzte Modellgröße: 8.56 KB (float32), 2.14 KB (int8)
2025-05-05 12:41:42,477 - INFO - Epoch 1/15 - Train Loss: 1.7929, Train Acc: 20.00% - Val Loss: 1.7903, Val Acc: 25.00%
2025-05-05 12:41:43,105 - INFO - Epoch 2/15 - Train Loss: 1.7868, Train Acc: 17.78% - Val Loss: 1.7876, Val Acc: 25.00%
2025-05-05 12:41:43,602 - INFO - Epoch 3/15 - Train Loss: 1.7625, Train Acc: 17.78% - Val Loss: 1.7819, Val Acc: 16.67%
2025-05-05 12:41:44,222 - INFO - Epoch 4/15 - Train Loss: 1.7362, Train Acc: 22.22% - Val Loss: 1.7708, Val Acc: 0.00%
2025-05-05 12:41:44,817 - INFO - Epoch 5/15 - Train Loss: 1.6663, Train Acc: 40.00% - Val Loss: 1.7583, Val Acc: 8.33%
2025-05-05 12:41:45,368 - INFO - Epoch 6/15 - Train Loss: 1.6316, Train Acc: 33.33% - Val Loss: 1.7438, Val Acc: 8.33%
2025-05-05 12:41:45,894 - INFO - Epoch 7/15 - Train Loss: 1.5889, Train Acc: 28.89% - Val Loss: 1.7280, Val Acc: 8.33%
2025-05-05 12:41:46,545 - INFO - Epoch 8/15 - Train Loss: 1.5561, Train Acc: 22.22% - Val Loss: 1.7142, Val Acc: 8.33%
2025-05-05 12:41:47,117 - INFO - Epoch 9/15 - Train Loss: 1.5461, Train Acc: 22.22% - Val Loss: 1.7000, Val Acc: 8.33%
2025-05-05 12:41:47,624 - INFO - Epoch 10/15 - Train Loss: 1.4962, Train Acc: 37.78% - Val Loss: 1.6881, Val Acc: 8.33%
2025-05-05 12:41:48,246 - INFO - Epoch 11/15 - Train Loss: 1.4897, Train Acc: 28.89% - Val Loss: 1.6796, Val Acc: 0.00%
2025-05-05 12:41:48,707 - INFO - Epoch 12/15 - Train Loss: 1.5131, Train Acc: 35.56% - Val Loss: 1.6723, Val Acc: 0.00%
2025-05-05 12:41:49,337 - INFO - Epoch 13/15 - Train Loss: 1.4874, Train Acc: 40.00% - Val Loss: 1.6660, Val Acc: 0.00%
2025-05-05 12:41:49,690 - INFO - Epoch 14/15 - Train Loss: 1.5052, Train Acc: 37.78% - Val Loss: 1.6603, Val Acc: 0.00%
2025-05-05 12:41:50,195 - INFO - Epoch 15/15 - Train Loss: 1.4634, Train Acc: 42.22% - Val Loss: 1.6556, Val Acc: 0.00%
2025-05-05 12:41:50,198 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:41:50,452 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d1.25_b3_ch8_sep_gpool.pth
2025-05-05 12:41:51,612 - INFO - 
==================================================
Trainiere Modell 12/12: micro_d1.25_b3_ch16_sep_gpool
==================================================
2025-05-05 12:41:51,616 - INFO - Speicheranalyse:
2025-05-05 12:41:51,616 - INFO -   Modellgröße (Float32): 24.89 KB
2025-05-05 12:41:51,616 - INFO -   Modellgröße (Int8): 6.22 KB (0.3% des Flash)
2025-05-05 12:41:51,616 - INFO -   Aktivierungsspeicher: 307.21 KB
2025-05-05 12:41:51,616 - INFO -   Gesamter Laufzeitspeicher: 313.43 KB (118.7% des RAM)
2025-05-05 12:41:51,616 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (313.43KB > 100KB)
2025-05-05 12:41:51,616 - INFO - Modell hat 5,966 Parameter
2025-05-05 12:41:51,616 - INFO - Geschätzte Modellgröße: 24.89 KB (float32), 6.22 KB (int8)
2025-05-05 12:41:52,249 - INFO - Epoch 1/15 - Train Loss: 1.8728, Train Acc: 2.22% - Val Loss: 1.7947, Val Acc: 0.00%
2025-05-05 12:41:52,891 - INFO - Epoch 2/15 - Train Loss: 1.8098, Train Acc: 11.11% - Val Loss: 1.7938, Val Acc: 0.00%
2025-05-05 12:41:53,592 - INFO - Epoch 3/15 - Train Loss: 1.7664, Train Acc: 22.22% - Val Loss: 1.7851, Val Acc: 8.33%
2025-05-05 12:41:54,248 - INFO - Epoch 4/15 - Train Loss: 1.7295, Train Acc: 24.44% - Val Loss: 1.7691, Val Acc: 0.00%
2025-05-05 12:41:54,805 - INFO - Epoch 5/15 - Train Loss: 1.6473, Train Acc: 24.44% - Val Loss: 1.7560, Val Acc: 0.00%
2025-05-05 12:41:55,406 - INFO - Epoch 6/15 - Train Loss: 1.5330, Train Acc: 44.44% - Val Loss: 1.7469, Val Acc: 0.00%
2025-05-05 12:41:56,076 - INFO - Epoch 7/15 - Train Loss: 1.5129, Train Acc: 26.67% - Val Loss: 1.7351, Val Acc: 0.00%
2025-05-05 12:41:56,587 - INFO - Epoch 8/15 - Train Loss: 1.4588, Train Acc: 31.11% - Val Loss: 1.7240, Val Acc: 0.00%
2025-05-05 12:41:57,260 - INFO - Epoch 9/15 - Train Loss: 1.4389, Train Acc: 31.11% - Val Loss: 1.7169, Val Acc: 0.00%
2025-05-05 12:41:57,903 - INFO - Epoch 10/15 - Train Loss: 1.4090, Train Acc: 33.33% - Val Loss: 1.7073, Val Acc: 0.00%
2025-05-05 12:41:58,553 - INFO - Epoch 11/15 - Train Loss: 1.3833, Train Acc: 44.44% - Val Loss: 1.6967, Val Acc: 0.00%
2025-05-05 12:41:59,162 - INFO - Epoch 12/15 - Train Loss: 1.3753, Train Acc: 40.00% - Val Loss: 1.6889, Val Acc: 8.33%
2025-05-05 12:41:59,830 - INFO - Epoch 13/15 - Train Loss: 1.3476, Train Acc: 62.22% - Val Loss: 1.6822, Val Acc: 0.00%
2025-05-05 12:42:00,516 - INFO - Epoch 14/15 - Train Loss: 1.3587, Train Acc: 46.67% - Val Loss: 1.6756, Val Acc: 0.00%
2025-05-05 12:42:01,152 - INFO - Epoch 15/15 - Train Loss: 1.3775, Train Acc: 42.22% - Val Loss: 1.6679, Val Acc: 8.33%
2025-05-05 12:42:01,159 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:42:01,547 - INFO - Modell gespeichert unter: output/hyperparameter_search/models/micro_d1.25_b3_ch16_sep_gpool.pth
2025-05-05 12:44:46,093 - INFO - Starte Hyperparameter-Suche für Pizza Erkennung
2025-05-05 12:44:46,093 - INFO - ================================================================================
2025-05-05 12:44:46,093 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-05 12:44:46,093 - INFO - ================================================================================
2025-05-05 12:44:46,093 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-05 12:44:46,093 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-05 12:44:46,093 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-05 12:44:46,093 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-05 12:44:46,093 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-05 12:44:46,093 - INFO - ================================================================================
2025-05-05 12:44:46,093 - INFO - Lade Datensatz aus data/augmented
2025-05-05 12:44:46,093 - INFO - Analysiere Datensatz in data/augmented...
2025-05-05 12:44:46,126 - INFO - Datensatzanalyse abgeschlossen:
2025-05-05 12:44:46,126 - INFO - Gesamtzahl der Bilder: 57
2025-05-05 12:44:46,126 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-05 12:44:46,126 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-05 12:44:46,126 - INFO - RGB-Mittelwerte: [0.4887, 0.4074, 0.3422]
2025-05-05 12:44:46,126 - INFO - RGB-Standardabweichungen: [0.2379, 0.2558, 0.2714]
2025-05-05 12:44:46,126 - INFO - Preparing optimized data loaders...
2025-05-05 12:44:46,127 - INFO - Using dataset-specific normalization: mean=[0.48873176 0.40742488 0.34219451], std=[0.23793679 0.25583396 0.2714229 ]
2025-05-05 12:44:46,128 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-05 12:44:46,128 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-05 12:44:46,128 - INFO - Generiert: 12 Modellkonfigurationen für die Suche
2025-05-05 12:44:46,128 - INFO - 
==================================================
Trainiere Modell 1/12: micro_d0.75_b2_ch8_sep_gpool
==================================================
2025-05-05 12:44:46,131 - INFO - Speicheranalyse:
2025-05-05 12:44:46,131 - INFO -   Modellgröße (Float32): 1.82 KB
2025-05-05 12:44:46,131 - INFO -   Modellgröße (Int8): 0.45 KB (0.0% des Flash)
2025-05-05 12:44:46,131 - INFO -   Aktivierungsspeicher: 76.05 KB
2025-05-05 12:44:46,131 - INFO -   Gesamter Laufzeitspeicher: 76.51 KB (29.0% des RAM)
2025-05-05 12:44:46,131 - INFO - Modell hat 414 Parameter
2025-05-05 12:44:46,131 - INFO - Geschätzte Modellgröße: 1.82 KB (float32), 0.45 KB (int8)
2025-05-05 12:44:46,920 - INFO - Epoch 1/10 - Train Loss: 1.7734, Train Acc: 26.67% - Val Loss: 1.7804, Val Acc: 66.67%
2025-05-05 12:44:47,359 - INFO - Epoch 2/10 - Train Loss: 1.7674, Train Acc: 26.67% - Val Loss: 1.7799, Val Acc: 75.00%
2025-05-05 12:44:47,951 - INFO - Epoch 3/10 - Train Loss: 1.7570, Train Acc: 17.78% - Val Loss: 1.7752, Val Acc: 33.33%
2025-05-05 12:44:48,508 - INFO - Epoch 4/10 - Train Loss: 1.7448, Train Acc: 26.67% - Val Loss: 1.7701, Val Acc: 25.00%
2025-05-05 12:44:49,023 - INFO - Epoch 5/10 - Train Loss: 1.7247, Train Acc: 31.11% - Val Loss: 1.7648, Val Acc: 25.00%
2025-05-05 12:44:49,234 - INFO - Epoch 6/10 - Train Loss: 1.7142, Train Acc: 31.11% - Val Loss: 1.7591, Val Acc: 25.00%
2025-05-05 12:44:49,682 - INFO - Epoch 7/10 - Train Loss: 1.6993, Train Acc: 22.22% - Val Loss: 1.7541, Val Acc: 25.00%
2025-05-05 12:44:50,205 - INFO - Epoch 8/10 - Train Loss: 1.6929, Train Acc: 20.00% - Val Loss: 1.7496, Val Acc: 25.00%
2025-05-05 12:44:50,800 - INFO - Epoch 9/10 - Train Loss: 1.6923, Train Acc: 17.78% - Val Loss: 1.7452, Val Acc: 25.00%
2025-05-05 12:44:51,355 - INFO - Epoch 10/10 - Train Loss: 1.6702, Train Acc: 40.00% - Val Loss: 1.7414, Val Acc: 25.00%
2025-05-05 12:44:51,359 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:44:52,211 - INFO - 
==================================================
Trainiere Modell 2/12: micro_d0.75_b2_ch16_sep_gpool
==================================================
2025-05-05 12:44:52,214 - INFO - Speicheranalyse:
2025-05-05 12:44:52,214 - INFO -   Modellgröße (Float32): 4.16 KB
2025-05-05 12:44:52,214 - INFO -   Modellgröße (Int8): 1.04 KB (0.1% des Flash)
2025-05-05 12:44:52,214 - INFO -   Aktivierungsspeicher: 152.09 KB
2025-05-05 12:44:52,214 - INFO -   Gesamter Laufzeitspeicher: 153.13 KB (58.0% des RAM)
2025-05-05 12:44:52,214 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (153.13KB > 100KB)
2025-05-05 12:44:52,214 - INFO - Modell hat 966 Parameter
2025-05-05 12:44:52,214 - INFO - Geschätzte Modellgröße: 4.16 KB (float32), 1.04 KB (int8)
2025-05-05 12:44:52,430 - INFO - Epoch 1/10 - Train Loss: 1.7966, Train Acc: 11.11% - Val Loss: 1.7935, Val Acc: 8.33%
2025-05-05 12:44:52,614 - INFO - Epoch 2/10 - Train Loss: 1.7855, Train Acc: 13.33% - Val Loss: 1.7895, Val Acc: 25.00%
2025-05-05 12:44:52,799 - INFO - Epoch 3/10 - Train Loss: 1.7726, Train Acc: 13.33% - Val Loss: 1.7854, Val Acc: 25.00%
2025-05-05 12:44:53,291 - INFO - Epoch 4/10 - Train Loss: 1.7387, Train Acc: 24.44% - Val Loss: 1.7803, Val Acc: 25.00%
2025-05-05 12:44:53,637 - INFO - Epoch 5/10 - Train Loss: 1.7092, Train Acc: 22.22% - Val Loss: 1.7728, Val Acc: 0.00%
2025-05-05 12:44:53,957 - INFO - Epoch 6/10 - Train Loss: 1.6761, Train Acc: 24.44% - Val Loss: 1.7638, Val Acc: 25.00%
2025-05-05 12:44:54,476 - INFO - Epoch 7/10 - Train Loss: 1.6643, Train Acc: 28.89% - Val Loss: 1.7549, Val Acc: 25.00%
2025-05-05 12:44:55,000 - INFO - Epoch 8/10 - Train Loss: 1.6271, Train Acc: 33.33% - Val Loss: 1.7473, Val Acc: 25.00%
2025-05-05 12:44:55,574 - INFO - Epoch 9/10 - Train Loss: 1.6247, Train Acc: 28.89% - Val Loss: 1.7413, Val Acc: 25.00%
2025-05-05 12:44:55,910 - INFO - Epoch 10/10 - Train Loss: 1.6185, Train Acc: 31.11% - Val Loss: 1.7366, Val Acc: 25.00%
2025-05-05 12:44:55,915 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:44:56,945 - INFO - 
==================================================
Trainiere Modell 3/12: micro_d0.75_b3_ch8_sep_gpool
==================================================
2025-05-05 12:44:56,947 - INFO - Speicheranalyse:
2025-05-05 12:44:56,947 - INFO -   Modellgröße (Float32): 4.21 KB
2025-05-05 12:44:56,947 - INFO -   Modellgröße (Int8): 1.05 KB (0.1% des Flash)
2025-05-05 12:44:56,947 - INFO -   Aktivierungsspeicher: 92.18 KB
2025-05-05 12:44:56,947 - INFO -   Gesamter Laufzeitspeicher: 93.23 KB (35.3% des RAM)
2025-05-05 12:44:56,947 - INFO - Modell hat 954 Parameter
2025-05-05 12:44:56,947 - INFO - Geschätzte Modellgröße: 4.21 KB (float32), 1.05 KB (int8)
2025-05-05 12:44:57,366 - INFO - Epoch 1/10 - Train Loss: 1.8010, Train Acc: 6.67% - Val Loss: 1.7936, Val Acc: 8.33%
2025-05-05 12:44:57,790 - INFO - Epoch 2/10 - Train Loss: 1.7821, Train Acc: 22.22% - Val Loss: 1.7922, Val Acc: 8.33%
2025-05-05 12:44:58,191 - INFO - Epoch 3/10 - Train Loss: 1.7761, Train Acc: 13.33% - Val Loss: 1.7865, Val Acc: 8.33%
2025-05-05 12:44:58,726 - INFO - Epoch 4/10 - Train Loss: 1.7325, Train Acc: 31.11% - Val Loss: 1.7777, Val Acc: 0.00%
2025-05-05 12:44:59,135 - INFO - Epoch 5/10 - Train Loss: 1.6919, Train Acc: 28.89% - Val Loss: 1.7676, Val Acc: 0.00%
2025-05-05 12:44:59,655 - INFO - Epoch 6/10 - Train Loss: 1.6743, Train Acc: 22.22% - Val Loss: 1.7570, Val Acc: 0.00%
2025-05-05 12:45:00,240 - INFO - Epoch 7/10 - Train Loss: 1.6750, Train Acc: 11.11% - Val Loss: 1.7462, Val Acc: 0.00%
2025-05-05 12:45:00,491 - INFO - Epoch 8/10 - Train Loss: 1.6363, Train Acc: 33.33% - Val Loss: 1.7369, Val Acc: 0.00%
2025-05-05 12:45:01,159 - INFO - Epoch 9/10 - Train Loss: 1.6217, Train Acc: 33.33% - Val Loss: 1.7305, Val Acc: 0.00%
2025-05-05 12:45:01,707 - INFO - Epoch 10/10 - Train Loss: 1.6235, Train Acc: 20.00% - Val Loss: 1.7249, Val Acc: 0.00%
2025-05-05 12:45:01,716 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:45:02,846 - INFO - 
==================================================
Trainiere Modell 4/12: micro_d0.75_b3_ch16_sep_gpool
==================================================
2025-05-05 12:45:02,855 - INFO - Speicheranalyse:
2025-05-05 12:45:02,855 - INFO -   Modellgröße (Float32): 11.20 KB
2025-05-05 12:45:02,855 - INFO -   Modellgröße (Int8): 2.80 KB (0.1% des Flash)
2025-05-05 12:45:02,855 - INFO -   Aktivierungsspeicher: 184.34 KB
2025-05-05 12:45:02,855 - INFO -   Gesamter Laufzeitspeicher: 187.14 KB (70.9% des RAM)
2025-05-05 12:45:02,855 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (187.14KB > 100KB)
2025-05-05 12:45:02,855 - INFO - Modell hat 2,622 Parameter
2025-05-05 12:45:02,855 - INFO - Geschätzte Modellgröße: 11.20 KB (float32), 2.80 KB (int8)
2025-05-05 12:45:03,503 - INFO - Epoch 1/10 - Train Loss: 1.8186, Train Acc: 6.67% - Val Loss: 1.7936, Val Acc: 16.67%
2025-05-05 12:45:04,062 - INFO - Epoch 2/10 - Train Loss: 1.7898, Train Acc: 22.22% - Val Loss: 1.7914, Val Acc: 25.00%
2025-05-05 12:45:04,732 - INFO - Epoch 3/10 - Train Loss: 1.7499, Train Acc: 22.22% - Val Loss: 1.7824, Val Acc: 8.33%
2025-05-05 12:45:05,369 - INFO - Epoch 4/10 - Train Loss: 1.7125, Train Acc: 22.22% - Val Loss: 1.7707, Val Acc: 0.00%
2025-05-05 12:45:05,849 - INFO - Epoch 5/10 - Train Loss: 1.6417, Train Acc: 33.33% - Val Loss: 1.7581, Val Acc: 0.00%
2025-05-05 12:45:06,399 - INFO - Epoch 6/10 - Train Loss: 1.6059, Train Acc: 26.67% - Val Loss: 1.7452, Val Acc: 0.00%
2025-05-05 12:45:07,050 - INFO - Epoch 7/10 - Train Loss: 1.5919, Train Acc: 24.44% - Val Loss: 1.7325, Val Acc: 0.00%
2025-05-05 12:45:07,713 - INFO - Epoch 8/10 - Train Loss: 1.5776, Train Acc: 20.00% - Val Loss: 1.7214, Val Acc: 0.00%
2025-05-05 12:45:08,304 - INFO - Epoch 9/10 - Train Loss: 1.5238, Train Acc: 35.56% - Val Loss: 1.7109, Val Acc: 0.00%
2025-05-05 12:45:08,965 - INFO - Epoch 10/10 - Train Loss: 1.5370, Train Acc: 28.89% - Val Loss: 1.7022, Val Acc: 0.00%
2025-05-05 12:45:08,972 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:45:10,313 - INFO - 
==================================================
Trainiere Modell 5/12: micro_d1.0_b2_ch8_sep_gpool
==================================================
2025-05-05 12:45:10,322 - INFO - Speicheranalyse:
2025-05-05 12:45:10,322 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-05 12:45:10,323 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-05 12:45:10,323 - INFO -   Aktivierungsspeicher: 101.40 KB
2025-05-05 12:45:10,323 - INFO -   Gesamter Laufzeitspeicher: 102.03 KB (38.6% des RAM)
2025-05-05 12:45:10,323 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.03KB > 100KB)
2025-05-05 12:45:10,323 - INFO - Modell hat 582 Parameter
2025-05-05 12:45:10,323 - INFO - Geschätzte Modellgröße: 2.54 KB (float32), 0.63 KB (int8)
2025-05-05 12:45:11,001 - INFO - Epoch 1/10 - Train Loss: 1.7911, Train Acc: 22.22% - Val Loss: 1.7942, Val Acc: 0.00%
2025-05-05 12:45:11,443 - INFO - Epoch 2/10 - Train Loss: 1.7891, Train Acc: 26.67% - Val Loss: 1.7926, Val Acc: 0.00%
2025-05-05 12:45:12,121 - INFO - Epoch 3/10 - Train Loss: 1.7705, Train Acc: 44.44% - Val Loss: 1.7869, Val Acc: 0.00%
2025-05-05 12:45:12,785 - INFO - Epoch 4/10 - Train Loss: 1.7515, Train Acc: 37.78% - Val Loss: 1.7821, Val Acc: 0.00%
2025-05-05 12:45:13,386 - INFO - Epoch 5/10 - Train Loss: 1.7415, Train Acc: 22.22% - Val Loss: 1.7754, Val Acc: 0.00%
2025-05-05 12:45:13,756 - INFO - Epoch 6/10 - Train Loss: 1.7067, Train Acc: 37.78% - Val Loss: 1.7693, Val Acc: 0.00%
2025-05-05 12:45:14,250 - INFO - Epoch 7/10 - Train Loss: 1.6978, Train Acc: 37.78% - Val Loss: 1.7651, Val Acc: 0.00%
2025-05-05 12:45:14,934 - INFO - Epoch 8/10 - Train Loss: 1.6697, Train Acc: 33.33% - Val Loss: 1.7627, Val Acc: 0.00%
2025-05-05 12:45:15,613 - INFO - Epoch 9/10 - Train Loss: 1.6920, Train Acc: 37.78% - Val Loss: 1.7609, Val Acc: 0.00%
2025-05-05 12:45:16,303 - INFO - Epoch 10/10 - Train Loss: 1.6805, Train Acc: 33.33% - Val Loss: 1.7599, Val Acc: 0.00%
2025-05-05 12:45:16,310 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:45:17,495 - INFO - 
==================================================
Trainiere Modell 6/12: micro_d1.0_b2_ch16_sep_gpool
==================================================
2025-05-05 12:45:17,501 - INFO - Speicheranalyse:
2025-05-05 12:45:17,501 - INFO -   Modellgröße (Float32): 6.04 KB
2025-05-05 12:45:17,501 - INFO -   Modellgröße (Int8): 1.51 KB (0.1% des Flash)
2025-05-05 12:45:17,501 - INFO -   Aktivierungsspeicher: 202.77 KB
2025-05-05 12:45:17,502 - INFO -   Gesamter Laufzeitspeicher: 204.28 KB (77.4% des RAM)
2025-05-05 12:45:17,502 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (204.28KB > 100KB)
2025-05-05 12:45:17,502 - INFO - Modell hat 1,414 Parameter
2025-05-05 12:45:17,502 - INFO - Geschätzte Modellgröße: 6.04 KB (float32), 1.51 KB (int8)
2025-05-05 12:45:17,897 - INFO - Epoch 1/10 - Train Loss: 1.7911, Train Acc: 17.78% - Val Loss: 1.7928, Val Acc: 0.00%
2025-05-05 12:45:18,167 - INFO - Epoch 2/10 - Train Loss: 1.7839, Train Acc: 22.22% - Val Loss: 1.7906, Val Acc: 0.00%
2025-05-05 12:45:18,572 - INFO - Epoch 3/10 - Train Loss: 1.7674, Train Acc: 20.00% - Val Loss: 1.7840, Val Acc: 0.00%
2025-05-05 12:45:19,098 - INFO - Epoch 4/10 - Train Loss: 1.7138, Train Acc: 37.78% - Val Loss: 1.7730, Val Acc: 0.00%
2025-05-05 12:45:19,698 - INFO - Epoch 5/10 - Train Loss: 1.6617, Train Acc: 51.11% - Val Loss: 1.7595, Val Acc: 0.00%
2025-05-05 12:45:20,283 - INFO - Epoch 6/10 - Train Loss: 1.6489, Train Acc: 22.22% - Val Loss: 1.7444, Val Acc: 0.00%
2025-05-05 12:45:20,894 - INFO - Epoch 7/10 - Train Loss: 1.6449, Train Acc: 22.22% - Val Loss: 1.7303, Val Acc: 0.00%
2025-05-05 12:45:21,369 - INFO - Epoch 8/10 - Train Loss: 1.6526, Train Acc: 22.22% - Val Loss: 1.7191, Val Acc: 0.00%
2025-05-05 12:45:21,987 - INFO - Epoch 9/10 - Train Loss: 1.5938, Train Acc: 46.67% - Val Loss: 1.7110, Val Acc: 0.00%
2025-05-05 12:45:22,419 - INFO - Epoch 10/10 - Train Loss: 1.6487, Train Acc: 20.00% - Val Loss: 1.7047, Val Acc: 0.00%
2025-05-05 12:45:22,423 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:45:23,378 - INFO - 
==================================================
Trainiere Modell 7/12: micro_d1.0_b3_ch8_sep_gpool
==================================================
2025-05-05 12:45:23,383 - INFO - Speicheranalyse:
2025-05-05 12:45:23,383 - INFO -   Modellgröße (Float32): 6.23 KB
2025-05-05 12:45:23,383 - INFO -   Modellgröße (Int8): 1.56 KB (0.1% des Flash)
2025-05-05 12:45:23,383 - INFO -   Aktivierungsspeicher: 122.90 KB
2025-05-05 12:45:23,383 - INFO -   Gesamter Laufzeitspeicher: 124.46 KB (47.1% des RAM)
2025-05-05 12:45:23,383 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (124.46KB > 100KB)
2025-05-05 12:45:23,384 - INFO - Modell hat 1,430 Parameter
2025-05-05 12:45:23,384 - INFO - Geschätzte Modellgröße: 6.23 KB (float32), 1.56 KB (int8)
2025-05-05 12:45:23,683 - INFO - Epoch 1/10 - Train Loss: 1.7907, Train Acc: 17.78% - Val Loss: 1.7897, Val Acc: 41.67%
2025-05-05 12:45:24,349 - INFO - Epoch 2/10 - Train Loss: 1.7791, Train Acc: 31.11% - Val Loss: 1.7853, Val Acc: 50.00%
2025-05-05 12:45:24,948 - INFO - Epoch 3/10 - Train Loss: 1.7562, Train Acc: 20.00% - Val Loss: 1.7783, Val Acc: 0.00%
2025-05-05 12:45:25,590 - INFO - Epoch 4/10 - Train Loss: 1.7100, Train Acc: 24.44% - Val Loss: 1.7701, Val Acc: 0.00%
2025-05-05 12:45:26,220 - INFO - Epoch 5/10 - Train Loss: 1.6595, Train Acc: 42.22% - Val Loss: 1.7588, Val Acc: 0.00%
2025-05-05 12:45:26,885 - INFO - Epoch 6/10 - Train Loss: 1.6315, Train Acc: 33.33% - Val Loss: 1.7477, Val Acc: 0.00%
2025-05-05 12:45:27,563 - INFO - Epoch 7/10 - Train Loss: 1.6036, Train Acc: 42.22% - Val Loss: 1.7384, Val Acc: 0.00%
2025-05-05 12:45:28,070 - INFO - Epoch 8/10 - Train Loss: 1.6061, Train Acc: 22.22% - Val Loss: 1.7307, Val Acc: 0.00%
2025-05-05 12:45:28,623 - INFO - Epoch 9/10 - Train Loss: 1.5887, Train Acc: 35.56% - Val Loss: 1.7240, Val Acc: 0.00%
2025-05-05 12:45:29,260 - INFO - Epoch 10/10 - Train Loss: 1.6031, Train Acc: 26.67% - Val Loss: 1.7179, Val Acc: 0.00%
2025-05-05 12:45:29,269 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:45:30,446 - INFO - 
==================================================
Trainiere Modell 8/12: micro_d1.0_b3_ch16_sep_gpool
==================================================
2025-05-05 12:45:30,457 - INFO - Speicheranalyse:
2025-05-05 12:45:30,457 - INFO -   Modellgröße (Float32): 17.42 KB
2025-05-05 12:45:30,458 - INFO -   Modellgröße (Int8): 4.35 KB (0.2% des Flash)
2025-05-05 12:45:30,458 - INFO -   Aktivierungsspeicher: 245.77 KB
2025-05-05 12:45:30,458 - INFO -   Gesamter Laufzeitspeicher: 250.13 KB (94.7% des RAM)
2025-05-05 12:45:30,458 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (250.13KB > 100KB)
2025-05-05 12:45:30,458 - INFO - Modell hat 4,134 Parameter
2025-05-05 12:45:30,458 - INFO - Geschätzte Modellgröße: 17.42 KB (float32), 4.35 KB (int8)
2025-05-05 12:45:31,149 - INFO - Epoch 1/10 - Train Loss: 1.8272, Train Acc: 0.00% - Val Loss: 1.7937, Val Acc: 0.00%
2025-05-05 12:45:31,818 - INFO - Epoch 2/10 - Train Loss: 1.7872, Train Acc: 11.11% - Val Loss: 1.7929, Val Acc: 25.00%
2025-05-05 12:45:32,522 - INFO - Epoch 3/10 - Train Loss: 1.7575, Train Acc: 28.89% - Val Loss: 1.7889, Val Acc: 0.00%
2025-05-05 12:45:33,136 - INFO - Epoch 4/10 - Train Loss: 1.6656, Train Acc: 26.67% - Val Loss: 1.7797, Val Acc: 0.00%
2025-05-05 12:45:33,766 - INFO - Epoch 5/10 - Train Loss: 1.5640, Train Acc: 46.67% - Val Loss: 1.7691, Val Acc: 0.00%
2025-05-05 12:45:34,365 - INFO - Epoch 6/10 - Train Loss: 1.4997, Train Acc: 46.67% - Val Loss: 1.7581, Val Acc: 0.00%
2025-05-05 12:45:34,908 - INFO - Epoch 7/10 - Train Loss: 1.5074, Train Acc: 37.78% - Val Loss: 1.7491, Val Acc: 0.00%
2025-05-05 12:45:35,568 - INFO - Epoch 8/10 - Train Loss: 1.5507, Train Acc: 24.44% - Val Loss: 1.7403, Val Acc: 0.00%
2025-05-05 12:45:36,141 - INFO - Epoch 9/10 - Train Loss: 1.5434, Train Acc: 33.33% - Val Loss: 1.7333, Val Acc: 8.33%
2025-05-05 12:45:36,767 - INFO - Epoch 10/10 - Train Loss: 1.4821, Train Acc: 33.33% - Val Loss: 1.7277, Val Acc: 8.33%
2025-05-05 12:45:36,774 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:45:38,278 - INFO - 
==================================================
Trainiere Modell 9/12: micro_d1.25_b2_ch8_sep_gpool
==================================================
2025-05-05 12:45:38,281 - INFO - Speicheranalyse:
2025-05-05 12:45:38,282 - INFO -   Modellgröße (Float32): 3.32 KB
2025-05-05 12:45:38,282 - INFO -   Modellgröße (Int8): 0.83 KB (0.0% des Flash)
2025-05-05 12:45:38,282 - INFO -   Aktivierungsspeicher: 126.74 KB
2025-05-05 12:45:38,282 - INFO -   Gesamter Laufzeitspeicher: 127.57 KB (48.3% des RAM)
2025-05-05 12:45:38,282 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (127.57KB > 100KB)
2025-05-05 12:45:38,282 - INFO - Modell hat 766 Parameter
2025-05-05 12:45:38,282 - INFO - Geschätzte Modellgröße: 3.32 KB (float32), 0.83 KB (int8)
2025-05-05 12:45:38,626 - INFO - Epoch 1/10 - Train Loss: 1.7724, Train Acc: 28.89% - Val Loss: 1.7864, Val Acc: 58.33%
2025-05-05 12:45:39,151 - INFO - Epoch 2/10 - Train Loss: 1.7700, Train Acc: 13.33% - Val Loss: 1.7830, Val Acc: 41.67%
2025-05-05 12:45:39,797 - INFO - Epoch 3/10 - Train Loss: 1.7680, Train Acc: 22.22% - Val Loss: 1.7771, Val Acc: 33.33%
2025-05-05 12:45:40,490 - INFO - Epoch 4/10 - Train Loss: 1.7342, Train Acc: 24.44% - Val Loss: 1.7724, Val Acc: 0.00%
2025-05-05 12:45:40,920 - INFO - Epoch 5/10 - Train Loss: 1.7008, Train Acc: 44.44% - Val Loss: 1.7681, Val Acc: 0.00%
2025-05-05 12:45:41,535 - INFO - Epoch 6/10 - Train Loss: 1.6790, Train Acc: 26.67% - Val Loss: 1.7616, Val Acc: 0.00%
2025-05-05 12:45:42,220 - INFO - Epoch 7/10 - Train Loss: 1.6650, Train Acc: 24.44% - Val Loss: 1.7553, Val Acc: 0.00%
2025-05-05 12:45:42,887 - INFO - Epoch 8/10 - Train Loss: 1.6605, Train Acc: 22.22% - Val Loss: 1.7498, Val Acc: 0.00%
2025-05-05 12:45:43,421 - INFO - Epoch 9/10 - Train Loss: 1.6376, Train Acc: 26.67% - Val Loss: 1.7444, Val Acc: 0.00%
2025-05-05 12:45:44,071 - INFO - Epoch 10/10 - Train Loss: 1.6489, Train Acc: 20.00% - Val Loss: 1.7398, Val Acc: 0.00%
2025-05-05 12:45:44,076 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:45:45,246 - INFO - 
==================================================
Trainiere Modell 10/12: micro_d1.25_b2_ch16_sep_gpool
==================================================
2025-05-05 12:45:45,257 - INFO - Speicheranalyse:
2025-05-05 12:45:45,258 - INFO -   Modellgröße (Float32): 8.16 KB
2025-05-05 12:45:45,258 - INFO -   Modellgröße (Int8): 2.04 KB (0.1% des Flash)
2025-05-05 12:45:45,258 - INFO -   Aktivierungsspeicher: 253.46 KB
2025-05-05 12:45:45,259 - INFO -   Gesamter Laufzeitspeicher: 255.50 KB (96.8% des RAM)
2025-05-05 12:45:45,259 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (255.50KB > 100KB)
2025-05-05 12:45:45,259 - INFO - Modell hat 1,926 Parameter
2025-05-05 12:45:45,259 - INFO - Geschätzte Modellgröße: 8.16 KB (float32), 2.04 KB (int8)
2025-05-05 12:45:45,963 - INFO - Epoch 1/10 - Train Loss: 1.8056, Train Acc: 20.00% - Val Loss: 1.7925, Val Acc: 0.00%
2025-05-05 12:45:46,630 - INFO - Epoch 2/10 - Train Loss: 1.8087, Train Acc: 22.22% - Val Loss: 1.7882, Val Acc: 41.67%
2025-05-05 12:45:47,090 - INFO - Epoch 3/10 - Train Loss: 1.7688, Train Acc: 24.44% - Val Loss: 1.7771, Val Acc: 0.00%
2025-05-05 12:45:47,583 - INFO - Epoch 4/10 - Train Loss: 1.7332, Train Acc: 24.44% - Val Loss: 1.7647, Val Acc: 0.00%
2025-05-05 12:45:48,166 - INFO - Epoch 5/10 - Train Loss: 1.6628, Train Acc: 33.33% - Val Loss: 1.7506, Val Acc: 0.00%
2025-05-05 12:45:48,856 - INFO - Epoch 6/10 - Train Loss: 1.6351, Train Acc: 31.11% - Val Loss: 1.7399, Val Acc: 0.00%
2025-05-05 12:45:49,511 - INFO - Epoch 7/10 - Train Loss: 1.6159, Train Acc: 24.44% - Val Loss: 1.7309, Val Acc: 0.00%
2025-05-05 12:45:50,215 - INFO - Epoch 8/10 - Train Loss: 1.5836, Train Acc: 20.00% - Val Loss: 1.7219, Val Acc: 0.00%
2025-05-05 12:45:50,848 - INFO - Epoch 9/10 - Train Loss: 1.5637, Train Acc: 26.67% - Val Loss: 1.7152, Val Acc: 0.00%
2025-05-05 12:45:51,403 - INFO - Epoch 10/10 - Train Loss: 1.5451, Train Acc: 42.22% - Val Loss: 1.7096, Val Acc: 0.00%
2025-05-05 12:45:51,404 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:45:52,362 - INFO - 
==================================================
Trainiere Modell 11/12: micro_d1.25_b3_ch8_sep_gpool
==================================================
2025-05-05 12:45:52,374 - INFO - Speicheranalyse:
2025-05-05 12:45:52,374 - INFO -   Modellgröße (Float32): 8.56 KB
2025-05-05 12:45:52,374 - INFO -   Modellgröße (Int8): 2.14 KB (0.1% des Flash)
2025-05-05 12:45:52,374 - INFO -   Aktivierungsspeicher: 153.62 KB
2025-05-05 12:45:52,375 - INFO -   Gesamter Laufzeitspeicher: 155.76 KB (59.0% des RAM)
2025-05-05 12:45:52,375 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (155.76KB > 100KB)
2025-05-05 12:45:52,375 - INFO - Modell hat 1,986 Parameter
2025-05-05 12:45:52,375 - INFO - Geschätzte Modellgröße: 8.56 KB (float32), 2.14 KB (int8)
2025-05-05 12:45:53,107 - INFO - Epoch 1/10 - Train Loss: 1.7871, Train Acc: 15.56% - Val Loss: 1.7871, Val Acc: 25.00%
2025-05-05 12:45:53,598 - INFO - Epoch 2/10 - Train Loss: 1.7705, Train Acc: 15.56% - Val Loss: 1.7839, Val Acc: 25.00%
2025-05-05 12:45:54,238 - INFO - Epoch 3/10 - Train Loss: 1.7360, Train Acc: 20.00% - Val Loss: 1.7739, Val Acc: 25.00%
2025-05-05 12:45:54,928 - INFO - Epoch 4/10 - Train Loss: 1.6946, Train Acc: 31.11% - Val Loss: 1.7652, Val Acc: 25.00%
2025-05-05 12:45:55,594 - INFO - Epoch 5/10 - Train Loss: 1.6373, Train Acc: 37.78% - Val Loss: 1.7553, Val Acc: 25.00%
2025-05-05 12:45:56,193 - INFO - Epoch 6/10 - Train Loss: 1.6070, Train Acc: 22.22% - Val Loss: 1.7424, Val Acc: 16.67%
2025-05-05 12:45:56,838 - INFO - Epoch 7/10 - Train Loss: 1.5735, Train Acc: 28.89% - Val Loss: 1.7328, Val Acc: 16.67%
2025-05-05 12:45:57,471 - INFO - Epoch 8/10 - Train Loss: 1.5732, Train Acc: 22.22% - Val Loss: 1.7253, Val Acc: 8.33%
2025-05-05 12:45:58,148 - INFO - Epoch 9/10 - Train Loss: 1.5316, Train Acc: 37.78% - Val Loss: 1.7202, Val Acc: 0.00%
2025-05-05 12:45:58,825 - INFO - Epoch 10/10 - Train Loss: 1.5237, Train Acc: 28.89% - Val Loss: 1.7152, Val Acc: 8.33%
2025-05-05 12:45:58,832 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:46:00,179 - INFO - 
==================================================
Trainiere Modell 12/12: micro_d1.25_b3_ch16_sep_gpool
==================================================
2025-05-05 12:46:00,191 - INFO - Speicheranalyse:
2025-05-05 12:46:00,191 - INFO -   Modellgröße (Float32): 24.89 KB
2025-05-05 12:46:00,191 - INFO -   Modellgröße (Int8): 6.22 KB (0.3% des Flash)
2025-05-05 12:46:00,192 - INFO -   Aktivierungsspeicher: 307.21 KB
2025-05-05 12:46:00,192 - INFO -   Gesamter Laufzeitspeicher: 313.43 KB (118.7% des RAM)
2025-05-05 12:46:00,192 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (313.43KB > 100KB)
2025-05-05 12:46:00,192 - INFO - Modell hat 5,966 Parameter
2025-05-05 12:46:00,192 - INFO - Geschätzte Modellgröße: 24.89 KB (float32), 6.22 KB (int8)
2025-05-05 12:46:00,795 - INFO - Epoch 1/10 - Train Loss: 1.7718, Train Acc: 20.00% - Val Loss: 1.7864, Val Acc: 25.00%
2025-05-05 12:46:01,418 - INFO - Epoch 2/10 - Train Loss: 1.7120, Train Acc: 35.56% - Val Loss: 1.7746, Val Acc: 25.00%
2025-05-05 12:46:02,113 - INFO - Epoch 3/10 - Train Loss: 1.6969, Train Acc: 20.00% - Val Loss: 1.7624, Val Acc: 25.00%
2025-05-05 12:46:02,746 - INFO - Epoch 4/10 - Train Loss: 1.5820, Train Acc: 31.11% - Val Loss: 1.7557, Val Acc: 25.00%
2025-05-05 12:46:03,174 - INFO - Epoch 5/10 - Train Loss: 1.5504, Train Acc: 28.89% - Val Loss: 1.7435, Val Acc: 8.33%
2025-05-05 12:46:03,776 - INFO - Epoch 6/10 - Train Loss: 1.4659, Train Acc: 26.67% - Val Loss: 1.7330, Val Acc: 8.33%
2025-05-05 12:46:04,359 - INFO - Epoch 7/10 - Train Loss: 1.4559, Train Acc: 24.44% - Val Loss: 1.7275, Val Acc: 8.33%
2025-05-05 12:46:04,732 - INFO - Epoch 8/10 - Train Loss: 1.4264, Train Acc: 37.78% - Val Loss: 1.7221, Val Acc: 0.00%
2025-05-05 12:46:05,353 - INFO - Epoch 9/10 - Train Loss: 1.4190, Train Acc: 37.78% - Val Loss: 1.7177, Val Acc: 0.00%
2025-05-05 12:46:05,956 - INFO - Epoch 10/10 - Train Loss: 1.5209, Train Acc: 20.00% - Val Loss: 1.7141, Val Acc: 0.00%
2025-05-05 12:46:05,963 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 12:46:08,411 - INFO - 
==================================================
2025-05-05 12:46:08,412 - INFO - ZUSAMMENFASSUNG DER HYPERPARAMETER-SUCHE
2025-05-05 12:46:08,412 - INFO - ==================================================
2025-05-05 12:46:08,412 - INFO - Analysierte Modelle: 12
2025-05-05 12:46:08,412 - INFO - Pareto-optimale Modelle: 2
2025-05-05 12:46:08,412 - INFO - 
Top 5 Modelle nach Genauigkeit:
2025-05-05 12:46:08,412 - INFO - 1. micro_d0.75_b2_ch8_sep_gpool: Acc=25.00%, Size=0.5KB, Time=8.2ms
2025-05-05 12:46:08,412 - INFO - 2. micro_d0.75_b2_ch16_sep_gpool: Acc=25.00%, Size=1.0KB, Time=11.7ms
2025-05-05 12:46:08,413 - INFO - 3. micro_d1.25_b3_ch8_sep_gpool: Acc=8.33%, Size=2.1KB, Time=15.0ms
2025-05-05 12:46:08,413 - INFO - 4. micro_d1.0_b3_ch16_sep_gpool: Acc=8.33%, Size=4.4KB, Time=15.3ms
2025-05-05 12:46:08,413 - INFO - 5. micro_d0.75_b3_ch16_sep_gpool: Acc=0.00%, Size=2.8KB, Time=20.4ms
2025-05-05 12:46:08,414 - INFO - 
Top 5 Modelle nach Speichereffizienz (Accuracy/KB):
2025-05-05 12:46:08,414 - INFO - 1. micro_d0.75_b2_ch8_sep_gpool: Eff=55.05%/KB, Acc=25.00%, Size=0.5KB
2025-05-05 12:46:08,414 - INFO - 2. micro_d0.75_b2_ch16_sep_gpool: Eff=24.04%/KB, Acc=25.00%, Size=1.0KB
2025-05-05 12:46:08,415 - INFO - 3. micro_d1.25_b3_ch8_sep_gpool: Eff=3.89%/KB, Acc=8.33%, Size=2.1KB
2025-05-05 12:46:08,415 - INFO - 4. micro_d1.0_b3_ch16_sep_gpool: Eff=1.91%/KB, Acc=8.33%, Size=4.4KB
2025-05-05 12:46:08,415 - INFO - 5. micro_d0.75_b3_ch16_sep_gpool: Eff=0.00%/KB, Acc=0.00%, Size=2.8KB
2025-05-05 12:46:08,415 - INFO - 
Ergebnisse wurden gespeichert in:
2025-05-05 12:46:08,415 - INFO - - CSV: output/hyperparameter_search/hyperparameter_results.csv
2025-05-05 12:46:08,415 - INFO - - Excel: output/hyperparameter_search/hyperparameter_results.xlsx
2025-05-05 12:46:08,415 - INFO - - Plots: output/hyperparameter_search/plots
2025-05-05 15:32:51,345 - WARNING - Fehler beim Laden der Klassennamen: string indices must be integers, not 'str'
2025-05-05 15:32:51,349 - INFO - Lade MicroPizzaNet Modell
2025-05-05 15:32:51,352 - ERROR - Fehler beim Laden des Modells: Error(s) in loading state_dict for ModularMicroPizzaNet:
	Missing key(s) in state_dict: "blocks.0.0.weight", "blocks.0.1.weight", "blocks.0.1.bias", "blocks.0.1.running_mean", "blocks.0.1.running_var", "blocks.1.0.weight", "blocks.1.1.weight", "blocks.1.1.bias", "blocks.1.1.running_mean", "blocks.1.1.running_var", "blocks.1.3.weight", "blocks.1.4.weight", "blocks.1.4.bias", "blocks.1.4.running_mean", "blocks.1.4.running_var", "blocks.2.0.weight", "blocks.2.1.weight", "blocks.2.1.bias", "blocks.2.1.running_mean", "blocks.2.1.running_var", "blocks.2.3.weight", "blocks.2.4.weight", "blocks.2.4.bias", "blocks.2.4.running_mean", "blocks.2.4.running_var", "classifier.1.weight", "classifier.1.bias". 
	Unexpected key(s) in state_dict: "block1.0.weight", "block1.1.weight", "block1.1.bias", "block1.1.running_mean", "block1.1.running_var", "block1.1.num_batches_tracked", "block2.0.weight", "block2.1.weight", "block2.1.bias", "block2.1.running_mean", "block2.1.running_var", "block2.1.num_batches_tracked", "block2.3.weight", "block2.4.weight", "block2.4.bias", "block2.4.running_mean", "block2.4.running_var", "block2.4.num_batches_tracked", "classifier.2.weight", "classifier.2.bias". 
2025-05-05 15:35:47,368 - WARNING - Fehler beim Laden der Klassennamen: string indices must be integers, not 'str'
2025-05-05 15:35:47,368 - INFO - Lade MicroPizzaNet Modell
2025-05-05 15:35:47,371 - ERROR - Fehler beim Laden des Modells: Error(s) in loading state_dict for ModularMicroPizzaNet:
	Missing key(s) in state_dict: "blocks.0.0.weight", "blocks.0.1.weight", "blocks.0.1.bias", "blocks.0.1.running_mean", "blocks.0.1.running_var", "blocks.1.0.weight", "blocks.1.1.weight", "blocks.1.1.bias", "blocks.1.1.running_mean", "blocks.1.1.running_var", "blocks.1.3.weight", "blocks.1.4.weight", "blocks.1.4.bias", "blocks.1.4.running_mean", "blocks.1.4.running_var", "blocks.2.0.weight", "blocks.2.1.weight", "blocks.2.1.bias", "blocks.2.1.running_mean", "blocks.2.1.running_var", "blocks.2.3.weight", "blocks.2.4.weight", "blocks.2.4.bias", "blocks.2.4.running_mean", "blocks.2.4.running_var", "classifier.1.weight", "classifier.1.bias". 
	Unexpected key(s) in state_dict: "block1.0.weight", "block1.1.weight", "block1.1.bias", "block1.1.running_mean", "block1.1.running_var", "block1.1.num_batches_tracked", "block2.0.weight", "block2.1.weight", "block2.1.bias", "block2.1.running_mean", "block2.1.running_var", "block2.1.num_batches_tracked", "block2.3.weight", "block2.4.weight", "block2.4.bias", "block2.4.running_mean", "block2.4.running_var", "block2.4.num_batches_tracked", "classifier.2.weight", "classifier.2.bias". 
2025-05-05 15:43:00,262 - INFO - Klassen geladen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-05 15:43:00,262 - INFO - Lade MicroPizzaNet Modell
2025-05-05 15:43:00,264 - ERROR - Fehler beim Laden des Modells: Error(s) in loading state_dict for OriginalMicroPizzaNet:
	Missing key(s) in state_dict: "block1.0.bias", "block2.0.bias", "block2.3.bias". 
	size mismatch for block2.0.weight: copying a param with shape torch.Size([8, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 1, 3, 3]).
	size mismatch for block2.1.weight: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([16]).
	size mismatch for block2.1.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([16]).
	size mismatch for block2.1.running_mean: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([16]).
	size mismatch for block2.1.running_var: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([16]).
	size mismatch for block2.3.weight: copying a param with shape torch.Size([16, 8, 1, 1]) from checkpoint, the shape in current model is torch.Size([16, 16, 1, 1]).
2025-05-05 15:44:24,660 - INFO - Klassen geladen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-05 15:44:24,661 - INFO - Lade MicroPizzaNet Modell
2025-05-05 15:45:29,487 - INFO - Klassen geladen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-05 15:45:29,487 - INFO - Lade MicroPizzaNet Modell
2025-05-05 15:45:29,490 - INFO - Modell aus models/micro_pizza_model.pth geladen
2025-05-05 15:45:29,490 - INFO - ================================================================================
2025-05-05 15:45:29,490 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-05 15:45:29,490 - INFO - ================================================================================
2025-05-05 15:45:29,490 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-05 15:45:29,490 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-05 15:45:29,490 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-05 15:45:29,490 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-05 15:45:29,490 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-05 15:45:29,490 - INFO - ================================================================================
2025-05-05 15:45:29,490 - INFO - Preparing optimized data loaders...
2025-05-05 15:46:57,432 - INFO - Klassen geladen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-05 15:46:57,432 - INFO - Lade MicroPizzaNet Modell
2025-05-05 15:46:57,435 - INFO - Modell aus models/micro_pizza_model.pth geladen
2025-05-05 15:46:57,435 - ERROR - Fehler beim Laden des Datensatzes: Found no valid file for the classes progression, segment. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp
2025-05-05 15:46:57,435 - ERROR - Erstelle einen Dummy-Datensatz für den Test
2025-05-05 15:46:57,435 - WARNING - Verwende Dummy-Datensatz! Die Ergebnisse sind nicht repräsentativ.
2025-05-05 15:46:57,440 - INFO - Automatisch ausgewählter Layer für Grad-CAM: Conv2d
2025-05-05 15:48:45,696 - INFO - Klassen geladen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-05 15:48:45,696 - INFO - Lade MicroPizzaNet Modell
2025-05-05 15:48:45,698 - INFO - Modell aus models/micro_pizza_model.pth geladen
2025-05-05 15:48:45,699 - ERROR - Fehler beim Laden des Datensatzes: Found no valid file for the classes progression, segment. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp
2025-05-05 15:48:45,699 - ERROR - Erstelle einen Dummy-Datensatz für den Test
2025-05-05 15:48:45,699 - WARNING - Verwende Dummy-Datensatz! Die Ergebnisse sind nicht repräsentativ.
2025-05-05 15:48:45,699 - INFO - Automatisch ausgewählter Layer für Grad-CAM: Conv2d
2025-05-05 15:48:45,758 - INFO - HTML-Bericht erstellt: output/gradcam_results/gradcam_report.html
2025-05-05 15:48:50,799 - INFO - GradCAM-Visualisierung abgeschlossen!
2025-05-05 15:48:50,800 - INFO - Ergebnisse gespeichert in: /home/emilio/Documents/ai/pizza/output/gradcam_results
2025-05-05 21:46:22,382 - INFO - ================================================================================
2025-05-05 21:46:22,382 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-05 21:46:22,382 - INFO - ================================================================================
2025-05-05 21:46:22,382 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-05 21:46:22,382 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-05 21:46:22,382 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-05 21:46:22,382 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-05 21:46:22,382 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-05 21:46:22,382 - INFO - ================================================================================
2025-05-05 21:46:22,382 - INFO - Lade Datensatz aus data
2025-05-05 21:46:22,382 - INFO - Analysiere Datensatz in data...
2025-05-05 21:46:22,417 - INFO - Datensatzanalyse abgeschlossen:
2025-05-05 21:46:22,418 - INFO - Gesamtzahl der Bilder: 1377
2025-05-05 21:46:22,418 - INFO - Klassenverteilung: {'videos': 0, 'synthetic': 1223, 'augmented': 142, 'raw': 12, 'classified': 0, 'processed': 0}
2025-05-05 21:46:22,418 - INFO - Durchschnittliche Bildgröße: 235.5 x 226.6
2025-05-05 21:46:22,418 - INFO - RGB-Mittelwerte: [0.2902, 0.2409, 0.2006]
2025-05-05 21:46:22,418 - INFO - RGB-Standardabweichungen: [0.3096, 0.2938, 0.2740]
2025-05-05 21:46:22,418 - INFO - Preparing optimized data loaders...
2025-05-05 21:46:22,418 - INFO - Using dataset-specific normalization: mean=[0.29017202 0.24085468 0.20059984], std=[0.3096061  0.29380828 0.27403119]
2025-05-05 21:46:22,421 - INFO - Data loaders created: 1101 training images, 276 validation images
2025-05-05 21:46:22,421 - INFO - Classes: ['augmented', 'classified', 'processed', 'raw', 'synthetic', 'videos']
2025-05-05 21:46:22,421 - INFO - Datensatz geladen: 6 Klassen
2025-05-05 21:46:22,421 - INFO - Erstelle Teacher-Modell (mobilenet)
2025-05-05 21:46:44,960 - INFO - ================================================================================
2025-05-05 21:46:44,960 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-05 21:46:44,960 - INFO - ================================================================================
2025-05-05 21:46:44,960 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-05 21:46:44,960 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-05 21:46:44,960 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-05 21:46:44,960 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-05 21:46:44,960 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-05 21:46:44,960 - INFO - ================================================================================
2025-05-05 21:46:44,960 - INFO - Lade Datensatz aus data
2025-05-05 21:46:44,961 - INFO - Analysiere Datensatz in data...
2025-05-05 21:46:44,993 - INFO - Datensatzanalyse abgeschlossen:
2025-05-05 21:46:44,993 - INFO - Gesamtzahl der Bilder: 1377
2025-05-05 21:46:44,993 - INFO - Klassenverteilung: {'videos': 0, 'synthetic': 1223, 'augmented': 142, 'raw': 12, 'classified': 0, 'processed': 0}
2025-05-05 21:46:44,993 - INFO - Durchschnittliche Bildgröße: 229.8 x 225.3
2025-05-05 21:46:44,993 - INFO - RGB-Mittelwerte: [0.2797, 0.2303, 0.2099]
2025-05-05 21:46:44,993 - INFO - RGB-Standardabweichungen: [0.2976, 0.2824, 0.2776]
2025-05-05 21:46:44,993 - INFO - Preparing optimized data loaders...
2025-05-05 21:46:44,993 - INFO - Using dataset-specific normalization: mean=[0.27969264 0.23033064 0.20986061], std=[0.29758076 0.28237676 0.27756683]
2025-05-05 21:46:44,995 - INFO - Data loaders created: 1101 training images, 276 validation images
2025-05-05 21:46:44,995 - INFO - Classes: ['augmented', 'classified', 'processed', 'raw', 'synthetic', 'videos']
2025-05-05 21:46:44,995 - INFO - Datensatz geladen: 6 Klassen
2025-05-05 21:46:44,995 - INFO - Erstelle Teacher-Modell (mobilenet)
2025-05-05 21:46:44,998 - WARNING - Kein Checkpoint gefunden. Teacher-Modell wird mit Standardgewichten initialisiert.
2025-05-05 21:46:44,998 - INFO - Erstelle Student-Modell (micropizza)
2025-05-05 21:46:44,999 - INFO - Starte Training mit Knowledge Distillation
2025-05-05 21:46:44,999 - INFO - Temperatur: 2.0, Alpha: 0.5
2025-05-05 23:35:39,474 - INFO - Starte Vergleich zwischen MicroPizzaNet und MicroPizzaNetV2
2025-05-05 23:35:39,475 - INFO - ================================================================================
2025-05-05 23:35:39,475 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-05 23:35:39,475 - INFO - ================================================================================
2025-05-05 23:35:39,475 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-05 23:35:39,475 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-05 23:35:39,475 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-05 23:35:39,475 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-05 23:35:39,475 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-05 23:35:39,475 - INFO - ================================================================================
2025-05-05 23:35:39,475 - INFO - Lade Datensatz aus data/augmented
2025-05-05 23:35:39,475 - INFO - Analysiere Datensatz in data/augmented...
2025-05-05 23:35:39,528 - INFO - Datensatzanalyse abgeschlossen:
2025-05-05 23:35:39,528 - INFO - Gesamtzahl der Bilder: 57
2025-05-05 23:35:39,528 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-05 23:35:39,528 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-05 23:35:39,528 - INFO - RGB-Mittelwerte: [0.4781, 0.3935, 0.3254]
2025-05-05 23:35:39,528 - INFO - RGB-Standardabweichungen: [0.2268, 0.2472, 0.2595]
2025-05-05 23:35:39,528 - INFO - Preparing optimized data loaders...
2025-05-05 23:35:39,528 - INFO - Using dataset-specific normalization: mean=[0.47809556 0.39354444 0.3253947 ], std=[0.22684293 0.24716978 0.2594598 ]
2025-05-05 23:35:39,531 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-05 23:35:39,531 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-05 23:35:39,535 - INFO - 
==================================================
Trainiere MicroPizzaNet (Original)
==================================================
2025-05-05 23:35:39,578 - INFO - Speicheranalyse:
2025-05-05 23:35:39,578 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-05 23:35:39,578 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-05 23:35:39,578 - INFO -   Aktivierungsspeicher: 101.46 KB
2025-05-05 23:35:39,579 - INFO -   Gesamter Laufzeitspeicher: 102.09 KB (38.7% des RAM)
2025-05-05 23:35:39,579 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.09KB > 100KB)
2025-05-05 23:35:39,579 - INFO - Modell hat 582 Parameter
2025-05-05 23:35:39,579 - INFO - Geschätzte Modellgröße: 2.54 KB (float32), 0.63 KB (int8)
2025-05-05 23:35:39,579 - INFO - Starte optimiertes Training für Mikrocontroller-Modell...
2025-05-05 23:35:39,579 - INFO - Speicheranalyse:
2025-05-05 23:35:39,580 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-05 23:35:39,580 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-05 23:35:39,580 - INFO -   Aktivierungsspeicher: 101.46 KB
2025-05-05 23:35:39,580 - INFO -   Gesamter Laufzeitspeicher: 102.09 KB (38.7% des RAM)
2025-05-05 23:35:39,580 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.09KB > 100KB)
2025-05-05 23:35:39,757 - INFO - Klassengewichte für Loss-Funktion: [0.58, 0.75, 0.47, 1.25, 1.0, 1.0]
2025-05-05 23:36:05,203 - INFO - Starte Vergleich zwischen MicroPizzaNet und MicroPizzaNetV2
2025-05-05 23:36:05,203 - INFO - ================================================================================
2025-05-05 23:36:05,203 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-05 23:36:05,203 - INFO - ================================================================================
2025-05-05 23:36:05,203 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-05 23:36:05,203 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-05 23:36:05,203 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-05 23:36:05,203 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-05 23:36:05,203 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-05 23:36:05,203 - INFO - ================================================================================
2025-05-05 23:36:05,203 - INFO - Lade Datensatz aus data/augmented
2025-05-05 23:36:05,203 - INFO - Analysiere Datensatz in data/augmented...
2025-05-05 23:36:05,241 - INFO - Datensatzanalyse abgeschlossen:
2025-05-05 23:36:05,241 - INFO - Gesamtzahl der Bilder: 57
2025-05-05 23:36:05,241 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-05 23:36:05,241 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-05 23:36:05,241 - INFO - RGB-Mittelwerte: [0.4794, 0.3970, 0.3326]
2025-05-05 23:36:05,241 - INFO - RGB-Standardabweichungen: [0.2325, 0.2494, 0.2632]
2025-05-05 23:36:05,241 - INFO - Preparing optimized data loaders...
2025-05-05 23:36:05,241 - INFO - Using dataset-specific normalization: mean=[0.47942234 0.39695834 0.33263576], std=[0.23246424 0.24936087 0.26318754]
2025-05-05 23:36:05,242 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-05 23:36:05,242 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-05 23:36:05,244 - INFO - 
==================================================
Trainiere MicroPizzaNet (Original)
==================================================
2025-05-05 23:36:05,246 - INFO - Speicheranalyse:
2025-05-05 23:36:05,247 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-05 23:36:05,247 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-05 23:36:05,247 - INFO -   Aktivierungsspeicher: 101.46 KB
2025-05-05 23:36:05,247 - INFO -   Gesamter Laufzeitspeicher: 102.09 KB (38.7% des RAM)
2025-05-05 23:36:05,247 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.09KB > 100KB)
2025-05-05 23:36:05,247 - INFO - Modell hat 582 Parameter
2025-05-05 23:36:05,247 - INFO - Geschätzte Modellgröße: 2.54 KB (float32), 0.63 KB (int8)
2025-05-05 23:36:05,247 - INFO - Starte optimiertes Training für Mikrocontroller-Modell...
2025-05-05 23:36:05,248 - INFO - Speicheranalyse:
2025-05-05 23:36:05,248 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-05 23:36:05,248 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-05 23:36:05,248 - INFO -   Aktivierungsspeicher: 101.46 KB
2025-05-05 23:36:05,248 - INFO -   Gesamter Laufzeitspeicher: 102.09 KB (38.7% des RAM)
2025-05-05 23:36:05,248 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.09KB > 100KB)
2025-05-05 23:36:05,401 - INFO - Klassengewichte für Loss-Funktion: [1.25, 0.36, 0.94, 0.75, 1.0, 1.0]
2025-05-05 23:36:45,750 - INFO - Starte Vergleich zwischen MicroPizzaNet und MicroPizzaNetV2
2025-05-05 23:36:45,751 - INFO - ================================================================================
2025-05-05 23:36:45,751 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-05 23:36:45,751 - INFO - ================================================================================
2025-05-05 23:36:45,751 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-05 23:36:45,751 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-05 23:36:45,751 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-05 23:36:45,751 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-05 23:36:45,751 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-05 23:36:45,751 - INFO - ================================================================================
2025-05-05 23:36:45,751 - INFO - Lade Datensatz aus data/augmented
2025-05-05 23:36:45,751 - INFO - Analysiere Datensatz in data/augmented...
2025-05-05 23:36:45,784 - INFO - Datensatzanalyse abgeschlossen:
2025-05-05 23:36:45,784 - INFO - Gesamtzahl der Bilder: 57
2025-05-05 23:36:45,784 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-05 23:36:45,784 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-05 23:36:45,784 - INFO - RGB-Mittelwerte: [0.4837, 0.4027, 0.3339]
2025-05-05 23:36:45,784 - INFO - RGB-Standardabweichungen: [0.2290, 0.2537, 0.2652]
2025-05-05 23:36:45,784 - INFO - Preparing optimized data loaders...
2025-05-05 23:36:45,784 - INFO - Using dataset-specific normalization: mean=[0.48365136 0.40266209 0.33387831], std=[0.22902512 0.25373903 0.26518313]
2025-05-05 23:36:45,786 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-05 23:36:45,786 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-05 23:36:45,787 - INFO - 
==================================================
Trainiere MicroPizzaNet (Original)
==================================================
2025-05-05 23:36:45,789 - INFO - Speicheranalyse:
2025-05-05 23:36:45,789 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-05 23:36:45,789 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-05 23:36:45,789 - INFO -   Aktivierungsspeicher: 101.46 KB
2025-05-05 23:36:45,789 - INFO -   Gesamter Laufzeitspeicher: 102.09 KB (38.7% des RAM)
2025-05-05 23:36:45,789 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.09KB > 100KB)
2025-05-05 23:36:45,789 - INFO - Modell hat 582 Parameter
2025-05-05 23:36:45,789 - INFO - Geschätzte Modellgröße: 2.54 KB (float32), 0.63 KB (int8)
2025-05-05 23:36:45,789 - INFO - Starte optimiertes Training für Mikrocontroller-Modell...
2025-05-05 23:36:45,790 - INFO - Speicheranalyse:
2025-05-05 23:36:45,790 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-05 23:36:45,790 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-05 23:36:45,790 - INFO -   Aktivierungsspeicher: 101.46 KB
2025-05-05 23:36:45,790 - INFO -   Gesamter Laufzeitspeicher: 102.09 KB (38.7% des RAM)
2025-05-05 23:36:45,790 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.09KB > 100KB)
2025-05-05 23:36:45,963 - INFO - Klassengewichte für Loss-Funktion: [1.5, 0.62, 0.54, 0.54, 1.0, 1.0]
2025-05-05 23:38:31,668 - INFO - Starte Vergleich zwischen MicroPizzaNet und MicroPizzaNetV2
2025-05-05 23:38:31,668 - INFO - ================================================================================
2025-05-05 23:38:31,668 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-05 23:38:31,668 - INFO - ================================================================================
2025-05-05 23:38:31,668 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-05 23:38:31,668 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-05 23:38:31,668 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-05 23:38:31,668 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-05 23:38:31,668 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-05 23:38:31,668 - INFO - ================================================================================
2025-05-05 23:38:31,668 - INFO - CUDA verfügbar, aber --force_cpu Option verwendet. Verwende CPU.
2025-05-05 23:38:31,668 - INFO - Lade Datensatz aus data/augmented
2025-05-05 23:38:31,669 - INFO - Analysiere Datensatz in data/augmented...
2025-05-05 23:38:31,703 - INFO - Datensatzanalyse abgeschlossen:
2025-05-05 23:38:31,703 - INFO - Gesamtzahl der Bilder: 57
2025-05-05 23:38:31,703 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-05 23:38:31,703 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-05 23:38:31,703 - INFO - RGB-Mittelwerte: [0.4891, 0.4074, 0.3386]
2025-05-05 23:38:31,703 - INFO - RGB-Standardabweichungen: [0.2343, 0.2532, 0.2687]
2025-05-05 23:38:31,703 - INFO - Preparing optimized data loaders...
2025-05-05 23:38:31,703 - INFO - Using dataset-specific normalization: mean=[0.48911953 0.40736471 0.33860643], std=[0.23429247 0.25320947 0.2686546 ]
2025-05-05 23:38:31,705 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-05 23:38:31,705 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-05 23:38:31,706 - INFO - 
==================================================
Trainiere MicroPizzaNet (Original)
==================================================
2025-05-05 23:38:31,708 - INFO - Speicheranalyse:
2025-05-05 23:38:31,708 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-05 23:38:31,708 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-05 23:38:31,708 - INFO -   Aktivierungsspeicher: 101.46 KB
2025-05-05 23:38:31,708 - INFO -   Gesamter Laufzeitspeicher: 102.09 KB (38.7% des RAM)
2025-05-05 23:38:31,708 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.09KB > 100KB)
2025-05-05 23:38:31,708 - INFO - Modell hat 582 Parameter
2025-05-05 23:38:31,708 - INFO - Geschätzte Modellgröße: 2.54 KB (float32), 0.63 KB (int8)
2025-05-05 23:38:31,708 - INFO - Starte optimiertes Training für Mikrocontroller-Modell...
2025-05-05 23:38:31,709 - INFO - Speicheranalyse:
2025-05-05 23:38:31,709 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-05 23:38:31,709 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-05 23:38:31,709 - INFO -   Aktivierungsspeicher: 101.46 KB
2025-05-05 23:38:31,709 - INFO -   Gesamter Laufzeitspeicher: 102.09 KB (38.7% des RAM)
2025-05-05 23:38:31,709 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.09KB > 100KB)
2025-05-05 23:38:31,873 - INFO - Klassengewichte für Loss-Funktion: [0.58, 0.83, 0.58, 0.75, 1.0, 1.0]
2025-05-05 23:38:32,047 - INFO - Epoch 1/10 - Train Loss: 1.7979, Train Acc: 4.44% - Val Loss: 1.7933, Val Acc: 8.33%
2025-05-05 23:38:32,047 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:38:32,047 - INFO -   basic: 0.00% (0/8)
2025-05-05 23:38:32,047 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:38:32,047 - INFO -   mixed: 100.00% (1/1)
2025-05-05 23:38:32,050 - INFO - Checkpoint gespeichert: models_optimized/micropizzanet_(original)_epoch1.pth
2025-05-05 23:38:32,158 - INFO - Epoch 2/10 - Train Loss: 1.7868, Train Acc: 20.00% - Val Loss: 1.7958, Val Acc: 8.33%
2025-05-05 23:38:32,158 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:38:32,158 - INFO -   basic: 0.00% (0/8)
2025-05-05 23:38:32,158 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:38:32,158 - INFO -   mixed: 100.00% (1/1)
2025-05-05 23:38:32,158 - INFO - EarlyStopping counter: 1/10
2025-05-05 23:38:32,278 - INFO - Epoch 3/10 - Train Loss: 1.7771, Train Acc: 24.44% - Val Loss: 1.7938, Val Acc: 8.33%
2025-05-05 23:38:32,278 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:38:32,278 - INFO -   basic: 0.00% (0/8)
2025-05-05 23:38:32,279 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:38:32,279 - INFO -   mixed: 100.00% (1/1)
2025-05-05 23:38:32,279 - INFO - EarlyStopping counter: 2/10
2025-05-05 23:38:32,430 - INFO - Epoch 4/10 - Train Loss: 1.7322, Train Acc: 37.78% - Val Loss: 1.7845, Val Acc: 0.00%
2025-05-05 23:38:32,431 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:38:32,431 - INFO -   basic: 0.00% (0/8)
2025-05-05 23:38:32,431 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:38:32,431 - INFO -   mixed: 0.00% (0/1)
2025-05-05 23:38:32,572 - INFO - Epoch 5/10 - Train Loss: 1.7181, Train Acc: 28.89% - Val Loss: 1.7704, Val Acc: 0.00%
2025-05-05 23:38:32,572 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:38:32,572 - INFO -   basic: 0.00% (0/8)
2025-05-05 23:38:32,572 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:38:32,572 - INFO -   mixed: 0.00% (0/1)
2025-05-05 23:38:32,574 - INFO - Checkpoint gespeichert: models_optimized/micropizzanet_(original)_epoch5.pth
2025-05-05 23:38:32,693 - INFO - Epoch 6/10 - Train Loss: 1.6757, Train Acc: 28.89% - Val Loss: 1.7612, Val Acc: 0.00%
2025-05-05 23:38:32,693 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:38:32,694 - INFO -   basic: 0.00% (0/8)
2025-05-05 23:38:32,694 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:38:32,694 - INFO -   mixed: 0.00% (0/1)
2025-05-05 23:38:32,815 - INFO - Epoch 7/10 - Train Loss: 1.6419, Train Acc: 31.11% - Val Loss: 1.7540, Val Acc: 0.00%
2025-05-05 23:38:32,815 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:38:32,815 - INFO -   basic: 0.00% (0/8)
2025-05-05 23:38:32,815 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:38:32,816 - INFO -   mixed: 0.00% (0/1)
2025-05-05 23:38:32,953 - INFO - Epoch 8/10 - Train Loss: 1.6330, Train Acc: 26.67% - Val Loss: 1.7508, Val Acc: 0.00%
2025-05-05 23:38:32,953 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:38:32,953 - INFO -   basic: 0.00% (0/8)
2025-05-05 23:38:32,953 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:38:32,953 - INFO -   mixed: 0.00% (0/1)
2025-05-05 23:38:33,074 - INFO - Epoch 9/10 - Train Loss: 1.6287, Train Acc: 24.44% - Val Loss: 1.7492, Val Acc: 0.00%
2025-05-05 23:38:33,074 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:38:33,074 - INFO -   basic: 0.00% (0/8)
2025-05-05 23:38:33,074 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:38:33,074 - INFO -   mixed: 0.00% (0/1)
2025-05-05 23:38:33,199 - INFO - Epoch 10/10 - Train Loss: 1.6096, Train Acc: 28.89% - Val Loss: 1.7490, Val Acc: 0.00%
2025-05-05 23:38:33,199 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:38:33,199 - INFO -   basic: 0.00% (0/8)
2025-05-05 23:38:33,199 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:38:33,199 - INFO -   mixed: 0.00% (0/1)
2025-05-05 23:38:33,199 - INFO - EarlyStopping counter: 1/10
2025-05-05 23:38:33,200 - INFO - Checkpoint gespeichert: models_optimized/micropizzanet_(original)_epoch10.pth
2025-05-05 23:38:33,200 - INFO - Training abgeschlossen in 1.33 Sekunden
2025-05-05 23:38:33,201 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 23:38:33,202 - INFO - Modell gespeichert als: models_optimized/micropizzanet_(original).pth
2025-05-05 23:38:33,202 - INFO - Starte detaillierte Modellevaluierung...
2025-05-05 23:38:33,269 - INFO - 
==================================================
2025-05-05 23:38:33,269 - INFO - DETAILLIERTE EVALUIERUNG
2025-05-05 23:38:33,269 - INFO - ==================================================
2025-05-05 23:38:33,269 - INFO - Gesamtgenauigkeit: 0.00%
2025-05-05 23:38:33,270 - INFO - Makro-Präzision: 0.0000
2025-05-05 23:38:33,270 - INFO - Makro-Recall: 0.0000
2025-05-05 23:38:33,270 - INFO - Makro-F1: 0.0000
2025-05-05 23:38:33,270 - INFO - Mikro-F1 (Genauigkeit): 0.0000
2025-05-05 23:38:33,270 - INFO - 
Klassenweise Leistung:
2025-05-05 23:38:33,270 - INFO - Klasse          Precision  Recall     F1         Support
2025-05-05 23:38:33,270 - INFO - ------------------------------------------------------------
2025-05-05 23:38:33,270 - INFO - basic           0.0000      0.0000      0.0000      8
2025-05-05 23:38:33,270 - INFO - burnt           0.0000      0.0000      0.0000      0
2025-05-05 23:38:33,270 - INFO - combined        0.0000      0.0000      0.0000      3
2025-05-05 23:38:33,271 - INFO - mixed           0.0000      0.0000      0.0000      1
2025-05-05 23:38:33,271 - INFO - progression     0.0000      0.0000      0.0000      0
2025-05-05 23:38:33,271 - INFO - segment         0.0000      0.0000      0.0000      0
2025-05-05 23:38:33,271 - INFO - 
Top-5 häufigste Fehler:
2025-05-05 23:38:33,271 - INFO - 1. basic als burnt klassifiziert: 8 Fälle
2025-05-05 23:38:33,271 - INFO - 2. combined als burnt klassifiziert: 3 Fälle
2025-05-05 23:38:33,271 - INFO - 3. mixed als burnt klassifiziert: 1 Fälle
2025-05-05 23:38:33,271 - INFO - 
Konfusionsmatrix:
2025-05-05 23:38:33,272 - INFO -     0     8     0     0     0     0
    0     0     0     0     0     0
    0     3     0     0     0     0
    0     1     0     0     0     0
    0     0     0     0     0     0
    0     0     0     0     0     0
2025-05-05 23:38:33,273 - INFO - 
Vollständiger Evaluierungsbericht gespeichert: models_optimized/evaluation_report.json
2025-05-05 23:38:33,327 - INFO - Modell gespeichert unter: output/inverted_residual_comparison/models/micropizzanet_(original).pth
2025-05-05 23:41:09,609 - INFO - Starte Vergleich zwischen MicroPizzaNet und MicroPizzaNetV2
2025-05-05 23:41:09,609 - INFO - ================================================================================
2025-05-05 23:41:09,609 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-05 23:41:09,609 - INFO - ================================================================================
2025-05-05 23:41:09,609 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-05 23:41:09,609 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-05 23:41:09,609 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-05 23:41:09,609 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-05 23:41:09,609 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-05 23:41:09,609 - INFO - ================================================================================
2025-05-05 23:41:09,610 - INFO - CUDA verfügbar, aber --force_cpu Option verwendet. Verwende CPU.
2025-05-05 23:41:09,610 - INFO - Lade Datensatz aus data/augmented
2025-05-05 23:41:09,610 - INFO - Analysiere Datensatz in data/augmented...
2025-05-05 23:41:09,644 - INFO - Datensatzanalyse abgeschlossen:
2025-05-05 23:41:09,644 - INFO - Gesamtzahl der Bilder: 57
2025-05-05 23:41:09,644 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-05 23:41:09,644 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-05 23:41:09,644 - INFO - RGB-Mittelwerte: [0.4832, 0.3983, 0.3324]
2025-05-05 23:41:09,644 - INFO - RGB-Standardabweichungen: [0.2382, 0.2534, 0.2657]
2025-05-05 23:41:09,644 - INFO - Preparing optimized data loaders...
2025-05-05 23:41:09,645 - INFO - Using dataset-specific normalization: mean=[0.48323307 0.39832191 0.3323894 ], std=[0.238161   0.25344186 0.26572448]
2025-05-05 23:41:09,646 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-05 23:41:09,646 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-05 23:41:09,648 - INFO - 
==================================================
Trainiere MicroPizzaNet (Original)
==================================================
2025-05-05 23:41:09,650 - INFO - Speicheranalyse:
2025-05-05 23:41:09,650 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-05 23:41:09,650 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-05 23:41:09,650 - INFO -   Aktivierungsspeicher: 101.46 KB
2025-05-05 23:41:09,650 - INFO -   Gesamter Laufzeitspeicher: 102.09 KB (38.7% des RAM)
2025-05-05 23:41:09,650 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.09KB > 100KB)
2025-05-05 23:41:09,650 - INFO - Modell hat 582 Parameter
2025-05-05 23:41:09,650 - INFO - Geschätzte Modellgröße: 2.54 KB (float32), 0.63 KB (int8)
2025-05-05 23:41:09,650 - INFO - Starte optimiertes Training für Mikrocontroller-Modell...
2025-05-05 23:41:09,651 - INFO - Speicheranalyse:
2025-05-05 23:41:09,651 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-05 23:41:09,651 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-05 23:41:09,651 - INFO -   Aktivierungsspeicher: 101.46 KB
2025-05-05 23:41:09,651 - INFO -   Gesamter Laufzeitspeicher: 102.09 KB (38.7% des RAM)
2025-05-05 23:41:09,651 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.09KB > 100KB)
2025-05-05 23:41:09,820 - INFO - Klassengewichte für Loss-Funktion: [0.83, 0.5, 0.54, 1.07, 1.0, 1.0]
2025-05-05 23:41:09,947 - INFO - Epoch 1/10 - Train Loss: 1.7832, Train Acc: 22.22% - Val Loss: 1.7877, Val Acc: 66.67%
2025-05-05 23:41:09,947 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:09,947 - INFO -   basic: 100.00% (8/8)
2025-05-05 23:41:09,948 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:41:09,948 - INFO -   mixed: 0.00% (0/1)
2025-05-05 23:41:09,950 - INFO - Checkpoint gespeichert: models_optimized/micropizzanet_(original)_epoch1.pth
2025-05-05 23:41:10,068 - INFO - Epoch 2/10 - Train Loss: 1.7782, Train Acc: 20.00% - Val Loss: 1.7814, Val Acc: 66.67%
2025-05-05 23:41:10,068 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:10,068 - INFO -   basic: 100.00% (8/8)
2025-05-05 23:41:10,068 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:41:10,068 - INFO -   mixed: 0.00% (0/1)
2025-05-05 23:41:10,219 - INFO - Epoch 3/10 - Train Loss: 1.7459, Train Acc: 33.33% - Val Loss: 1.7711, Val Acc: 66.67%
2025-05-05 23:41:10,219 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:10,219 - INFO -   basic: 87.50% (7/8)
2025-05-05 23:41:10,219 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:41:10,219 - INFO -   mixed: 100.00% (1/1)
2025-05-05 23:41:10,398 - INFO - Epoch 4/10 - Train Loss: 1.7271, Train Acc: 22.22% - Val Loss: 1.7535, Val Acc: 33.33%
2025-05-05 23:41:10,399 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:10,399 - INFO -   basic: 37.50% (3/8)
2025-05-05 23:41:10,399 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:41:10,399 - INFO -   mixed: 100.00% (1/1)
2025-05-05 23:41:10,539 - INFO - Epoch 5/10 - Train Loss: 1.6691, Train Acc: 26.67% - Val Loss: 1.7300, Val Acc: 33.33%
2025-05-05 23:41:10,539 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:10,539 - INFO -   basic: 37.50% (3/8)
2025-05-05 23:41:10,540 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:41:10,540 - INFO -   mixed: 100.00% (1/1)
2025-05-05 23:41:10,542 - INFO - Checkpoint gespeichert: models_optimized/micropizzanet_(original)_epoch5.pth
2025-05-05 23:41:10,661 - INFO - Epoch 6/10 - Train Loss: 1.6508, Train Acc: 22.22% - Val Loss: 1.7064, Val Acc: 25.00%
2025-05-05 23:41:10,661 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:10,661 - INFO -   basic: 25.00% (2/8)
2025-05-05 23:41:10,661 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:41:10,661 - INFO -   mixed: 100.00% (1/1)
2025-05-05 23:41:10,791 - INFO - Epoch 7/10 - Train Loss: 1.6345, Train Acc: 26.67% - Val Loss: 1.6855, Val Acc: 25.00%
2025-05-05 23:41:10,792 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:10,792 - INFO -   basic: 25.00% (2/8)
2025-05-05 23:41:10,792 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:41:10,792 - INFO -   mixed: 100.00% (1/1)
2025-05-05 23:41:10,961 - INFO - Epoch 8/10 - Train Loss: 1.6090, Train Acc: 33.33% - Val Loss: 1.6640, Val Acc: 16.67%
2025-05-05 23:41:10,961 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:10,961 - INFO -   basic: 12.50% (1/8)
2025-05-05 23:41:10,961 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:41:10,961 - INFO -   mixed: 100.00% (1/1)
2025-05-05 23:41:11,104 - INFO - Epoch 9/10 - Train Loss: 1.5809, Train Acc: 33.33% - Val Loss: 1.6527, Val Acc: 16.67%
2025-05-05 23:41:11,104 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:11,104 - INFO -   basic: 12.50% (1/8)
2025-05-05 23:41:11,105 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:41:11,105 - INFO -   mixed: 100.00% (1/1)
2025-05-05 23:41:11,259 - INFO - Epoch 10/10 - Train Loss: 1.6120, Train Acc: 22.22% - Val Loss: 1.6406, Val Acc: 16.67%
2025-05-05 23:41:11,259 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:11,260 - INFO -   basic: 12.50% (1/8)
2025-05-05 23:41:11,260 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:41:11,260 - INFO -   mixed: 100.00% (1/1)
2025-05-05 23:41:11,264 - INFO - Checkpoint gespeichert: models_optimized/micropizzanet_(original)_epoch10.pth
2025-05-05 23:41:11,264 - INFO - Training abgeschlossen in 1.44 Sekunden
2025-05-05 23:41:11,265 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 23:41:11,266 - INFO - Modell gespeichert als: models_optimized/micropizzanet_(original).pth
2025-05-05 23:41:11,266 - INFO - Starte detaillierte Modellevaluierung...
2025-05-05 23:41:11,329 - INFO - 
==================================================
2025-05-05 23:41:11,330 - INFO - DETAILLIERTE EVALUIERUNG
2025-05-05 23:41:11,330 - INFO - ==================================================
2025-05-05 23:41:11,330 - INFO - Gesamtgenauigkeit: 16.67%
2025-05-05 23:41:11,330 - INFO - Makro-Präzision: 0.1818
2025-05-05 23:41:11,330 - INFO - Makro-Recall: 0.1875
2025-05-05 23:41:11,330 - INFO - Makro-F1: 0.0648
2025-05-05 23:41:11,330 - INFO - Mikro-F1 (Genauigkeit): 0.1667
2025-05-05 23:41:11,330 - INFO - 
Klassenweise Leistung:
2025-05-05 23:41:11,330 - INFO - Klasse          Precision  Recall     F1         Support
2025-05-05 23:41:11,330 - INFO - ------------------------------------------------------------
2025-05-05 23:41:11,330 - INFO - basic           1.0000      0.1250      0.2222      8
2025-05-05 23:41:11,330 - INFO - burnt           0.0000      0.0000      0.0000      0
2025-05-05 23:41:11,331 - INFO - combined        0.0000      0.0000      0.0000      3
2025-05-05 23:41:11,331 - INFO - mixed           0.0909      1.0000      0.1667      1
2025-05-05 23:41:11,331 - INFO - progression     0.0000      0.0000      0.0000      0
2025-05-05 23:41:11,331 - INFO - segment         0.0000      0.0000      0.0000      0
2025-05-05 23:41:11,331 - INFO - 
Top-5 häufigste Fehler:
2025-05-05 23:41:11,331 - INFO - 1. basic als mixed klassifiziert: 7 Fälle
2025-05-05 23:41:11,331 - INFO - 2. combined als mixed klassifiziert: 3 Fälle
2025-05-05 23:41:11,331 - INFO - 
Konfusionsmatrix:
2025-05-05 23:41:11,331 - INFO -     1     0     0     7     0     0
    0     0     0     0     0     0
    0     0     0     3     0     0
    0     0     0     1     0     0
    0     0     0     0     0     0
    0     0     0     0     0     0
2025-05-05 23:41:11,332 - INFO - 
Vollständiger Evaluierungsbericht gespeichert: models_optimized/evaluation_report.json
2025-05-05 23:41:11,363 - INFO - Modell gespeichert unter: output/inverted_residual_comparison/models/micropizzanet_(original).pth
2025-05-05 23:41:11,795 - INFO - 
==================================================
Trainiere MicroPizzaNetV2 (Inverted Residual)
==================================================
2025-05-05 23:41:11,798 - INFO - Speicheranalyse:
2025-05-05 23:41:11,798 - INFO -   Modellgröße (Float32): 9.32 KB
2025-05-05 23:41:11,798 - INFO -   Modellgröße (Int8): 2.33 KB (0.1% des Flash)
2025-05-05 23:41:11,798 - INFO -   Aktivierungsspeicher: 164.46 KB
2025-05-05 23:41:11,798 - INFO -   Gesamter Laufzeitspeicher: 166.79 KB (63.2% des RAM)
2025-05-05 23:41:11,798 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (166.79KB > 100KB)
2025-05-05 23:41:11,798 - INFO - Modell hat 2,142 Parameter
2025-05-05 23:41:11,798 - INFO - Geschätzte Modellgröße: 9.32 KB (float32), 2.33 KB (int8)
2025-05-05 23:41:11,798 - INFO - Starte optimiertes Training für Mikrocontroller-Modell...
2025-05-05 23:41:11,801 - INFO - Speicheranalyse:
2025-05-05 23:41:11,801 - INFO -   Modellgröße (Float32): 9.32 KB
2025-05-05 23:41:11,801 - INFO -   Modellgröße (Int8): 2.33 KB (0.1% des Flash)
2025-05-05 23:41:11,801 - INFO -   Aktivierungsspeicher: 164.46 KB
2025-05-05 23:41:11,801 - INFO -   Gesamter Laufzeitspeicher: 166.79 KB (63.2% des RAM)
2025-05-05 23:41:11,801 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (166.79KB > 100KB)
2025-05-05 23:41:11,862 - INFO - Klassengewichte für Loss-Funktion: [0.47, 0.75, 0.83, 0.75, 1.0, 1.0]
2025-05-05 23:41:11,987 - INFO - Epoch 1/10 - Train Loss: 1.7904, Train Acc: 13.33% - Val Loss: 1.7882, Val Acc: 0.00%
2025-05-05 23:41:11,987 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:11,987 - INFO -   basic: 0.00% (0/8)
2025-05-05 23:41:11,987 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:41:11,987 - INFO -   mixed: 0.00% (0/1)
2025-05-05 23:41:12,115 - INFO - Epoch 2/10 - Train Loss: 1.7894, Train Acc: 15.56% - Val Loss: 1.7865, Val Acc: 0.00%
2025-05-05 23:41:12,115 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:12,115 - INFO -   basic: 0.00% (0/8)
2025-05-05 23:41:12,115 - INFO -   combined: 0.00% (0/3)
2025-05-05 23:41:12,115 - INFO -   mixed: 0.00% (0/1)
2025-05-05 23:41:12,244 - INFO - Epoch 3/10 - Train Loss: 1.7875, Train Acc: 20.00% - Val Loss: 1.7853, Val Acc: 8.33%
2025-05-05 23:41:12,244 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:12,244 - INFO -   basic: 0.00% (0/8)
2025-05-05 23:41:12,244 - INFO -   combined: 33.33% (1/3)
2025-05-05 23:41:12,244 - INFO -   mixed: 0.00% (0/1)
2025-05-05 23:41:12,245 - INFO - Checkpoint gespeichert: models_optimized/micropizzanetv2_(inverted_residual)_epoch3.pth
2025-05-05 23:41:12,367 - INFO - Epoch 4/10 - Train Loss: 1.7695, Train Acc: 48.89% - Val Loss: 1.7808, Val Acc: 8.33%
2025-05-05 23:41:12,367 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:12,367 - INFO -   basic: 0.00% (0/8)
2025-05-05 23:41:12,367 - INFO -   combined: 33.33% (1/3)
2025-05-05 23:41:12,367 - INFO -   mixed: 0.00% (0/1)
2025-05-05 23:41:12,506 - INFO - Epoch 5/10 - Train Loss: 1.7657, Train Acc: 53.33% - Val Loss: 1.7746, Val Acc: 58.33%
2025-05-05 23:41:12,506 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:12,506 - INFO -   basic: 75.00% (6/8)
2025-05-05 23:41:12,507 - INFO -   combined: 33.33% (1/3)
2025-05-05 23:41:12,507 - INFO -   mixed: 0.00% (0/1)
2025-05-05 23:41:12,509 - INFO - Checkpoint gespeichert: models_optimized/micropizzanetv2_(inverted_residual)_epoch5.pth
2025-05-05 23:41:12,637 - INFO - Epoch 6/10 - Train Loss: 1.7460, Train Acc: 46.67% - Val Loss: 1.7679, Val Acc: 58.33%
2025-05-05 23:41:12,637 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:12,637 - INFO -   basic: 75.00% (6/8)
2025-05-05 23:41:12,637 - INFO -   combined: 33.33% (1/3)
2025-05-05 23:41:12,637 - INFO -   mixed: 0.00% (0/1)
2025-05-05 23:41:12,760 - INFO - Epoch 7/10 - Train Loss: 1.7350, Train Acc: 53.33% - Val Loss: 1.7628, Val Acc: 58.33%
2025-05-05 23:41:12,760 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:12,760 - INFO -   basic: 62.50% (5/8)
2025-05-05 23:41:12,760 - INFO -   combined: 33.33% (1/3)
2025-05-05 23:41:12,760 - INFO -   mixed: 100.00% (1/1)
2025-05-05 23:41:12,889 - INFO - Epoch 8/10 - Train Loss: 1.7293, Train Acc: 53.33% - Val Loss: 1.7602, Val Acc: 50.00%
2025-05-05 23:41:12,889 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:12,889 - INFO -   basic: 50.00% (4/8)
2025-05-05 23:41:12,890 - INFO -   combined: 33.33% (1/3)
2025-05-05 23:41:12,890 - INFO -   mixed: 100.00% (1/1)
2025-05-05 23:41:13,021 - INFO - Epoch 9/10 - Train Loss: 1.7229, Train Acc: 44.44% - Val Loss: 1.7604, Val Acc: 50.00%
2025-05-05 23:41:13,021 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:13,021 - INFO -   basic: 50.00% (4/8)
2025-05-05 23:41:13,021 - INFO -   combined: 33.33% (1/3)
2025-05-05 23:41:13,021 - INFO -   mixed: 100.00% (1/1)
2025-05-05 23:41:13,021 - INFO - EarlyStopping counter: 1/10
2025-05-05 23:41:13,152 - INFO - Epoch 10/10 - Train Loss: 1.7150, Train Acc: 42.22% - Val Loss: 1.7618, Val Acc: 50.00%
2025-05-05 23:41:13,152 - INFO - Klassenweise Genauigkeiten:
2025-05-05 23:41:13,152 - INFO -   basic: 50.00% (4/8)
2025-05-05 23:41:13,152 - INFO -   combined: 33.33% (1/3)
2025-05-05 23:41:13,152 - INFO -   mixed: 100.00% (1/1)
2025-05-05 23:41:13,152 - INFO - EarlyStopping counter: 2/10
2025-05-05 23:41:13,153 - INFO - Checkpoint gespeichert: models_optimized/micropizzanetv2_(inverted_residual)_epoch10.pth
2025-05-05 23:41:13,153 - INFO - Training abgeschlossen in 1.29 Sekunden
2025-05-05 23:41:13,154 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-05 23:41:13,154 - INFO - Modell gespeichert als: models_optimized/micropizzanetv2_(inverted_residual).pth
2025-05-05 23:41:13,155 - INFO - Starte detaillierte Modellevaluierung...
2025-05-05 23:41:13,207 - INFO - 
==================================================
2025-05-05 23:41:13,207 - INFO - DETAILLIERTE EVALUIERUNG
2025-05-05 23:41:13,207 - INFO - ==================================================
2025-05-05 23:41:13,207 - INFO - Gesamtgenauigkeit: 50.00%
2025-05-05 23:41:13,207 - INFO - Makro-Präzision: 0.2306
2025-05-05 23:41:13,207 - INFO - Makro-Recall: 0.3056
2025-05-05 23:41:13,207 - INFO - Makro-F1: 0.2248
2025-05-05 23:41:13,207 - INFO - Mikro-F1 (Genauigkeit): 0.5000
2025-05-05 23:41:13,207 - INFO - 
Klassenweise Leistung:
2025-05-05 23:41:13,207 - INFO - Klasse          Precision  Recall     F1         Support
2025-05-05 23:41:13,207 - INFO - ------------------------------------------------------------
2025-05-05 23:41:13,207 - INFO - basic           0.8000      0.5000      0.6154      8
2025-05-05 23:41:13,207 - INFO - burnt           0.0000      0.0000      0.0000      0
2025-05-05 23:41:13,207 - INFO - combined        0.3333      0.3333      0.3333      3
2025-05-05 23:41:13,207 - INFO - mixed           0.2500      1.0000      0.4000      1
2025-05-05 23:41:13,207 - INFO - progression     0.0000      0.0000      0.0000      0
2025-05-05 23:41:13,207 - INFO - segment         0.0000      0.0000      0.0000      0
2025-05-05 23:41:13,207 - INFO - 
Top-5 häufigste Fehler:
2025-05-05 23:41:13,207 - INFO - 1. basic als mixed klassifiziert: 2 Fälle
2025-05-05 23:41:13,207 - INFO - 2. basic als combined klassifiziert: 2 Fälle
2025-05-05 23:41:13,207 - INFO - 3. combined als basic klassifiziert: 1 Fälle
2025-05-05 23:41:13,207 - INFO - 4. combined als mixed klassifiziert: 1 Fälle
2025-05-05 23:41:13,207 - INFO - 
Konfusionsmatrix:
2025-05-05 23:41:13,207 - INFO -     4     0     2     2     0     0
    0     0     0     0     0     0
    1     0     1     1     0     0
    0     0     0     1     0     0
    0     0     0     0     0     0
    0     0     0     0     0     0
2025-05-05 23:41:13,208 - INFO - 
Vollständiger Evaluierungsbericht gespeichert: models_optimized/evaluation_report.json
2025-05-05 23:41:13,234 - INFO - Modell gespeichert unter: output/inverted_residual_comparison/models/micropizzanetv2_(inverted_residual).pth
2025-05-05 23:41:14,145 - INFO - 
==================================================
2025-05-05 23:41:14,145 - INFO - ZUSAMMENFASSUNG DES ARCHITEKTURVERGLEICHS
2025-05-05 23:41:14,145 - INFO - ==================================================
2025-05-05 23:41:14,145 - INFO - MicroPizzaNet (Original):
2025-05-05 23:41:14,145 - INFO - - Genauigkeit: 16.67%
2025-05-05 23:41:14,145 - INFO - - F1-Score: 0.065
2025-05-05 23:41:14,145 - INFO - - Parameter: 582
2025-05-05 23:41:14,145 - INFO - - Modellgröße (Int8): 0.6 KB
2025-05-05 23:41:14,145 - INFO - - Inferenzzeit auf RP2040: 2.5 ms
2025-05-05 23:41:14,145 - INFO - - FPS auf RP2040: 400.4
2025-05-05 23:41:14,145 - INFO - - Spitzen-RAM-Nutzung: 102.1 KB
2025-05-05 23:41:14,145 - INFO - 
2025-05-05 23:41:14,145 - INFO - MicroPizzaNetV2 (Inverted Residual):
2025-05-05 23:41:14,145 - INFO - - Genauigkeit: 50.00%
2025-05-05 23:41:14,145 - INFO - - F1-Score: 0.225
2025-05-05 23:41:14,145 - INFO - - Parameter: 2,142
2025-05-05 23:41:14,145 - INFO - - Modellgröße (Int8): 2.3 KB
2025-05-05 23:41:14,145 - INFO - - Inferenzzeit auf RP2040: 2.3 ms
2025-05-05 23:41:14,146 - INFO - - FPS auf RP2040: 441.3
2025-05-05 23:41:14,146 - INFO - - Spitzen-RAM-Nutzung: 166.8 KB
2025-05-05 23:41:14,146 - INFO - 
2025-05-05 23:41:14,146 - INFO - MicroPizzaNetV2 im Vergleich zu MicroPizzaNet:
2025-05-05 23:41:14,146 - INFO - - Genauigkeit: +200.0%
2025-05-05 23:41:14,146 - INFO - - F1-Score: +246.8%
2025-05-05 23:41:14,146 - INFO - - Modellgröße: +267.6%
2025-05-05 23:41:14,146 - INFO - - Inferenzgeschwindigkeit: -9.3%
2025-05-05 23:41:14,146 - INFO - - RAM-Nutzung: +63.4%
2025-05-05 23:41:14,146 - INFO - 
Ergebnisse wurden gespeichert in:
2025-05-05 23:41:14,146 - INFO - - HTML-Bericht: output/inverted_residual_comparison/comparison_report.html
2025-05-05 23:41:14,146 - INFO - - Plots: output/inverted_residual_comparison/plots
2025-05-05 23:41:14,146 - INFO - - Modelle: output/inverted_residual_comparison/models
2025-05-05 23:41:14,146 - INFO - - Detailergebnisse: output/inverted_residual_comparison/comparison_results.json
2025-05-06 00:00:14,896 - INFO - Verwende Gerät: cuda
2025-05-06 00:00:14,896 - INFO - ================================================================================
2025-05-06 00:00:14,896 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 00:00:14,896 - INFO - ================================================================================
2025-05-06 00:00:14,896 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 00:00:14,896 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 00:00:14,896 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 00:00:14,896 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 00:00:14,896 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 00:00:14,896 - INFO - ================================================================================
2025-05-06 00:00:14,896 - INFO - Preparing optimized data loaders...
2025-05-06 00:00:43,991 - INFO - Verwende Gerät: cuda
2025-05-06 00:00:43,991 - INFO - ================================================================================
2025-05-06 00:00:43,991 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 00:00:43,991 - INFO - ================================================================================
2025-05-06 00:00:43,991 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 00:00:43,991 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 00:00:43,991 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 00:00:43,991 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 00:00:43,991 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 00:00:43,991 - INFO - ================================================================================
2025-05-06 00:00:43,991 - INFO - Preparing optimized data loaders...
2025-05-06 00:04:34,541 - INFO - Verwende Gerät: cuda
2025-05-06 00:04:34,541 - INFO - ================================================================================
2025-05-06 00:04:34,541 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 00:04:34,541 - INFO - ================================================================================
2025-05-06 00:04:34,541 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 00:04:34,541 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 00:04:34,541 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 00:04:34,541 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 00:04:34,541 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 00:04:34,541 - INFO - ================================================================================
2025-05-06 00:04:34,541 - INFO - Preparing optimized data loaders...
2025-05-06 00:04:34,541 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 00:04:34,579 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 00:04:34,580 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 00:04:34,580 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 00:04:34,580 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 00:04:34,580 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 00:04:34,580 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 00:04:34,580 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 00:04:34,581 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 00:04:34,581 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 00:04:34,581 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 00:04:34,581 - INFO - Lade Teacher-Modell von models/micro_pizza_model.pth
2025-05-06 00:04:34,701 - INFO - Konnte nicht als MicroPizzaNetV2 laden: Error(s) in loading state_dict for MicroPizzaNetV2:
	Missing key(s) in state_dict: "block2.conv.0.weight", "block2.conv.1.weight", "block2.conv.1.bias", "block2.conv.1.running_mean", "block2.conv.1.running_var", "block2.conv.3.weight", "block2.conv.4.weight", "block2.conv.4.bias", "block2.conv.4.running_mean", "block2.conv.4.running_var", "block2.conv.6.weight", "block2.conv.7.weight", "block2.conv.7.bias", "block2.conv.7.running_mean", "block2.conv.7.running_var". 
	Unexpected key(s) in state_dict: "block2.0.weight", "block2.1.weight", "block2.1.bias", "block2.1.running_mean", "block2.1.running_var", "block2.1.num_batches_tracked", "block2.3.weight", "block2.4.weight", "block2.4.bias", "block2.4.running_mean", "block2.4.running_var", "block2.4.num_batches_tracked". 
2025-05-06 00:04:34,701 - INFO - Versuche als MicroPizzaNet zu laden
2025-05-06 00:04:34,704 - INFO - Teacher-Modell als MicroPizzaNet geladen
2025-05-06 00:04:34,706 - INFO - Student-Modell: CustomMicroPizzaNet (extra klein)
2025-05-06 00:04:34,706 - INFO - Teacher-Modell: 0 Parameter
2025-05-06 00:04:34,706 - INFO - Student-Modell: 414 Parameter
2025-05-06 00:06:07,591 - INFO - Verwende Gerät: cuda
2025-05-06 00:06:07,592 - INFO - ================================================================================
2025-05-06 00:06:07,592 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 00:06:07,592 - INFO - ================================================================================
2025-05-06 00:06:07,592 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 00:06:07,592 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 00:06:07,592 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 00:06:07,592 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 00:06:07,592 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 00:06:07,592 - INFO - ================================================================================
2025-05-06 00:06:07,592 - INFO - Preparing optimized data loaders...
2025-05-06 00:06:07,592 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 00:06:07,630 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 00:06:07,630 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 00:06:07,630 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 00:06:07,630 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 00:06:07,630 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 00:06:07,630 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 00:06:07,631 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 00:06:07,632 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 00:06:07,632 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 00:06:07,632 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 00:06:07,632 - INFO - Lade Teacher-Modell von models/micro_pizza_model.pth
2025-05-06 00:06:07,750 - INFO - Konnte nicht als MicroPizzaNetV2 laden: Error(s) in loading state_dict for MicroPizzaNetV2:
	Missing key(s) in state_dict: "block2.conv.0.weight", "block2.conv.1.weight", "block2.conv.1.bias", "block2.conv.1.running_mean", "block2.conv.1.running_var", "block2.conv.3.weight", "block2.conv.4.weight", "block2.conv.4.bias", "block2.conv.4.running_mean", "block2.conv.4.running_var", "block2.conv.6.weight", "block2.conv.7.weight", "block2.conv.7.bias", "block2.conv.7.running_mean", "block2.conv.7.running_var". 
	Unexpected key(s) in state_dict: "block2.0.weight", "block2.1.weight", "block2.1.bias", "block2.1.running_mean", "block2.1.running_var", "block2.1.num_batches_tracked", "block2.3.weight", "block2.4.weight", "block2.4.bias", "block2.4.running_mean", "block2.4.running_var", "block2.4.num_batches_tracked". 
2025-05-06 00:06:07,750 - INFO - Versuche als MicroPizzaNet zu laden
2025-05-06 00:06:07,753 - INFO - Teacher-Modell als MicroPizzaNet geladen
2025-05-06 00:06:07,755 - INFO - Student-Modell: CustomMicroPizzaNet (extra klein)
2025-05-06 00:06:07,755 - INFO - Teacher-Modell: 582 Parameter
2025-05-06 00:06:07,755 - INFO - Student-Modell: 414 Parameter
2025-05-06 00:06:07,755 - INFO - Parameterreduktion: 28.87%
2025-05-06 00:06:07,755 - INFO - Evaluiere Modell...
2025-05-06 00:06:08,189 - INFO - Genauigkeit für Klasse 'basic': 0.00%
2025-05-06 00:06:08,190 - INFO - Genauigkeit für Klasse 'burnt': 0.00%
2025-05-06 00:06:08,190 - INFO - Genauigkeit für Klasse 'combined': 0.00%
2025-05-06 00:06:08,190 - INFO - Genauigkeit für Klasse 'mixed': 0.00%
2025-05-06 00:06:08,190 - INFO - Genauigkeit für Klasse 'progression': 0.00%
2025-05-06 00:06:08,190 - INFO - Genauigkeit für Klasse 'segment': 0.00%
2025-05-06 00:06:08,190 - INFO - Gesamtgenauigkeit: 0.00%
2025-05-06 00:06:08,190 - INFO - Teacher-Modell Genauigkeit: 0.00%
2025-05-06 00:06:08,190 - INFO - Starte Training mit Knowledge Distillation (alpha=0.5, temp=4.0)
2025-05-06 00:06:08,692 - INFO - Epoch 1/30: Train Loss: 1.2106, Train Acc: 13.33% - Hard Loss: 1.8000, Soft Loss: 0.0388 - Val Loss: 1.1681, Val Acc: 16.67%
2025-05-06 00:06:08,692 - INFO - Neues bestes Modell in Epoch 1 mit Validation Accuracy: 16.67%
2025-05-06 00:06:08,832 - INFO - Epoch 2/30: Train Loss: 1.1866, Train Acc: 26.67% - Hard Loss: 1.7753, Soft Loss: 0.0374 - Val Loss: 1.1590, Val Acc: 0.00%
2025-05-06 00:06:08,968 - INFO - Epoch 3/30: Train Loss: 1.1378, Train Acc: 26.67% - Hard Loss: 1.7567, Soft Loss: 0.0324 - Val Loss: 1.1477, Val Acc: 0.00%
2025-05-06 00:06:09,102 - INFO - Epoch 4/30: Train Loss: 1.1205, Train Acc: 31.11% - Hard Loss: 1.7361, Soft Loss: 0.0316 - Val Loss: 1.1352, Val Acc: 0.00%
2025-05-06 00:06:09,229 - INFO - Epoch 5/30: Train Loss: 1.0869, Train Acc: 31.11% - Hard Loss: 1.7122, Soft Loss: 0.0288 - Val Loss: 1.1202, Val Acc: 0.00%
2025-05-06 00:06:09,365 - INFO - Epoch 6/30: Train Loss: 1.0854, Train Acc: 26.67% - Hard Loss: 1.7069, Soft Loss: 0.0290 - Val Loss: 1.1049, Val Acc: 0.00%
2025-05-06 00:06:09,505 - INFO - Epoch 7/30: Train Loss: 1.0676, Train Acc: 20.00% - Hard Loss: 1.6903, Soft Loss: 0.0278 - Val Loss: 1.0878, Val Acc: 0.00%
2025-05-06 00:06:09,638 - INFO - Epoch 8/30: Train Loss: 1.0393, Train Acc: 22.22% - Hard Loss: 1.6765, Soft Loss: 0.0251 - Val Loss: 1.0697, Val Acc: 0.00%
2025-05-06 00:06:09,768 - INFO - Epoch 9/30: Train Loss: 1.0152, Train Acc: 22.22% - Hard Loss: 1.6626, Soft Loss: 0.0230 - Val Loss: 1.0502, Val Acc: 0.00%
2025-05-06 00:06:09,898 - INFO - Epoch 10/30: Train Loss: 0.9923, Train Acc: 31.11% - Hard Loss: 1.6320, Soft Loss: 0.0220 - Val Loss: 1.0301, Val Acc: 0.00%
2025-05-06 00:06:10,044 - INFO - Epoch 11/30: Train Loss: 0.9768, Train Acc: 37.78% - Hard Loss: 1.6130, Soft Loss: 0.0213 - Val Loss: 1.0095, Val Acc: 0.00%
2025-05-06 00:06:10,044 - INFO - Early Stopping in Epoch 11
2025-05-06 00:06:10,045 - INFO - Beste Modellgewichte aus Epoch 1 geladen
2025-05-06 00:06:10,046 - INFO - Student-Modell gespeichert unter output/knowledge_distillation/student_model.pth
2025-05-06 00:06:10,424 - INFO - Trainingshistorie gespeichert unter output/knowledge_distillation/training_history.png
2025-05-06 00:06:10,425 - INFO - Evaluiere Modell...
2025-05-06 00:06:10,489 - INFO - Genauigkeit für Klasse 'basic': 0.00%
2025-05-06 00:06:10,489 - INFO - Genauigkeit für Klasse 'burnt': 0.00%
2025-05-06 00:06:10,490 - INFO - Genauigkeit für Klasse 'combined': 0.00%
2025-05-06 00:06:10,490 - INFO - Genauigkeit für Klasse 'mixed': 0.00%
2025-05-06 00:06:10,490 - INFO - Genauigkeit für Klasse 'progression': 0.00%
2025-05-06 00:06:10,490 - INFO - Genauigkeit für Klasse 'segment': 0.00%
2025-05-06 00:06:10,490 - INFO - Gesamtgenauigkeit: 0.00%
2025-05-06 00:06:10,490 - INFO - Student-Modell Genauigkeit: 0.00%
2025-05-06 00:06:10,490 - INFO - Vergleiche Student- und Teacher-Modell...
2025-05-06 00:08:42,571 - INFO - Verwende Gerät: cuda
2025-05-06 00:08:42,571 - INFO - ================================================================================
2025-05-06 00:08:42,571 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 00:08:42,571 - INFO - ================================================================================
2025-05-06 00:08:42,571 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 00:08:42,571 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 00:08:42,571 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 00:08:42,571 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 00:08:42,571 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 00:08:42,571 - INFO - ================================================================================
2025-05-06 00:08:42,571 - INFO - Preparing optimized data loaders...
2025-05-06 00:08:42,572 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 00:08:42,609 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 00:08:42,609 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 00:08:42,609 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 00:08:42,609 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 00:08:42,609 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 00:08:42,609 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 00:08:42,609 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 00:08:42,610 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 00:08:42,610 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 00:08:42,610 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 00:08:42,610 - INFO - Lade Teacher-Modell von models/micro_pizza_model.pth
2025-05-06 00:08:42,730 - INFO - Konnte nicht als MicroPizzaNetV2 laden: Error(s) in loading state_dict for MicroPizzaNetV2:
	Missing key(s) in state_dict: "block2.conv.0.weight", "block2.conv.1.weight", "block2.conv.1.bias", "block2.conv.1.running_mean", "block2.conv.1.running_var", "block2.conv.3.weight", "block2.conv.4.weight", "block2.conv.4.bias", "block2.conv.4.running_mean", "block2.conv.4.running_var", "block2.conv.6.weight", "block2.conv.7.weight", "block2.conv.7.bias", "block2.conv.7.running_mean", "block2.conv.7.running_var". 
	Unexpected key(s) in state_dict: "block2.0.weight", "block2.1.weight", "block2.1.bias", "block2.1.running_mean", "block2.1.running_var", "block2.1.num_batches_tracked", "block2.3.weight", "block2.4.weight", "block2.4.bias", "block2.4.running_mean", "block2.4.running_var", "block2.4.num_batches_tracked". 
2025-05-06 00:08:42,730 - INFO - Versuche als MicroPizzaNet zu laden
2025-05-06 00:08:42,732 - INFO - Teacher-Modell als MicroPizzaNet geladen
2025-05-06 00:08:42,734 - INFO - Student-Modell: CustomMicroPizzaNet (extra klein)
2025-05-06 00:08:42,734 - INFO - Teacher-Modell: 582 Parameter
2025-05-06 00:08:42,735 - INFO - Student-Modell: 414 Parameter
2025-05-06 00:08:42,735 - INFO - Parameterreduktion: 28.87%
2025-05-06 00:08:42,735 - INFO - Evaluiere Modell...
2025-05-06 00:08:42,891 - INFO - Genauigkeit für Klasse 'basic': 0.00%
2025-05-06 00:08:42,891 - INFO - Genauigkeit für Klasse 'burnt': 0.00%
2025-05-06 00:08:42,891 - INFO - Genauigkeit für Klasse 'combined': 0.00%
2025-05-06 00:08:42,891 - INFO - Genauigkeit für Klasse 'mixed': 0.00%
2025-05-06 00:08:42,891 - INFO - Genauigkeit für Klasse 'progression': 0.00%
2025-05-06 00:08:42,891 - INFO - Genauigkeit für Klasse 'segment': 0.00%
2025-05-06 00:08:42,891 - INFO - Gesamtgenauigkeit: 0.00%
2025-05-06 00:08:42,891 - INFO - Teacher-Modell Genauigkeit: 0.00%
2025-05-06 00:08:42,891 - INFO - Starte Training mit Knowledge Distillation (alpha=0.5, temp=4.0)
2025-05-06 00:08:43,160 - INFO - Epoch 1/30: Train Loss: 1.2042, Train Acc: 20.00% - Hard Loss: 1.7910, Soft Loss: 0.0386 - Val Loss: 1.1682, Val Acc: 33.33%
2025-05-06 00:08:43,160 - INFO - Neues bestes Modell in Epoch 1 mit Validation Accuracy: 33.33%
2025-05-06 00:08:43,293 - INFO - Epoch 2/30: Train Loss: 1.1798, Train Acc: 22.22% - Hard Loss: 1.7773, Soft Loss: 0.0364 - Val Loss: 1.1604, Val Acc: 16.67%
2025-05-06 00:08:43,428 - INFO - Epoch 3/30: Train Loss: 1.1442, Train Acc: 24.44% - Hard Loss: 1.7534, Soft Loss: 0.0334 - Val Loss: 1.1504, Val Acc: 16.67%
2025-05-06 00:08:43,558 - INFO - Epoch 4/30: Train Loss: 1.1098, Train Acc: 22.22% - Hard Loss: 1.7373, Soft Loss: 0.0302 - Val Loss: 1.1386, Val Acc: 25.00%
2025-05-06 00:08:43,688 - INFO - Epoch 5/30: Train Loss: 1.1050, Train Acc: 17.78% - Hard Loss: 1.7259, Soft Loss: 0.0303 - Val Loss: 1.1254, Val Acc: 25.00%
2025-05-06 00:08:43,829 - INFO - Epoch 6/30: Train Loss: 1.1021, Train Acc: 24.44% - Hard Loss: 1.7041, Soft Loss: 0.0313 - Val Loss: 1.1116, Val Acc: 16.67%
2025-05-06 00:08:43,959 - INFO - Epoch 7/30: Train Loss: 1.0667, Train Acc: 26.67% - Hard Loss: 1.6868, Soft Loss: 0.0279 - Val Loss: 1.0955, Val Acc: 16.67%
2025-05-06 00:08:44,086 - INFO - Epoch 8/30: Train Loss: 1.0426, Train Acc: 22.22% - Hard Loss: 1.6675, Soft Loss: 0.0261 - Val Loss: 1.0791, Val Acc: 0.00%
2025-05-06 00:08:44,217 - INFO - Epoch 9/30: Train Loss: 1.0210, Train Acc: 46.67% - Hard Loss: 1.6455, Soft Loss: 0.0248 - Val Loss: 1.0629, Val Acc: 0.00%
2025-05-06 00:08:44,350 - INFO - Epoch 10/30: Train Loss: 1.0038, Train Acc: 37.78% - Hard Loss: 1.6389, Soft Loss: 0.0230 - Val Loss: 1.0464, Val Acc: 0.00%
2025-05-06 00:08:44,484 - INFO - Epoch 11/30: Train Loss: 0.9925, Train Acc: 37.78% - Hard Loss: 1.6235, Soft Loss: 0.0226 - Val Loss: 1.0290, Val Acc: 0.00%
2025-05-06 00:08:44,484 - INFO - Early Stopping in Epoch 11
2025-05-06 00:08:44,485 - INFO - Beste Modellgewichte aus Epoch 1 geladen
2025-05-06 00:08:44,486 - INFO - Student-Modell gespeichert unter output/knowledge_distillation/student_model.pth
2025-05-06 00:08:44,841 - INFO - Trainingshistorie gespeichert unter output/knowledge_distillation/training_history.png
2025-05-06 00:08:44,841 - INFO - Evaluiere Modell...
2025-05-06 00:08:44,906 - INFO - Genauigkeit für Klasse 'basic': 0.00%
2025-05-06 00:08:44,907 - INFO - Genauigkeit für Klasse 'burnt': 0.00%
2025-05-06 00:08:44,907 - INFO - Genauigkeit für Klasse 'combined': 0.00%
2025-05-06 00:08:44,907 - INFO - Genauigkeit für Klasse 'mixed': 0.00%
2025-05-06 00:08:44,907 - INFO - Genauigkeit für Klasse 'progression': 0.00%
2025-05-06 00:08:44,907 - INFO - Genauigkeit für Klasse 'segment': 0.00%
2025-05-06 00:08:44,907 - INFO - Gesamtgenauigkeit: 0.00%
2025-05-06 00:08:44,907 - INFO - Student-Modell Genauigkeit: 0.00%
2025-05-06 00:08:44,907 - INFO - Vergleiche Student- und Teacher-Modell...
2025-05-06 00:08:44,966 - INFO - 
============================================================
2025-05-06 00:08:44,966 - INFO - MODELLVERGLEICH: TEACHER VS. STUDENT
2025-05-06 00:08:44,966 - INFO - ============================================================
2025-05-06 00:08:44,966 - INFO - TEACHER Modell:
2025-05-06 00:08:44,966 - INFO -   - Parameter: 582
2025-05-06 00:08:44,966 - INFO -   - Modellgröße: 9.10 KB
2025-05-06 00:08:44,966 - INFO -   - Genauigkeit: 0.00%
2025-05-06 00:08:44,966 - INFO -   - Inferenzzeit: 0.87 ms
2025-05-06 00:08:44,966 - INFO - 
STUDENT Modell:
2025-05-06 00:08:44,966 - INFO -   - Parameter: 414
2025-05-06 00:08:44,966 - INFO -   - Modellgröße: 8.23 KB
2025-05-06 00:08:44,966 - INFO -   - Genauigkeit: 0.00%
2025-05-06 00:08:44,966 - INFO -   - Inferenzzeit: 0.28 ms
2025-05-06 00:08:44,966 - INFO - 
VERGLEICH:
2025-05-06 00:08:44,966 - INFO -   - Parameterreduktion: 28.87%
2025-05-06 00:08:44,966 - INFO -   - Größenreduktion: 9.61%
2025-05-06 00:08:44,966 - INFO -   - Genauigkeitsänderung: 0.00%
2025-05-06 00:08:44,966 - INFO -   - Beschleunigungsfaktor: 3.12x
2025-05-06 00:08:44,966 - INFO - ============================================================
2025-05-06 00:08:44,967 - INFO - Vergleichsbericht gespeichert unter output/knowledge_distillation/model_comparison.json
2025-05-06 00:08:45,091 - INFO - Vergleichsvisualisierung gespeichert unter output/knowledge_distillation/model_comparison.png
2025-05-06 00:08:45,091 - INFO - 
==================================================
2025-05-06 00:08:45,091 - INFO - KNOWLEDGE DISTILLATION ABGESCHLOSSEN
2025-05-06 00:08:45,091 - INFO - ==================================================
2025-05-06 00:08:45,092 - INFO - Teacher-Genauigkeit: 0.00%
2025-05-06 00:08:45,092 - INFO - Student-Genauigkeit: 0.00%
2025-05-06 00:08:45,092 - INFO - Genauigkeitsänderung: 0.00%
2025-05-06 00:08:45,092 - INFO - Parameterreduktion: 28.87%
2025-05-06 00:08:45,092 - INFO - Modell und Berichte gespeichert unter: output/knowledge_distillation
2025-05-06 00:20:43,936 - INFO - Starte Vergleich zwischen MicroPizzaNet und Variante mit Squeeze-and-Excitation-Modulen
2025-05-06 00:20:43,936 - INFO - ================================================================================
2025-05-06 00:20:43,936 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 00:20:43,937 - INFO - ================================================================================
2025-05-06 00:20:43,937 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 00:20:43,937 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 00:20:43,937 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 00:20:43,937 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 00:20:43,937 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 00:20:43,937 - INFO - ================================================================================
2025-05-06 00:20:43,937 - INFO - Lade Datensatz aus data/augmented
2025-05-06 00:20:43,937 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 00:20:43,971 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 00:20:43,971 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 00:20:43,971 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 00:20:43,971 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 00:20:43,971 - INFO - RGB-Mittelwerte: [0.4811, 0.3992, 0.3300]
2025-05-06 00:20:43,971 - INFO - RGB-Standardabweichungen: [0.2417, 0.2575, 0.2701]
2025-05-06 00:20:43,971 - INFO - Preparing optimized data loaders...
2025-05-06 00:20:43,971 - INFO - Using dataset-specific normalization: mean=[0.48106108 0.39918071 0.3299819 ], std=[0.24165445 0.25754791 0.27012255]
2025-05-06 00:20:43,973 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 00:20:43,973 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 00:20:43,973 - INFO - 
==================================================
Trainiere Modell 1/3: MicroPizzaNet (Original)
==================================================
2025-05-06 00:20:43,976 - INFO - Speicheranalyse:
2025-05-06 00:20:43,976 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-06 00:20:43,976 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-06 00:20:43,976 - INFO -   Aktivierungsspeicher: 101.46 KB
2025-05-06 00:20:43,976 - INFO -   Gesamter Laufzeitspeicher: 102.09 KB (38.7% des RAM)
2025-05-06 00:20:43,976 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.09KB > 100KB)
2025-05-06 00:20:43,976 - INFO - Starte Training für micropizzanet_(original)...
2025-05-06 00:20:44,092 - INFO - Modell hat 582 Parameter
2025-05-06 00:20:44,452 - INFO - Epoch 1/20 - Loss: 1.7992, Acc: 8.89% - Val Loss: 1.7892, Val Acc: 33.33%
2025-05-06 00:20:44,597 - INFO - Epoch 2/20 - Loss: 1.7790, Acc: 26.67% - Val Loss: 1.7831, Val Acc: 33.33%
2025-05-06 00:20:44,737 - INFO - Epoch 3/20 - Loss: 1.7658, Acc: 26.67% - Val Loss: 1.7764, Val Acc: 33.33%
2025-05-06 00:20:44,881 - INFO - Epoch 4/20 - Loss: 1.7463, Acc: 31.11% - Val Loss: 1.7690, Val Acc: 33.33%
2025-05-06 00:20:45,026 - INFO - Epoch 5/20 - Loss: 1.7315, Acc: 28.89% - Val Loss: 1.7600, Val Acc: 33.33%
2025-05-06 00:20:45,171 - INFO - Epoch 6/20 - Loss: 1.7267, Acc: 26.67% - Val Loss: 1.7501, Val Acc: 33.33%
2025-05-06 00:20:45,314 - INFO - Epoch 7/20 - Loss: 1.7085, Acc: 31.11% - Val Loss: 1.7392, Val Acc: 33.33%
2025-05-06 00:20:45,461 - INFO - Epoch 8/20 - Loss: 1.7013, Acc: 28.89% - Val Loss: 1.7306, Val Acc: 33.33%
2025-05-06 00:20:45,605 - INFO - Epoch 9/20 - Loss: 1.6985, Acc: 20.00% - Val Loss: 1.7212, Val Acc: 33.33%
2025-05-06 00:20:45,747 - INFO - Epoch 10/20 - Loss: 1.7034, Acc: 22.22% - Val Loss: 1.7119, Val Acc: 33.33%
2025-05-06 00:20:45,890 - INFO - Epoch 11/20 - Loss: 1.6814, Acc: 20.00% - Val Loss: 1.7015, Val Acc: 33.33%
2025-05-06 00:20:46,033 - INFO - Epoch 12/20 - Loss: 1.6818, Acc: 22.22% - Val Loss: 1.6914, Val Acc: 33.33%
2025-05-06 00:20:46,191 - INFO - Epoch 13/20 - Loss: 1.6897, Acc: 17.78% - Val Loss: 1.6817, Val Acc: 33.33%
2025-05-06 00:20:46,333 - INFO - Epoch 14/20 - Loss: 1.6786, Acc: 17.78% - Val Loss: 1.6757, Val Acc: 33.33%
2025-05-06 00:20:46,478 - INFO - Epoch 15/20 - Loss: 1.6770, Acc: 22.22% - Val Loss: 1.6698, Val Acc: 41.67%
2025-05-06 00:20:46,619 - INFO - Epoch 16/20 - Loss: 1.6612, Acc: 24.44% - Val Loss: 1.6642, Val Acc: 41.67%
2025-05-06 00:20:46,771 - INFO - Epoch 17/20 - Loss: 1.6435, Acc: 35.56% - Val Loss: 1.6583, Val Acc: 41.67%
2025-05-06 00:20:46,915 - INFO - Epoch 18/20 - Loss: 1.6588, Acc: 28.89% - Val Loss: 1.6538, Val Acc: 50.00%
2025-05-06 00:20:47,062 - INFO - Epoch 19/20 - Loss: 1.6640, Acc: 22.22% - Val Loss: 1.6490, Val Acc: 50.00%
2025-05-06 00:20:47,207 - INFO - Epoch 20/20 - Loss: 1.6621, Acc: 28.89% - Val Loss: 1.6442, Val Acc: 41.67%
2025-05-06 00:20:47,208 - INFO - Beste Gewichte wiederhergestellt
2025-05-06 00:20:47,208 - INFO - Evaluiere Modell...
2025-05-06 00:20:47,277 - INFO - Genauigkeit: 41.67%
2025-05-06 00:20:47,278 - INFO - Precision: 0.5625
2025-05-06 00:20:47,278 - INFO - Recall: 0.4167
2025-05-06 00:20:47,278 - INFO - F1-Score: 0.4242
2025-05-06 00:20:47,278 - INFO - Messe Inferenzzeit...
2025-05-06 00:20:47,301 - INFO - Durchschnittliche Inferenzzeit auf CPU: 0.13 ms
2025-05-06 00:20:47,302 - INFO - Geschätzte Inferenzzeit auf RP2040: 4.44 ms
2025-05-06 00:20:47,303 - INFO - Modell gespeichert unter: output/se_comparison/models/micropizzanet_(original).pth
2025-05-06 00:20:47,716 - INFO - 
==================================================
Trainiere Modell 2/3: MicroPizzaNetWithSE (SE-Ratio=4)
==================================================
2025-05-06 00:20:47,722 - INFO - Speicheranalyse:
2025-05-06 00:20:47,722 - INFO -   Modellgröße (Float32): 3.16 KB
2025-05-06 00:20:47,723 - INFO -   Modellgröße (Int8): 0.79 KB (0.0% des Flash)
2025-05-06 00:20:47,723 - INFO -   Aktivierungsspeicher: 101.70 KB
2025-05-06 00:20:47,723 - INFO -   Gesamter Laufzeitspeicher: 102.49 KB (38.8% des RAM)
2025-05-06 00:20:47,723 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.49KB > 100KB)
2025-05-06 00:20:47,723 - INFO - Starte Training für micropizzanetwithse_(se-ratio=4)...
2025-05-06 00:20:47,725 - INFO - Modell hat 742 Parameter
2025-05-06 00:20:47,900 - INFO - Epoch 1/20 - Loss: 1.7988, Acc: 11.11% - Val Loss: 1.7899, Val Acc: 0.00%
2025-05-06 00:20:48,054 - INFO - Epoch 2/20 - Loss: 1.7827, Acc: 31.11% - Val Loss: 1.7875, Val Acc: 0.00%
2025-05-06 00:20:48,223 - INFO - Epoch 3/20 - Loss: 1.7815, Acc: 24.44% - Val Loss: 1.7846, Val Acc: 0.00%
2025-05-06 00:20:48,382 - INFO - Epoch 4/20 - Loss: 1.7733, Acc: 28.89% - Val Loss: 1.7812, Val Acc: 0.00%
2025-05-06 00:20:48,537 - INFO - Epoch 5/20 - Loss: 1.7682, Acc: 26.67% - Val Loss: 1.7772, Val Acc: 0.00%
2025-05-06 00:20:48,692 - INFO - Epoch 6/20 - Loss: 1.7525, Acc: 42.22% - Val Loss: 1.7728, Val Acc: 0.00%
2025-05-06 00:20:48,848 - INFO - Epoch 7/20 - Loss: 1.7567, Acc: 35.56% - Val Loss: 1.7687, Val Acc: 0.00%
2025-05-06 00:20:49,002 - INFO - Epoch 8/20 - Loss: 1.7482, Acc: 24.44% - Val Loss: 1.7658, Val Acc: 0.00%
2025-05-06 00:20:49,153 - INFO - Epoch 9/20 - Loss: 1.7284, Acc: 44.44% - Val Loss: 1.7626, Val Acc: 0.00%
2025-05-06 00:20:49,303 - INFO - Epoch 10/20 - Loss: 1.7488, Acc: 26.67% - Val Loss: 1.7597, Val Acc: 0.00%
2025-05-06 00:20:49,455 - INFO - Epoch 11/20 - Loss: 1.7316, Acc: 33.33% - Val Loss: 1.7567, Val Acc: 0.00%
2025-05-06 00:20:49,612 - INFO - Epoch 12/20 - Loss: 1.7393, Acc: 26.67% - Val Loss: 1.7536, Val Acc: 0.00%
2025-05-06 00:20:49,772 - INFO - Epoch 13/20 - Loss: 1.7341, Acc: 26.67% - Val Loss: 1.7506, Val Acc: 0.00%
2025-05-06 00:20:49,925 - INFO - Epoch 14/20 - Loss: 1.7268, Acc: 42.22% - Val Loss: 1.7485, Val Acc: 0.00%
2025-05-06 00:20:50,081 - INFO - Epoch 15/20 - Loss: 1.7184, Acc: 37.78% - Val Loss: 1.7462, Val Acc: 0.00%
2025-05-06 00:20:50,235 - INFO - Epoch 16/20 - Loss: 1.7268, Acc: 28.89% - Val Loss: 1.7439, Val Acc: 0.00%
2025-05-06 00:20:50,387 - INFO - Epoch 17/20 - Loss: 1.7133, Acc: 35.56% - Val Loss: 1.7417, Val Acc: 0.00%
2025-05-06 00:20:50,539 - INFO - Epoch 18/20 - Loss: 1.7123, Acc: 40.00% - Val Loss: 1.7398, Val Acc: 0.00%
2025-05-06 00:20:50,691 - INFO - Epoch 19/20 - Loss: 1.7051, Acc: 42.22% - Val Loss: 1.7376, Val Acc: 0.00%
2025-05-06 00:20:50,844 - INFO - Epoch 20/20 - Loss: 1.7197, Acc: 26.67% - Val Loss: 1.7362, Val Acc: 0.00%
2025-05-06 00:20:50,845 - INFO - Beste Gewichte wiederhergestellt
2025-05-06 00:20:50,846 - INFO - Evaluiere Modell...
2025-05-06 00:20:50,908 - INFO - Genauigkeit: 0.00%
2025-05-06 00:20:50,909 - INFO - Precision: 0.0000
2025-05-06 00:20:50,909 - INFO - Recall: 0.0000
2025-05-06 00:20:50,909 - INFO - F1-Score: 0.0000
2025-05-06 00:20:50,909 - INFO - Messe Inferenzzeit...
2025-05-06 00:20:50,934 - INFO - Durchschnittliche Inferenzzeit auf CPU: 0.22 ms
2025-05-06 00:20:50,934 - INFO - Geschätzte Inferenzzeit auf RP2040: 7.76 ms
2025-05-06 00:20:50,936 - INFO - Modell gespeichert unter: output/se_comparison/models/micropizzanetwithse_(se-ratio=4).pth
2025-05-06 00:20:51,315 - INFO - 
==================================================
Trainiere Modell 3/3: MicroPizzaNetWithSE (SE-Ratio=8)
==================================================
2025-05-06 00:20:51,318 - INFO - Speicheranalyse:
2025-05-06 00:20:51,318 - INFO -   Modellgröße (Float32): 2.85 KB
2025-05-06 00:20:51,318 - INFO -   Modellgröße (Int8): 0.71 KB (0.0% des Flash)
2025-05-06 00:20:51,318 - INFO -   Aktivierungsspeicher: 101.67 KB
2025-05-06 00:20:51,318 - INFO -   Gesamter Laufzeitspeicher: 102.38 KB (38.8% des RAM)
2025-05-06 00:20:51,318 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.38KB > 100KB)
2025-05-06 00:20:51,318 - INFO - Starte Training für micropizzanetwithse_(se-ratio=8)...
2025-05-06 00:20:51,318 - INFO - Modell hat 662 Parameter
2025-05-06 00:20:51,540 - INFO - Epoch 1/20 - Loss: 1.7997, Acc: 4.44% - Val Loss: 1.7886, Val Acc: 66.67%
2025-05-06 00:20:51,692 - INFO - Epoch 2/20 - Loss: 1.7882, Acc: 20.00% - Val Loss: 1.7859, Val Acc: 66.67%
2025-05-06 00:20:51,849 - INFO - Epoch 3/20 - Loss: 1.7849, Acc: 11.11% - Val Loss: 1.7835, Val Acc: 58.33%
2025-05-06 00:20:52,004 - INFO - Epoch 4/20 - Loss: 1.7733, Acc: 15.56% - Val Loss: 1.7817, Val Acc: 0.00%
2025-05-06 00:20:52,159 - INFO - Epoch 5/20 - Loss: 1.7663, Acc: 26.67% - Val Loss: 1.7793, Val Acc: 0.00%
2025-05-06 00:20:52,316 - INFO - Epoch 6/20 - Loss: 1.7575, Acc: 31.11% - Val Loss: 1.7767, Val Acc: 0.00%
2025-05-06 00:20:52,481 - INFO - Epoch 7/20 - Loss: 1.7502, Acc: 33.33% - Val Loss: 1.7740, Val Acc: 0.00%
2025-05-06 00:20:52,632 - INFO - Epoch 8/20 - Loss: 1.7466, Acc: 20.00% - Val Loss: 1.7722, Val Acc: 0.00%
2025-05-06 00:20:52,784 - INFO - Epoch 9/20 - Loss: 1.7360, Acc: 33.33% - Val Loss: 1.7703, Val Acc: 0.00%
2025-05-06 00:20:52,938 - INFO - Epoch 10/20 - Loss: 1.7341, Acc: 24.44% - Val Loss: 1.7677, Val Acc: 0.00%
2025-05-06 00:20:53,094 - INFO - Epoch 11/20 - Loss: 1.7332, Acc: 28.89% - Val Loss: 1.7650, Val Acc: 0.00%
2025-05-06 00:20:53,250 - INFO - Epoch 12/20 - Loss: 1.7247, Acc: 37.78% - Val Loss: 1.7620, Val Acc: 0.00%
2025-05-06 00:20:53,404 - INFO - Epoch 13/20 - Loss: 1.7255, Acc: 31.11% - Val Loss: 1.7593, Val Acc: 0.00%
2025-05-06 00:20:53,560 - INFO - Epoch 14/20 - Loss: 1.7218, Acc: 28.89% - Val Loss: 1.7570, Val Acc: 0.00%
2025-05-06 00:20:53,716 - INFO - Epoch 15/20 - Loss: 1.7139, Acc: 37.78% - Val Loss: 1.7546, Val Acc: 0.00%
2025-05-06 00:20:53,867 - INFO - Epoch 16/20 - Loss: 1.7121, Acc: 40.00% - Val Loss: 1.7522, Val Acc: 0.00%
2025-05-06 00:20:54,025 - INFO - Epoch 17/20 - Loss: 1.7124, Acc: 33.33% - Val Loss: 1.7496, Val Acc: 0.00%
2025-05-06 00:20:54,195 - INFO - Epoch 18/20 - Loss: 1.7134, Acc: 31.11% - Val Loss: 1.7468, Val Acc: 0.00%
2025-05-06 00:20:54,355 - INFO - Epoch 19/20 - Loss: 1.7151, Acc: 20.00% - Val Loss: 1.7442, Val Acc: 0.00%
2025-05-06 00:20:54,509 - INFO - Epoch 20/20 - Loss: 1.7096, Acc: 28.89% - Val Loss: 1.7419, Val Acc: 0.00%
2025-05-06 00:20:54,510 - INFO - Beste Gewichte wiederhergestellt
2025-05-06 00:20:54,510 - INFO - Evaluiere Modell...
2025-05-06 00:20:54,588 - INFO - Genauigkeit: 0.00%
2025-05-06 00:20:54,588 - INFO - Precision: 0.0000
2025-05-06 00:20:54,588 - INFO - Recall: 0.0000
2025-05-06 00:20:54,588 - INFO - F1-Score: 0.0000
2025-05-06 00:20:54,588 - INFO - Messe Inferenzzeit...
2025-05-06 00:20:54,613 - INFO - Durchschnittliche Inferenzzeit auf CPU: 0.22 ms
2025-05-06 00:20:54,614 - INFO - Geschätzte Inferenzzeit auf RP2040: 7.71 ms
2025-05-06 00:20:54,615 - INFO - Modell gespeichert unter: output/se_comparison/models/micropizzanetwithse_(se-ratio=8).pth
2025-05-06 00:20:55,449 - INFO - Feature-Maps für MicroPizzaNet (Original) gespeichert in output/se_comparison/micropizzanet_(original)/activations
2025-05-06 00:20:56,015 - INFO - Feature-Maps für MicroPizzaNetWithSE (SE-Ratio=4) gespeichert in output/se_comparison/micropizzanetwithse_(se-ratio=4)/activations
2025-05-06 00:20:56,532 - INFO - Feature-Maps für MicroPizzaNetWithSE (SE-Ratio=8) gespeichert in output/se_comparison/micropizzanetwithse_(se-ratio=8)/activations
2025-05-06 00:20:57,300 - INFO - 
==================================================
2025-05-06 00:20:57,300 - INFO - ZUSAMMENFASSUNG DES SQUEEZE-AND-EXCITATION VERGLEICHS
2025-05-06 00:20:57,300 - INFO - ==================================================
2025-05-06 00:20:57,300 - INFO - Bestes Modell: MicroPizzaNet (Original)
2025-05-06 00:20:57,300 - INFO - - Genauigkeit: 41.67%
2025-05-06 00:20:57,300 - INFO - - F1-Score: 0.4242
2025-05-06 00:20:57,300 - INFO - - Parameter: 582
2025-05-06 00:20:57,300 - INFO - - Modellgröße: 2.5 KB
2025-05-06 00:20:57,300 - INFO - - RAM-Nutzung: 102.1 KB
2025-05-06 00:20:57,300 - INFO - - Inferenzzeit auf RP2040: 4.4 ms
2025-05-06 00:20:57,301 - INFO - 
Verbesserung gegenüber Original:
2025-05-06 00:20:57,301 - INFO - - Genauigkeit: +0.00%
2025-05-06 00:20:57,301 - INFO - - Parameteranstieg: +0.0%
2025-05-06 00:20:57,301 - INFO - 
Ergebnisse gespeichert in:
2025-05-06 00:20:57,301 - INFO - - CSV: output/se_comparison/se_comparison_results.csv
2025-05-06 00:20:57,301 - INFO - - Excel: output/se_comparison/se_comparison_results.xlsx
2025-05-06 00:20:57,301 - INFO - - HTML-Bericht: output/se_comparison/se_comparison_report.html
2025-05-06 00:26:28,220 - INFO - Starte Vergleich zwischen ReLU und Hard-Swish Aktivierungsfunktionen
2025-05-06 00:26:28,221 - INFO - ================================================================================
2025-05-06 00:26:28,221 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 00:26:28,221 - INFO - ================================================================================
2025-05-06 00:26:28,221 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 00:26:28,221 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 00:26:28,221 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 00:26:28,221 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 00:26:28,221 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 00:26:28,221 - INFO - ================================================================================
2025-05-06 00:26:28,221 - INFO - Lade Datensatz aus data/augmented
2025-05-06 00:26:28,221 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 00:26:28,254 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 00:26:28,254 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 00:26:28,254 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 00:26:28,254 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 00:26:28,254 - INFO - RGB-Mittelwerte: [0.4872, 0.4066, 0.3399]
2025-05-06 00:26:28,254 - INFO - RGB-Standardabweichungen: [0.2339, 0.2499, 0.2641]
2025-05-06 00:26:28,255 - INFO - Preparing optimized data loaders...
2025-05-06 00:26:28,255 - INFO - Using dataset-specific normalization: mean=[0.48720461 0.40661534 0.33988646], std=[0.23385905 0.24988272 0.26410666]
2025-05-06 00:26:28,256 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 00:26:28,256 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 00:26:28,256 - INFO - 
==================================================
Trainiere Modell 1/2: MicroPizzaNet (ReLU)
==================================================
2025-05-06 00:26:28,259 - INFO - Speicheranalyse:
2025-05-06 00:26:28,259 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-06 00:26:28,259 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-06 00:26:28,259 - INFO -   Aktivierungsspeicher: 101.46 KB
2025-05-06 00:26:28,259 - INFO -   Gesamter Laufzeitspeicher: 102.09 KB (38.7% des RAM)
2025-05-06 00:26:28,259 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.09KB > 100KB)
2025-05-06 00:26:28,259 - INFO - Starte Training für micropizzanet_(relu)...
2025-05-06 00:26:28,376 - INFO - Modell hat 582 Parameter
2025-05-06 00:26:28,714 - INFO - Epoch 1/30 - Loss: 1.7845, Acc: 26.67% - Val Loss: 1.7878, Val Acc: 16.67%
2025-05-06 00:26:28,860 - INFO - Epoch 2/30 - Loss: 1.7782, Acc: 24.44% - Val Loss: 1.7849, Val Acc: 25.00%
2025-05-06 00:26:29,005 - INFO - Epoch 3/30 - Loss: 1.7700, Acc: 22.22% - Val Loss: 1.7812, Val Acc: 25.00%
2025-05-06 00:26:29,155 - INFO - Epoch 4/30 - Loss: 1.7426, Acc: 26.67% - Val Loss: 1.7759, Val Acc: 0.00%
2025-05-06 00:26:29,303 - INFO - Epoch 5/30 - Loss: 1.7367, Acc: 24.44% - Val Loss: 1.7693, Val Acc: 8.33%
2025-05-06 00:26:29,453 - INFO - Epoch 6/30 - Loss: 1.7222, Acc: 24.44% - Val Loss: 1.7612, Val Acc: 0.00%
2025-05-06 00:26:29,606 - INFO - Epoch 7/30 - Loss: 1.7000, Acc: 40.00% - Val Loss: 1.7524, Val Acc: 8.33%
2025-05-06 00:26:29,758 - INFO - Epoch 8/30 - Loss: 1.6972, Acc: 26.67% - Val Loss: 1.7434, Val Acc: 8.33%
2025-05-06 00:26:29,907 - INFO - Epoch 9/30 - Loss: 1.6749, Acc: 35.56% - Val Loss: 1.7367, Val Acc: 8.33%
2025-05-06 00:26:30,063 - INFO - Epoch 10/30 - Loss: 1.6778, Acc: 31.11% - Val Loss: 1.7311, Val Acc: 8.33%
2025-05-06 00:26:30,219 - INFO - Epoch 11/30 - Loss: 1.6697, Acc: 20.00% - Val Loss: 1.7240, Val Acc: 8.33%
2025-05-06 00:26:30,367 - INFO - Epoch 12/30 - Loss: 1.6591, Acc: 28.89% - Val Loss: 1.7168, Val Acc: 8.33%
2025-05-06 00:26:30,531 - INFO - Epoch 13/30 - Loss: 1.6483, Acc: 40.00% - Val Loss: 1.7093, Val Acc: 8.33%
2025-05-06 00:26:30,678 - INFO - Epoch 14/30 - Loss: 1.6574, Acc: 22.22% - Val Loss: 1.7007, Val Acc: 8.33%
2025-05-06 00:26:30,822 - INFO - Epoch 15/30 - Loss: 1.6561, Acc: 17.78% - Val Loss: 1.6939, Val Acc: 8.33%
2025-05-06 00:26:30,974 - INFO - Epoch 16/30 - Loss: 1.6341, Acc: 33.33% - Val Loss: 1.6880, Val Acc: 8.33%
2025-05-06 00:26:31,123 - INFO - Epoch 17/30 - Loss: 1.6422, Acc: 31.11% - Val Loss: 1.6824, Val Acc: 8.33%
2025-05-06 00:26:31,274 - INFO - Epoch 18/30 - Loss: 1.6362, Acc: 24.44% - Val Loss: 1.6776, Val Acc: 8.33%
2025-05-06 00:26:31,423 - INFO - Epoch 19/30 - Loss: 1.6440, Acc: 22.22% - Val Loss: 1.6723, Val Acc: 8.33%
2025-05-06 00:26:31,577 - INFO - Epoch 20/30 - Loss: 1.6338, Acc: 24.44% - Val Loss: 1.6672, Val Acc: 8.33%
2025-05-06 00:26:31,727 - INFO - Epoch 21/30 - Loss: 1.6300, Acc: 22.22% - Val Loss: 1.6633, Val Acc: 8.33%
2025-05-06 00:26:31,875 - INFO - Epoch 22/30 - Loss: 1.6277, Acc: 31.11% - Val Loss: 1.6602, Val Acc: 8.33%
2025-05-06 00:26:32,018 - INFO - Epoch 23/30 - Loss: 1.6266, Acc: 20.00% - Val Loss: 1.6567, Val Acc: 8.33%
2025-05-06 00:26:32,168 - INFO - Epoch 24/30 - Loss: 1.6306, Acc: 28.89% - Val Loss: 1.6572, Val Acc: 8.33%
2025-05-06 00:26:32,168 - INFO - EarlyStopping counter: 1/10
2025-05-06 00:26:32,315 - INFO - Epoch 25/30 - Loss: 1.6419, Acc: 24.44% - Val Loss: 1.6530, Val Acc: 8.33%
2025-05-06 00:26:32,467 - INFO - Epoch 26/30 - Loss: 1.6238, Acc: 26.67% - Val Loss: 1.6522, Val Acc: 8.33%
2025-05-06 00:26:32,467 - INFO - EarlyStopping counter: 1/10
2025-05-06 00:26:32,614 - INFO - Epoch 27/30 - Loss: 1.6361, Acc: 20.00% - Val Loss: 1.6513, Val Acc: 8.33%
2025-05-06 00:26:32,766 - INFO - Epoch 28/30 - Loss: 1.6134, Acc: 35.56% - Val Loss: 1.6502, Val Acc: 8.33%
2025-05-06 00:26:32,911 - INFO - Epoch 29/30 - Loss: 1.6308, Acc: 20.00% - Val Loss: 1.6487, Val Acc: 8.33%
2025-05-06 00:26:33,055 - INFO - Epoch 30/30 - Loss: 1.6329, Acc: 17.78% - Val Loss: 1.6473, Val Acc: 8.33%
2025-05-06 00:26:33,056 - INFO - Beste Gewichte wiederhergestellt
2025-05-06 00:26:33,057 - INFO - Evaluiere Modell...
2025-05-06 00:26:33,120 - INFO - Genauigkeit: 8.33%
2025-05-06 00:26:33,120 - INFO - Precision: 0.0069
2025-05-06 00:26:33,120 - INFO - Recall: 0.0833
2025-05-06 00:26:33,120 - INFO - F1-Score: 0.0128
2025-05-06 00:26:33,120 - INFO - Messe Inferenzzeit...
2025-05-06 00:26:33,138 - INFO - Durchschnittliche Inferenzzeit auf CPU: 0.13 ms
2025-05-06 00:26:33,138 - INFO - Geschätzte Inferenzzeit auf RP2040: 4.43 ms
2025-05-06 00:26:33,139 - INFO - Modell gespeichert unter: output/hard_swish_comparison/models/micropizzanet_(relu).pth
2025-05-06 00:26:33,505 - INFO - 
==================================================
Trainiere Modell 2/2: MicroPizzaNet (Hard-Swish)
==================================================
2025-05-06 00:26:33,508 - INFO - Speicheranalyse:
2025-05-06 00:26:33,508 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-06 00:26:33,509 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-06 00:26:33,509 - INFO -   Aktivierungsspeicher: 101.46 KB
2025-05-06 00:26:33,509 - INFO -   Gesamter Laufzeitspeicher: 102.09 KB (38.7% des RAM)
2025-05-06 00:26:33,509 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.09KB > 100KB)
2025-05-06 00:26:33,509 - INFO - Starte Training für micropizzanet_(hard-swish)...
2025-05-06 00:26:33,510 - INFO - Modell hat 582 Parameter
2025-05-06 00:26:33,686 - INFO - Epoch 1/30 - Loss: 1.7971, Acc: 8.89% - Val Loss: 1.7913, Val Acc: 0.00%
2025-05-06 00:26:33,842 - INFO - Epoch 2/30 - Loss: 1.7863, Acc: 24.44% - Val Loss: 1.7918, Val Acc: 0.00%
2025-05-06 00:26:33,842 - INFO - EarlyStopping counter: 1/10
2025-05-06 00:26:34,002 - INFO - Epoch 3/30 - Loss: 1.7807, Acc: 13.33% - Val Loss: 1.7912, Val Acc: 0.00%
2025-05-06 00:26:34,002 - INFO - EarlyStopping counter: 2/10
2025-05-06 00:26:34,157 - INFO - Epoch 4/30 - Loss: 1.7639, Acc: 40.00% - Val Loss: 1.7905, Val Acc: 0.00%
2025-05-06 00:26:34,157 - INFO - EarlyStopping counter: 3/10
2025-05-06 00:26:34,326 - INFO - Epoch 5/30 - Loss: 1.7540, Acc: 37.78% - Val Loss: 1.7894, Val Acc: 0.00%
2025-05-06 00:26:34,488 - INFO - Epoch 6/30 - Loss: 1.7521, Acc: 26.67% - Val Loss: 1.7877, Val Acc: 0.00%
2025-05-06 00:26:34,642 - INFO - Epoch 7/30 - Loss: 1.7475, Acc: 22.22% - Val Loss: 1.7847, Val Acc: 0.00%
2025-05-06 00:26:34,803 - INFO - Epoch 8/30 - Loss: 1.7266, Acc: 31.11% - Val Loss: 1.7827, Val Acc: 0.00%
2025-05-06 00:26:34,962 - INFO - Epoch 9/30 - Loss: 1.7249, Acc: 40.00% - Val Loss: 1.7804, Val Acc: 0.00%
2025-05-06 00:26:35,116 - INFO - Epoch 10/30 - Loss: 1.7343, Acc: 15.56% - Val Loss: 1.7772, Val Acc: 0.00%
2025-05-06 00:26:35,274 - INFO - Epoch 11/30 - Loss: 1.7102, Acc: 28.89% - Val Loss: 1.7737, Val Acc: 0.00%
2025-05-06 00:26:35,429 - INFO - Epoch 12/30 - Loss: 1.7077, Acc: 28.89% - Val Loss: 1.7703, Val Acc: 0.00%
2025-05-06 00:26:35,587 - INFO - Epoch 13/30 - Loss: 1.7080, Acc: 15.56% - Val Loss: 1.7664, Val Acc: 0.00%
2025-05-06 00:26:35,742 - INFO - Epoch 14/30 - Loss: 1.7029, Acc: 24.44% - Val Loss: 1.7636, Val Acc: 0.00%
2025-05-06 00:26:35,896 - INFO - Epoch 15/30 - Loss: 1.6949, Acc: 33.33% - Val Loss: 1.7605, Val Acc: 0.00%
2025-05-06 00:26:36,050 - INFO - Epoch 16/30 - Loss: 1.6915, Acc: 26.67% - Val Loss: 1.7581, Val Acc: 0.00%
2025-05-06 00:26:36,203 - INFO - Epoch 17/30 - Loss: 1.6949, Acc: 24.44% - Val Loss: 1.7557, Val Acc: 0.00%
2025-05-06 00:26:36,374 - INFO - Epoch 18/30 - Loss: 1.6806, Acc: 46.67% - Val Loss: 1.7525, Val Acc: 0.00%
2025-05-06 00:26:36,528 - INFO - Epoch 19/30 - Loss: 1.6856, Acc: 35.56% - Val Loss: 1.7497, Val Acc: 0.00%
2025-05-06 00:26:36,685 - INFO - Epoch 20/30 - Loss: 1.6826, Acc: 26.67% - Val Loss: 1.7477, Val Acc: 0.00%
2025-05-06 00:26:36,839 - INFO - Epoch 21/30 - Loss: 1.6765, Acc: 28.89% - Val Loss: 1.7461, Val Acc: 0.00%
2025-05-06 00:26:37,002 - INFO - Epoch 22/30 - Loss: 1.6811, Acc: 24.44% - Val Loss: 1.7448, Val Acc: 0.00%
2025-05-06 00:26:37,161 - INFO - Epoch 23/30 - Loss: 1.6817, Acc: 28.89% - Val Loss: 1.7426, Val Acc: 0.00%
2025-05-06 00:26:37,321 - INFO - Epoch 24/30 - Loss: 1.6730, Acc: 35.56% - Val Loss: 1.7413, Val Acc: 0.00%
2025-05-06 00:26:37,478 - INFO - Epoch 25/30 - Loss: 1.6815, Acc: 31.11% - Val Loss: 1.7409, Val Acc: 0.00%
2025-05-06 00:26:37,478 - INFO - EarlyStopping counter: 1/10
2025-05-06 00:26:37,640 - INFO - Epoch 26/30 - Loss: 1.6876, Acc: 24.44% - Val Loss: 1.7407, Val Acc: 0.00%
2025-05-06 00:26:37,640 - INFO - EarlyStopping counter: 2/10
2025-05-06 00:26:37,801 - INFO - Epoch 27/30 - Loss: 1.6784, Acc: 22.22% - Val Loss: 1.7408, Val Acc: 0.00%
2025-05-06 00:26:37,801 - INFO - EarlyStopping counter: 3/10
2025-05-06 00:26:37,965 - INFO - Epoch 28/30 - Loss: 1.6684, Acc: 31.11% - Val Loss: 1.7399, Val Acc: 0.00%
2025-05-06 00:26:38,122 - INFO - Epoch 29/30 - Loss: 1.6727, Acc: 37.78% - Val Loss: 1.7390, Val Acc: 0.00%
2025-05-06 00:26:38,122 - INFO - EarlyStopping counter: 1/10
2025-05-06 00:26:38,291 - INFO - Epoch 30/30 - Loss: 1.6652, Acc: 26.67% - Val Loss: 1.7381, Val Acc: 0.00%
2025-05-06 00:26:38,292 - INFO - Beste Gewichte wiederhergestellt
2025-05-06 00:26:38,292 - INFO - Evaluiere Modell...
2025-05-06 00:26:38,357 - INFO - Genauigkeit: 0.00%
2025-05-06 00:26:38,357 - INFO - Precision: 0.0000
2025-05-06 00:26:38,357 - INFO - Recall: 0.0000
2025-05-06 00:26:38,357 - INFO - F1-Score: 0.0000
2025-05-06 00:26:38,357 - INFO - Messe Inferenzzeit...
2025-05-06 00:26:38,378 - INFO - Durchschnittliche Inferenzzeit auf CPU: 0.17 ms
2025-05-06 00:26:38,378 - INFO - Geschätzte Inferenzzeit auf RP2040: 6.12 ms
2025-05-06 00:26:38,379 - INFO - Modell gespeichert unter: output/hard_swish_comparison/models/micropizzanet_(hard-swish).pth
2025-05-06 00:26:39,197 - INFO - Feature-Maps für MicroPizzaNet (ReLU) gespeichert in output/hard_swish_comparison/micropizzanet_(relu)/activations
2025-05-06 00:26:39,697 - INFO - Feature-Maps für MicroPizzaNet (Hard-Swish) gespeichert in output/hard_swish_comparison/micropizzanet_(hard-swish)/activations
2025-05-06 00:26:40,324 - INFO - 
==================================================
2025-05-06 00:26:40,324 - INFO - ZUSAMMENFASSUNG DES HARD-SWISH VERGLEICHS
2025-05-06 00:26:40,324 - INFO - ==================================================
2025-05-06 00:26:40,324 - INFO - Bestes Modell: MicroPizzaNet (ReLU)
2025-05-06 00:26:40,324 - INFO - - Genauigkeit: 8.33%
2025-05-06 00:26:40,324 - INFO - - F1-Score: 0.0128
2025-05-06 00:26:40,324 - INFO - - Parameter: 582
2025-05-06 00:26:40,324 - INFO - - Modellgröße: 2.5 KB
2025-05-06 00:26:40,324 - INFO - - RAM-Nutzung: 102.1 KB
2025-05-06 00:26:40,324 - INFO - - Inferenzzeit auf RP2040: 4.4 ms
2025-05-06 00:26:40,325 - INFO - 
Verbesserung gegenüber Original:
2025-05-06 00:26:40,325 - INFO - - Genauigkeit: +0.00%
2025-05-06 00:26:40,325 - INFO - 
Ergebnisse gespeichert in:
2025-05-06 00:26:40,325 - INFO - - CSV: output/hard_swish_comparison/hard_swish_comparison_results.csv
2025-05-06 00:26:40,325 - INFO - - Excel: output/hard_swish_comparison/hard_swish_comparison_results.xlsx
2025-05-06 00:26:40,325 - INFO - - HTML-Bericht: output/hard_swish_comparison/hard_swish_comparison_report.html
2025-05-06 11:06:20,315 - INFO - Verwende Gerät: cuda
2025-05-06 11:06:20,316 - INFO - ================================================================================
2025-05-06 11:06:20,316 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:06:20,316 - INFO - ================================================================================
2025-05-06 11:06:20,316 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:06:20,316 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:06:20,316 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:06:20,316 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:06:20,316 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:06:20,316 - INFO - ================================================================================
2025-05-06 11:06:20,316 - INFO - Preparing optimized data loaders...
2025-05-06 11:06:20,317 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:06:20,372 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:06:20,372 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:06:20,373 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:06:20,373 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:06:20,373 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:06:20,373 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:06:20,373 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:06:20,375 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:06:20,375 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:06:20,375 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:06:20,528 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:06:52,160 - INFO - Verwende Gerät: cuda
2025-05-06 11:06:52,160 - INFO - ================================================================================
2025-05-06 11:06:52,160 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:06:52,160 - INFO - ================================================================================
2025-05-06 11:06:52,160 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:06:52,160 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:06:52,160 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:06:52,160 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:06:52,160 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:06:52,160 - INFO - ================================================================================
2025-05-06 11:06:52,160 - INFO - Preparing optimized data loaders...
2025-05-06 11:06:52,161 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:06:52,198 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:06:52,198 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:06:52,198 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:06:52,198 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:06:52,198 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:06:52,198 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:06:52,199 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:06:52,200 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:06:52,200 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:06:52,200 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:06:52,345 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:08:35,522 - INFO - Verwende Gerät: cuda
2025-05-06 11:08:35,522 - INFO - ================================================================================
2025-05-06 11:08:35,522 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:08:35,522 - INFO - ================================================================================
2025-05-06 11:08:35,522 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:08:35,522 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:08:35,522 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:08:35,522 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:08:35,522 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:08:35,522 - INFO - ================================================================================
2025-05-06 11:08:35,522 - INFO - Preparing optimized data loaders...
2025-05-06 11:08:35,523 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:08:35,561 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:08:35,561 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:08:35,561 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:08:35,561 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:08:35,561 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:08:35,561 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:08:35,561 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:08:35,562 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:08:35,563 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:08:35,563 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:08:35,708 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:08:35,990 - INFO - Speicheranalyse:
2025-05-06 11:08:35,990 - INFO -   Modellgröße (Float32): 309.93 KB
2025-05-06 11:08:35,990 - INFO -   Modellgröße (Int8): 77.48 KB (3.8% des Flash)
2025-05-06 11:08:35,990 - INFO -   Aktivierungsspeicher: 341.27 KB
2025-05-06 11:08:35,990 - INFO -   Gesamter Laufzeitspeicher: 418.76 KB (158.6% des RAM)
2025-05-06 11:08:35,990 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (418.76KB > 100KB)
2025-05-06 11:08:36,050 - INFO - Klassengewichte für Loss-Funktion: [0.68, 0.58, 0.58, 0.94, 1.0, 1.0]
2025-05-06 11:08:36,051 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:08:36,596 - INFO - Epoch 1/30 - Train Loss: 1.7948, Train Acc: 17.78% - Val Loss: 1.7805, Val Acc: 66.67%
2025-05-06 11:08:36,596 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:36,596 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:08:36,596 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:36,596 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:08:36,614 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch1.pth
2025-05-06 11:08:36,614 - INFO - Epoche 2: Observer-Learning deaktiviert
2025-05-06 11:08:36,751 - INFO - Epoch 2/30 - Train Loss: 1.7924, Train Acc: 22.22% - Val Loss: 1.7722, Val Acc: 66.67%
2025-05-06 11:08:36,752 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:36,752 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:08:36,752 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:36,752 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:08:36,756 - INFO - Epoche 3: Observer-Learning deaktiviert
2025-05-06 11:08:36,757 - INFO - Epoche 3: Fake-Quantisierung aktiviert
2025-05-06 11:08:36,897 - INFO - Epoch 3/30 - Train Loss: 1.7677, Train Acc: 28.89% - Val Loss: 1.7596, Val Acc: 66.67%
2025-05-06 11:08:36,897 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:36,897 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:08:36,897 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:36,897 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:08:36,901 - INFO - Epoche 4: Observer-Learning deaktiviert
2025-05-06 11:08:36,902 - INFO - Epoche 4: Fake-Quantisierung aktiviert
2025-05-06 11:08:37,044 - INFO - Epoch 4/30 - Train Loss: 1.7524, Train Acc: 22.22% - Val Loss: 1.7436, Val Acc: 66.67%
2025-05-06 11:08:37,044 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:37,044 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:08:37,044 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:37,044 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:08:37,050 - INFO - Epoche 5: Observer-Learning aktiviert
2025-05-06 11:08:37,053 - INFO - Epoche 5: Fake-Quantisierung aktiviert
2025-05-06 11:08:37,224 - INFO - Epoch 5/30 - Train Loss: 1.7298, Train Acc: 33.33% - Val Loss: 1.7263, Val Acc: 66.67%
2025-05-06 11:08:37,224 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:37,224 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:08:37,224 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:37,224 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:08:37,241 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch5.pth
2025-05-06 11:08:37,241 - INFO - Epoche 6: Observer-Learning deaktiviert
2025-05-06 11:08:37,242 - INFO - Epoche 6: Fake-Quantisierung aktiviert
2025-05-06 11:08:37,380 - INFO - Epoch 6/30 - Train Loss: 1.7072, Train Acc: 40.00% - Val Loss: 1.7063, Val Acc: 16.67%
2025-05-06 11:08:37,380 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:37,380 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:08:37,380 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:37,380 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:08:37,384 - INFO - Epoche 7: Observer-Learning deaktiviert
2025-05-06 11:08:37,385 - INFO - Epoche 7: Fake-Quantisierung aktiviert
2025-05-06 11:08:37,523 - INFO - Epoch 7/30 - Train Loss: 1.7001, Train Acc: 37.78% - Val Loss: 1.6948, Val Acc: 8.33%
2025-05-06 11:08:37,523 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:37,523 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:08:37,523 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:37,523 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:08:37,530 - INFO - Epoche 8: Observer-Learning deaktiviert
2025-05-06 11:08:37,533 - INFO - Epoche 8: Fake-Quantisierung aktiviert
2025-05-06 11:08:37,688 - INFO - Epoch 8/30 - Train Loss: 1.6815, Train Acc: 22.22% - Val Loss: 1.6860, Val Acc: 41.67%
2025-05-06 11:08:37,688 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:37,688 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:08:37,688 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:37,688 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:08:37,692 - INFO - Epoche 9: Observer-Learning aktiviert
2025-05-06 11:08:37,694 - INFO - Epoche 9: Fake-Quantisierung aktiviert
2025-05-06 11:08:37,847 - INFO - Epoch 9/30 - Train Loss: 1.6767, Train Acc: 40.00% - Val Loss: 1.6755, Val Acc: 33.33%
2025-05-06 11:08:37,847 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:37,847 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:08:37,847 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:37,847 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:08:37,851 - INFO - Epoche 10: Observer-Learning deaktiviert
2025-05-06 11:08:37,852 - INFO - Epoche 10: Fake-Quantisierung aktiviert
2025-05-06 11:08:37,986 - INFO - Epoch 10/30 - Train Loss: 1.6754, Train Acc: 33.33% - Val Loss: 1.6674, Val Acc: 33.33%
2025-05-06 11:08:37,986 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:37,986 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:08:37,986 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:37,986 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:08:38,001 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch10.pth
2025-05-06 11:08:38,001 - INFO - Epoche 11: Observer-Learning deaktiviert
2025-05-06 11:08:38,002 - INFO - Epoche 11: Fake-Quantisierung aktiviert
2025-05-06 11:08:38,136 - INFO - Epoch 11/30 - Train Loss: 1.6559, Train Acc: 40.00% - Val Loss: 1.6639, Val Acc: 41.67%
2025-05-06 11:08:38,136 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:38,136 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:08:38,137 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:38,137 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:08:38,141 - INFO - Epoche 12: Observer-Learning deaktiviert
2025-05-06 11:08:38,142 - INFO - Epoche 12: Fake-Quantisierung aktiviert
2025-05-06 11:08:38,273 - INFO - Epoch 12/30 - Train Loss: 1.6587, Train Acc: 44.44% - Val Loss: 1.6627, Val Acc: 41.67%
2025-05-06 11:08:38,273 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:38,273 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:08:38,273 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:38,273 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:08:38,277 - INFO - Epoche 13: Observer-Learning aktiviert
2025-05-06 11:08:38,278 - INFO - Epoche 13: Fake-Quantisierung aktiviert
2025-05-06 11:08:38,432 - INFO - Epoch 13/30 - Train Loss: 1.6715, Train Acc: 37.78% - Val Loss: 1.6414, Val Acc: 41.67%
2025-05-06 11:08:38,432 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:38,432 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:08:38,432 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:38,432 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:08:38,437 - INFO - Epoche 14: Observer-Learning deaktiviert
2025-05-06 11:08:38,439 - INFO - Epoche 14: Fake-Quantisierung aktiviert
2025-05-06 11:08:38,582 - INFO - Epoch 14/30 - Train Loss: 1.6511, Train Acc: 46.67% - Val Loss: 1.6374, Val Acc: 58.33%
2025-05-06 11:08:38,582 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:38,582 - INFO -   basic: 87.50% (7/8)
2025-05-06 11:08:38,582 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:38,582 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:08:38,586 - INFO - Epoche 15: Observer-Learning deaktiviert
2025-05-06 11:08:38,588 - INFO - Epoche 15: Fake-Quantisierung aktiviert
2025-05-06 11:08:38,726 - INFO - Epoch 15/30 - Train Loss: 1.6203, Train Acc: 48.89% - Val Loss: 1.6379, Val Acc: 58.33%
2025-05-06 11:08:38,726 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:38,726 - INFO -   basic: 87.50% (7/8)
2025-05-06 11:08:38,726 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:38,726 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:08:38,726 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:08:38,735 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch15.pth
2025-05-06 11:08:38,735 - INFO - Epoche 16: Observer-Learning deaktiviert
2025-05-06 11:08:38,735 - INFO - Epoche 16: Fake-Quantisierung aktiviert
2025-05-06 11:08:38,875 - INFO - Epoch 16/30 - Train Loss: 1.6609, Train Acc: 44.44% - Val Loss: 1.6384, Val Acc: 58.33%
2025-05-06 11:08:38,875 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:38,875 - INFO -   basic: 87.50% (7/8)
2025-05-06 11:08:38,875 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:38,875 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:08:38,875 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:08:38,875 - INFO - Epoche 17: Observer-Learning aktiviert
2025-05-06 11:08:38,876 - INFO - Epoche 17: Fake-Quantisierung aktiviert
2025-05-06 11:08:39,030 - INFO - Epoch 17/30 - Train Loss: 1.6363, Train Acc: 48.89% - Val Loss: 1.6306, Val Acc: 58.33%
2025-05-06 11:08:39,031 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:39,031 - INFO -   basic: 87.50% (7/8)
2025-05-06 11:08:39,031 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:39,031 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:08:39,035 - INFO - Epoche 18: Observer-Learning deaktiviert
2025-05-06 11:08:39,038 - INFO - Epoche 18: Fake-Quantisierung aktiviert
2025-05-06 11:08:39,192 - INFO - Epoch 18/30 - Train Loss: 1.6646, Train Acc: 42.22% - Val Loss: 1.6441, Val Acc: 50.00%
2025-05-06 11:08:39,193 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:39,193 - INFO -   basic: 75.00% (6/8)
2025-05-06 11:08:39,193 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:39,193 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:08:39,193 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:08:39,193 - INFO - Epoche 19: Observer-Learning deaktiviert
2025-05-06 11:08:39,193 - INFO - Epoche 19: Fake-Quantisierung aktiviert
2025-05-06 11:08:39,334 - INFO - Epoch 19/30 - Train Loss: 1.6148, Train Acc: 35.56% - Val Loss: 1.6514, Val Acc: 41.67%
2025-05-06 11:08:39,334 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:39,334 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:08:39,334 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:39,334 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:08:39,334 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:08:39,334 - INFO - Epoche 20: Observer-Learning deaktiviert
2025-05-06 11:08:39,335 - INFO - Epoche 20: Fake-Quantisierung aktiviert
2025-05-06 11:08:39,467 - INFO - Epoch 20/30 - Train Loss: 1.6308, Train Acc: 55.56% - Val Loss: 1.6556, Val Acc: 41.67%
2025-05-06 11:08:39,467 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:39,467 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:08:39,467 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:39,467 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:08:39,468 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:08:39,468 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:08:39,476 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch20.pth
2025-05-06 11:08:39,476 - INFO - Epoche 21: Observer-Learning aktiviert
2025-05-06 11:08:39,477 - INFO - Epoche 21: Fake-Quantisierung aktiviert
2025-05-06 11:08:39,629 - INFO - Epoch 21/30 - Train Loss: 1.6269, Train Acc: 44.44% - Val Loss: 1.6485, Val Acc: 41.67%
2025-05-06 11:08:39,629 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:39,629 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:08:39,629 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:39,629 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:08:39,629 - INFO - EarlyStopping counter: 9/10
2025-05-06 11:08:39,629 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:08:39,629 - INFO - Epoche 22: Observer-Learning deaktiviert
2025-05-06 11:08:39,630 - INFO - Epoche 22: Fake-Quantisierung aktiviert
2025-05-06 11:08:39,767 - INFO - Epoch 22/30 - Train Loss: 1.6168, Train Acc: 51.11% - Val Loss: 1.6534, Val Acc: 41.67%
2025-05-06 11:08:39,767 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:08:39,767 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:08:39,767 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:08:39,768 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:08:39,768 - INFO - EarlyStopping counter: 10/10
2025-05-06 11:08:39,768 - INFO - Early Stopping in Epoche 22
2025-05-06 11:08:39,768 - INFO - Training abgeschlossen in 3.72 Sekunden
2025-05-06 11:08:39,774 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 11:08:39,783 - INFO - Modell gespeichert als: models_optimized/qat_pizza_model.pth
2025-05-06 11:08:40,156 - INFO - Trainingshistorie gespeichert unter output/quantization_aware_training/qat_training_history.png
2025-05-06 11:08:40,156 - INFO - Konvertiere QAT-Modell zu quantisiertem Inferenzmodell...
2025-05-06 11:09:40,990 - INFO - Verwende Gerät: cuda
2025-05-06 11:09:40,990 - INFO - ================================================================================
2025-05-06 11:09:40,990 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:09:40,990 - INFO - ================================================================================
2025-05-06 11:09:40,990 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:09:40,990 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:09:40,990 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:09:40,990 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:09:40,990 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:09:40,990 - INFO - ================================================================================
2025-05-06 11:09:40,990 - INFO - Preparing optimized data loaders...
2025-05-06 11:09:40,990 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:09:41,029 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:09:41,029 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:09:41,029 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:09:41,029 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:09:41,029 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:09:41,029 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:09:41,029 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:09:41,030 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:09:41,030 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:09:41,031 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:10:46,989 - INFO - Verwende Gerät: cuda
2025-05-06 11:10:46,989 - INFO - ================================================================================
2025-05-06 11:10:46,989 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:10:46,989 - INFO - ================================================================================
2025-05-06 11:10:46,989 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:10:46,989 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:10:46,989 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:10:46,989 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:10:46,989 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:10:46,989 - INFO - ================================================================================
2025-05-06 11:10:46,989 - INFO - Preparing optimized data loaders...
2025-05-06 11:10:46,989 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:10:47,025 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:10:47,025 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:10:47,025 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:10:47,025 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:10:47,025 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:10:47,025 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:10:47,025 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:10:47,026 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:10:47,026 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:10:47,026 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:10:47,169 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:10:47,338 - INFO - Speicheranalyse:
2025-05-06 11:10:47,338 - INFO -   Modellgröße (Float32): 309.99 KB
2025-05-06 11:10:47,339 - INFO -   Modellgröße (Int8): 77.50 KB (3.8% des Flash)
2025-05-06 11:10:47,339 - INFO -   Aktivierungsspeicher: 834.67 KB
2025-05-06 11:10:47,339 - INFO -   Gesamter Laufzeitspeicher: 912.17 KB (345.5% des RAM)
2025-05-06 11:10:47,339 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (912.17KB > 100KB)
2025-05-06 11:10:47,406 - INFO - Klassengewichte für Loss-Funktion: [0.75, 0.47, 0.83, 0.75, 1.0, 1.0]
2025-05-06 11:10:47,407 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:10:47,680 - INFO - Epoch 1/30 - Train Loss: 1.7835, Train Acc: 26.67% - Val Loss: 1.7978, Val Acc: 0.00%
2025-05-06 11:10:47,681 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:47,681 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:47,681 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:10:47,681 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:47,684 - INFO - Epoche 2: Observer-Learning deaktiviert
2025-05-06 11:10:47,829 - INFO - Epoch 2/30 - Train Loss: 1.7861, Train Acc: 22.22% - Val Loss: 1.7988, Val Acc: 0.00%
2025-05-06 11:10:47,830 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:47,830 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:47,830 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:10:47,830 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:47,830 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:10:47,830 - INFO - Epoche 3: Observer-Learning deaktiviert
2025-05-06 11:10:47,830 - INFO - Epoche 3: Fake-Quantisierung aktiviert
2025-05-06 11:10:47,966 - INFO - Epoch 3/30 - Train Loss: 1.7722, Train Acc: 26.67% - Val Loss: 1.7960, Val Acc: 0.00%
2025-05-06 11:10:47,966 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:47,966 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:47,966 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:10:47,966 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:47,971 - INFO - Epoche 4: Observer-Learning deaktiviert
2025-05-06 11:10:47,974 - INFO - Epoche 4: Fake-Quantisierung aktiviert
2025-05-06 11:10:48,121 - INFO - Epoch 4/30 - Train Loss: 1.7285, Train Acc: 35.56% - Val Loss: 1.7896, Val Acc: 0.00%
2025-05-06 11:10:48,122 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:48,122 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:48,122 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:10:48,122 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:48,125 - INFO - Epoche 5: Observer-Learning aktiviert
2025-05-06 11:10:48,126 - INFO - Epoche 5: Fake-Quantisierung aktiviert
2025-05-06 11:10:48,289 - INFO - Epoch 5/30 - Train Loss: 1.7191, Train Acc: 37.78% - Val Loss: 1.7764, Val Acc: 0.00%
2025-05-06 11:10:48,289 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:48,289 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:48,289 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:10:48,289 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:48,304 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch5.pth
2025-05-06 11:10:48,304 - INFO - Epoche 6: Observer-Learning deaktiviert
2025-05-06 11:10:48,306 - INFO - Epoche 6: Fake-Quantisierung aktiviert
2025-05-06 11:10:48,473 - INFO - Epoch 6/30 - Train Loss: 1.6984, Train Acc: 37.78% - Val Loss: 1.7586, Val Acc: 0.00%
2025-05-06 11:10:48,474 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:48,474 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:48,474 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:10:48,474 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:48,481 - INFO - Epoche 7: Observer-Learning deaktiviert
2025-05-06 11:10:48,484 - INFO - Epoche 7: Fake-Quantisierung aktiviert
2025-05-06 11:10:48,662 - INFO - Epoch 7/30 - Train Loss: 1.6655, Train Acc: 35.56% - Val Loss: 1.7353, Val Acc: 0.00%
2025-05-06 11:10:48,662 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:48,662 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:48,663 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:10:48,663 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:48,669 - INFO - Epoche 8: Observer-Learning deaktiviert
2025-05-06 11:10:48,670 - INFO - Epoche 8: Fake-Quantisierung aktiviert
2025-05-06 11:10:48,818 - INFO - Epoch 8/30 - Train Loss: 1.6553, Train Acc: 40.00% - Val Loss: 1.7131, Val Acc: 8.33%
2025-05-06 11:10:48,818 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:48,818 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:48,818 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:10:48,818 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:10:48,842 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch8.pth
2025-05-06 11:10:48,842 - INFO - Epoche 9: Observer-Learning aktiviert
2025-05-06 11:10:48,843 - INFO - Epoche 9: Fake-Quantisierung aktiviert
2025-05-06 11:10:49,013 - INFO - Epoch 9/30 - Train Loss: 1.5503, Train Acc: 55.56% - Val Loss: 1.6947, Val Acc: 0.00%
2025-05-06 11:10:49,013 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:49,013 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:49,013 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:10:49,013 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:49,019 - INFO - Epoche 10: Observer-Learning deaktiviert
2025-05-06 11:10:49,021 - INFO - Epoche 10: Fake-Quantisierung aktiviert
2025-05-06 11:10:49,206 - INFO - Epoch 10/30 - Train Loss: 1.5492, Train Acc: 40.00% - Val Loss: 1.6608, Val Acc: 8.33%
2025-05-06 11:10:49,207 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:49,207 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:49,207 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:49,207 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:49,238 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch10.pth
2025-05-06 11:10:49,238 - INFO - Epoche 11: Observer-Learning deaktiviert
2025-05-06 11:10:49,240 - INFO - Epoche 11: Fake-Quantisierung aktiviert
2025-05-06 11:10:49,378 - INFO - Epoch 11/30 - Train Loss: 1.5314, Train Acc: 35.56% - Val Loss: 1.6284, Val Acc: 8.33%
2025-05-06 11:10:49,378 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:49,378 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:49,378 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:49,378 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:49,383 - INFO - Epoche 12: Observer-Learning deaktiviert
2025-05-06 11:10:49,384 - INFO - Epoche 12: Fake-Quantisierung aktiviert
2025-05-06 11:10:49,531 - INFO - Epoch 12/30 - Train Loss: 1.4654, Train Acc: 55.56% - Val Loss: 1.5792, Val Acc: 16.67%
2025-05-06 11:10:49,531 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:49,531 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:10:49,531 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:49,531 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:49,552 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch12.pth
2025-05-06 11:10:49,553 - INFO - Epoche 13: Observer-Learning aktiviert
2025-05-06 11:10:49,553 - INFO - Epoche 13: Fake-Quantisierung aktiviert
2025-05-06 11:10:49,711 - INFO - Epoch 13/30 - Train Loss: 1.4252, Train Acc: 53.33% - Val Loss: 1.5269, Val Acc: 25.00%
2025-05-06 11:10:49,711 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:49,711 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:10:49,711 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:49,711 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:49,723 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch13.pth
2025-05-06 11:10:49,723 - INFO - Epoche 14: Observer-Learning deaktiviert
2025-05-06 11:10:49,724 - INFO - Epoche 14: Fake-Quantisierung aktiviert
2025-05-06 11:10:49,856 - INFO - Epoch 14/30 - Train Loss: 1.4359, Train Acc: 51.11% - Val Loss: 1.4939, Val Acc: 33.33%
2025-05-06 11:10:49,856 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:49,856 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:10:49,856 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:49,856 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:49,874 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch14.pth
2025-05-06 11:10:49,874 - INFO - Epoche 15: Observer-Learning deaktiviert
2025-05-06 11:10:49,875 - INFO - Epoche 15: Fake-Quantisierung aktiviert
2025-05-06 11:10:50,006 - INFO - Epoch 15/30 - Train Loss: 1.3653, Train Acc: 55.56% - Val Loss: 1.4934, Val Acc: 16.67%
2025-05-06 11:10:50,006 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:50,006 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:10:50,006 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:50,006 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:50,006 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:10:50,015 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch15.pth
2025-05-06 11:10:50,015 - INFO - Epoche 16: Observer-Learning deaktiviert
2025-05-06 11:10:50,016 - INFO - Epoche 16: Fake-Quantisierung aktiviert
2025-05-06 11:10:50,156 - INFO - Epoch 16/30 - Train Loss: 1.3755, Train Acc: 44.44% - Val Loss: 1.4926, Val Acc: 8.33%
2025-05-06 11:10:50,156 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:50,156 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:50,156 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:50,156 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:50,160 - INFO - Epoche 17: Observer-Learning aktiviert
2025-05-06 11:10:50,161 - INFO - Epoche 17: Fake-Quantisierung aktiviert
2025-05-06 11:10:50,328 - INFO - Epoch 17/30 - Train Loss: 1.3306, Train Acc: 46.67% - Val Loss: 1.5043, Val Acc: 8.33%
2025-05-06 11:10:50,328 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:50,328 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:50,328 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:50,328 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:50,328 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:10:50,328 - INFO - Epoche 18: Observer-Learning deaktiviert
2025-05-06 11:10:50,329 - INFO - Epoche 18: Fake-Quantisierung aktiviert
2025-05-06 11:10:50,480 - INFO - Epoch 18/30 - Train Loss: 1.4146, Train Acc: 28.89% - Val Loss: 1.5098, Val Acc: 8.33%
2025-05-06 11:10:50,481 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:50,481 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:50,481 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:50,481 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:50,481 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:10:50,481 - INFO - Epoche 19: Observer-Learning deaktiviert
2025-05-06 11:10:50,482 - INFO - Epoche 19: Fake-Quantisierung aktiviert
2025-05-06 11:10:50,625 - INFO - Epoch 19/30 - Train Loss: 1.3095, Train Acc: 46.67% - Val Loss: 1.5150, Val Acc: 8.33%
2025-05-06 11:10:50,625 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:50,625 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:50,625 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:50,625 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:50,625 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:10:50,625 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:10:50,625 - INFO - Epoche 20: Observer-Learning deaktiviert
2025-05-06 11:10:50,626 - INFO - Epoche 20: Fake-Quantisierung aktiviert
2025-05-06 11:10:50,772 - INFO - Epoch 20/30 - Train Loss: 1.2760, Train Acc: 51.11% - Val Loss: 1.4720, Val Acc: 8.33%
2025-05-06 11:10:50,772 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:50,772 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:50,772 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:50,772 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:50,789 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch20.pth
2025-05-06 11:10:50,789 - INFO - Epoche 21: Observer-Learning aktiviert
2025-05-06 11:10:50,790 - INFO - Epoche 21: Fake-Quantisierung aktiviert
2025-05-06 11:10:50,949 - INFO - Epoch 21/30 - Train Loss: 1.2392, Train Acc: 51.11% - Val Loss: 1.4533, Val Acc: 8.33%
2025-05-06 11:10:50,949 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:50,949 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:50,950 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:50,950 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:50,953 - INFO - Epoche 22: Observer-Learning deaktiviert
2025-05-06 11:10:50,954 - INFO - Epoche 22: Fake-Quantisierung aktiviert
2025-05-06 11:10:51,099 - INFO - Epoch 22/30 - Train Loss: 1.2725, Train Acc: 46.67% - Val Loss: 1.4331, Val Acc: 8.33%
2025-05-06 11:10:51,099 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:51,099 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:51,099 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:51,099 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:51,103 - INFO - Epoche 23: Observer-Learning deaktiviert
2025-05-06 11:10:51,106 - INFO - Epoche 23: Fake-Quantisierung aktiviert
2025-05-06 11:10:51,242 - INFO - Epoch 23/30 - Train Loss: 1.2548, Train Acc: 55.56% - Val Loss: 1.4473, Val Acc: 8.33%
2025-05-06 11:10:51,242 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:51,242 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:51,242 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:51,242 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:51,242 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:10:51,242 - INFO - Epoche 24: Observer-Learning deaktiviert
2025-05-06 11:10:51,243 - INFO - Epoche 24: Fake-Quantisierung aktiviert
2025-05-06 11:10:51,377 - INFO - Epoch 24/30 - Train Loss: 1.3080, Train Acc: 48.89% - Val Loss: 1.3942, Val Acc: 16.67%
2025-05-06 11:10:51,377 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:51,377 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:10:51,377 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:51,377 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:51,381 - INFO - Epoche 25: Observer-Learning aktiviert
2025-05-06 11:10:51,382 - INFO - Epoche 25: Fake-Quantisierung aktiviert
2025-05-06 11:10:51,554 - INFO - Epoch 25/30 - Train Loss: 1.1941, Train Acc: 57.78% - Val Loss: 1.3778, Val Acc: 8.33%
2025-05-06 11:10:51,554 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:51,554 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:51,554 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:51,554 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:51,567 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch25.pth
2025-05-06 11:10:51,567 - INFO - Epoche 26: Observer-Learning deaktiviert
2025-05-06 11:10:51,567 - INFO - Epoche 26: Fake-Quantisierung aktiviert
2025-05-06 11:10:51,707 - INFO - Epoch 26/30 - Train Loss: 1.2520, Train Acc: 42.22% - Val Loss: 1.4126, Val Acc: 8.33%
2025-05-06 11:10:51,707 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:51,707 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:51,707 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:51,707 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:51,707 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:10:51,707 - INFO - Epoche 27: Observer-Learning deaktiviert
2025-05-06 11:10:51,708 - INFO - Epoche 27: Fake-Quantisierung aktiviert
2025-05-06 11:10:51,837 - INFO - Epoch 27/30 - Train Loss: 1.2517, Train Acc: 53.33% - Val Loss: 1.3925, Val Acc: 8.33%
2025-05-06 11:10:51,837 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:51,837 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:10:51,837 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:51,837 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:51,837 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:10:51,837 - INFO - Epoche 28: Observer-Learning deaktiviert
2025-05-06 11:10:51,838 - INFO - Epoche 28: Fake-Quantisierung aktiviert
2025-05-06 11:10:51,972 - INFO - Epoch 28/30 - Train Loss: 1.2290, Train Acc: 48.89% - Val Loss: 1.3618, Val Acc: 16.67%
2025-05-06 11:10:51,972 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:51,973 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:10:51,973 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:51,973 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:51,976 - INFO - Epoche 29: Observer-Learning aktiviert
2025-05-06 11:10:51,977 - INFO - Epoche 29: Fake-Quantisierung aktiviert
2025-05-06 11:10:52,144 - INFO - Epoch 29/30 - Train Loss: 1.1928, Train Acc: 60.00% - Val Loss: 1.3515, Val Acc: 16.67%
2025-05-06 11:10:52,144 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:52,144 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:10:52,144 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:52,144 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:52,148 - INFO - Epoche 30: Observer-Learning deaktiviert
2025-05-06 11:10:52,149 - INFO - Epoche 30: Fake-Quantisierung aktiviert
2025-05-06 11:10:52,302 - INFO - Epoch 30/30 - Train Loss: 1.2518, Train Acc: 53.33% - Val Loss: 1.3067, Val Acc: 25.00%
2025-05-06 11:10:52,302 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:10:52,302 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:10:52,302 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:10:52,302 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:10:52,329 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch30.pth
2025-05-06 11:10:52,329 - INFO - Training abgeschlossen in 4.92 Sekunden
2025-05-06 11:10:52,336 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 11:10:52,344 - INFO - Modell gespeichert als: models_optimized/qat_pizza_model.pth
2025-05-06 11:10:52,655 - INFO - Trainingshistorie gespeichert unter output/quantization_aware_training/qat_training_history.png
2025-05-06 11:10:52,655 - INFO - Konvertiere QAT-Modell zu quantisiertem Inferenzmodell...
2025-05-06 11:12:11,355 - INFO - Verwende Gerät: cuda
2025-05-06 11:12:11,355 - INFO - ================================================================================
2025-05-06 11:12:11,355 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:12:11,355 - INFO - ================================================================================
2025-05-06 11:12:11,355 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:12:11,355 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:12:11,355 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:12:11,355 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:12:11,355 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:12:11,355 - INFO - ================================================================================
2025-05-06 11:12:11,355 - INFO - Preparing optimized data loaders...
2025-05-06 11:12:11,355 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:12:11,392 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:12:11,392 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:12:11,392 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:12:11,392 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:12:11,393 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:12:11,393 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:12:11,393 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:12:11,394 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:12:11,394 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:12:11,394 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:12:11,537 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:12:11,711 - INFO - Speicheranalyse:
2025-05-06 11:12:11,711 - INFO -   Modellgröße (Float32): 309.99 KB
2025-05-06 11:12:11,711 - INFO -   Modellgröße (Int8): 77.50 KB (3.8% des Flash)
2025-05-06 11:12:11,711 - INFO -   Aktivierungsspeicher: 834.67 KB
2025-05-06 11:12:11,711 - INFO -   Gesamter Laufzeitspeicher: 912.17 KB (345.5% des RAM)
2025-05-06 11:12:11,711 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (912.17KB > 100KB)
2025-05-06 11:12:11,769 - INFO - Klassengewichte für Loss-Funktion: [0.94, 0.5, 0.68, 0.68, 1.0, 1.0]
2025-05-06 11:12:11,770 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:12:12,047 - INFO - Epoch 1/30 - Train Loss: 1.7846, Train Acc: 17.78% - Val Loss: 1.7866, Val Acc: 8.33%
2025-05-06 11:12:12,047 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:12,047 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:12:12,047 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:12:12,047 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:12,067 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch1.pth
2025-05-06 11:12:12,067 - INFO - Epoche 2: Observer-Learning deaktiviert
2025-05-06 11:12:12,226 - INFO - Epoch 2/30 - Train Loss: 1.7854, Train Acc: 15.56% - Val Loss: 1.7799, Val Acc: 8.33%
2025-05-06 11:12:12,226 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:12,226 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:12:12,226 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:12:12,226 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:12,230 - INFO - Epoche 3: Observer-Learning deaktiviert
2025-05-06 11:12:12,232 - INFO - Epoche 3: Fake-Quantisierung aktiviert
2025-05-06 11:12:12,386 - INFO - Epoch 3/30 - Train Loss: 1.7872, Train Acc: 17.78% - Val Loss: 1.7697, Val Acc: 8.33%
2025-05-06 11:12:12,386 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:12,386 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:12:12,386 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:12:12,386 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:12,390 - INFO - Epoche 4: Observer-Learning deaktiviert
2025-05-06 11:12:12,391 - INFO - Epoche 4: Fake-Quantisierung aktiviert
2025-05-06 11:12:12,539 - INFO - Epoch 4/30 - Train Loss: 1.7617, Train Acc: 15.56% - Val Loss: 1.7554, Val Acc: 8.33%
2025-05-06 11:12:12,539 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:12,539 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:12:12,539 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:12:12,539 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:12,543 - INFO - Epoche 5: Observer-Learning aktiviert
2025-05-06 11:12:12,545 - INFO - Epoche 5: Fake-Quantisierung aktiviert
2025-05-06 11:12:12,715 - INFO - Epoch 5/30 - Train Loss: 1.7247, Train Acc: 33.33% - Val Loss: 1.7314, Val Acc: 8.33%
2025-05-06 11:12:12,715 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:12,715 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:12:12,715 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:12:12,715 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:12,729 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch5.pth
2025-05-06 11:12:12,729 - INFO - Epoche 6: Observer-Learning deaktiviert
2025-05-06 11:12:12,730 - INFO - Epoche 6: Fake-Quantisierung aktiviert
2025-05-06 11:12:12,875 - INFO - Epoch 6/30 - Train Loss: 1.6836, Train Acc: 33.33% - Val Loss: 1.7015, Val Acc: 8.33%
2025-05-06 11:12:12,876 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:12,876 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:12:12,876 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:12:12,876 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:12,880 - INFO - Epoche 7: Observer-Learning deaktiviert
2025-05-06 11:12:12,881 - INFO - Epoche 7: Fake-Quantisierung aktiviert
2025-05-06 11:12:13,033 - INFO - Epoch 7/30 - Train Loss: 1.6759, Train Acc: 28.89% - Val Loss: 1.6569, Val Acc: 8.33%
2025-05-06 11:12:13,033 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:13,033 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:12:13,033 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:12:13,033 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:13,038 - INFO - Epoche 8: Observer-Learning deaktiviert
2025-05-06 11:12:13,039 - INFO - Epoche 8: Fake-Quantisierung aktiviert
2025-05-06 11:12:13,186 - INFO - Epoch 8/30 - Train Loss: 1.6331, Train Acc: 28.89% - Val Loss: 1.6055, Val Acc: 75.00%
2025-05-06 11:12:13,186 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:13,186 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:12:13,186 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:13,186 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:12:13,199 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch8.pth
2025-05-06 11:12:13,199 - INFO - Epoche 9: Observer-Learning aktiviert
2025-05-06 11:12:13,200 - INFO - Epoche 9: Fake-Quantisierung aktiviert
2025-05-06 11:12:13,368 - INFO - Epoch 9/30 - Train Loss: 1.5979, Train Acc: 20.00% - Val Loss: 1.5681, Val Acc: 16.67%
2025-05-06 11:12:13,368 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:13,368 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:12:13,368 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:13,368 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:13,372 - INFO - Epoche 10: Observer-Learning deaktiviert
2025-05-06 11:12:13,373 - INFO - Epoche 10: Fake-Quantisierung aktiviert
2025-05-06 11:12:13,516 - INFO - Epoch 10/30 - Train Loss: 1.5512, Train Acc: 31.11% - Val Loss: 1.5310, Val Acc: 16.67%
2025-05-06 11:12:13,516 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:13,516 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:12:13,516 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:13,516 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:13,534 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch10.pth
2025-05-06 11:12:13,534 - INFO - Epoche 11: Observer-Learning deaktiviert
2025-05-06 11:12:13,534 - INFO - Epoche 11: Fake-Quantisierung aktiviert
2025-05-06 11:12:13,675 - INFO - Epoch 11/30 - Train Loss: 1.4629, Train Acc: 44.44% - Val Loss: 1.4935, Val Acc: 16.67%
2025-05-06 11:12:13,676 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:13,676 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:12:13,676 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:13,676 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:13,680 - INFO - Epoche 12: Observer-Learning deaktiviert
2025-05-06 11:12:13,681 - INFO - Epoche 12: Fake-Quantisierung aktiviert
2025-05-06 11:12:13,824 - INFO - Epoch 12/30 - Train Loss: 1.5075, Train Acc: 28.89% - Val Loss: 1.4532, Val Acc: 16.67%
2025-05-06 11:12:13,824 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:13,824 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:12:13,824 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:13,824 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:13,828 - INFO - Epoche 13: Observer-Learning aktiviert
2025-05-06 11:12:13,829 - INFO - Epoche 13: Fake-Quantisierung aktiviert
2025-05-06 11:12:14,000 - INFO - Epoch 13/30 - Train Loss: 1.4350, Train Acc: 35.56% - Val Loss: 1.4020, Val Acc: 16.67%
2025-05-06 11:12:14,000 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:14,000 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:12:14,001 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:14,001 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:14,005 - INFO - Epoche 14: Observer-Learning deaktiviert
2025-05-06 11:12:14,007 - INFO - Epoche 14: Fake-Quantisierung aktiviert
2025-05-06 11:12:14,167 - INFO - Epoch 14/30 - Train Loss: 1.4677, Train Acc: 35.56% - Val Loss: 1.3658, Val Acc: 25.00%
2025-05-06 11:12:14,167 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:14,167 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:12:14,167 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:14,167 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:14,171 - INFO - Epoche 15: Observer-Learning deaktiviert
2025-05-06 11:12:14,172 - INFO - Epoche 15: Fake-Quantisierung aktiviert
2025-05-06 11:12:14,314 - INFO - Epoch 15/30 - Train Loss: 1.4143, Train Acc: 40.00% - Val Loss: 1.3421, Val Acc: 41.67%
2025-05-06 11:12:14,314 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:14,314 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:12:14,314 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:14,314 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:14,346 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch15.pth
2025-05-06 11:12:14,347 - INFO - Epoche 16: Observer-Learning deaktiviert
2025-05-06 11:12:14,347 - INFO - Epoche 16: Fake-Quantisierung aktiviert
2025-05-06 11:12:14,484 - INFO - Epoch 16/30 - Train Loss: 1.4202, Train Acc: 33.33% - Val Loss: 1.3212, Val Acc: 41.67%
2025-05-06 11:12:14,484 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:14,484 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:12:14,484 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:14,484 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:14,488 - INFO - Epoche 17: Observer-Learning aktiviert
2025-05-06 11:12:14,490 - INFO - Epoche 17: Fake-Quantisierung aktiviert
2025-05-06 11:12:14,664 - INFO - Epoch 17/30 - Train Loss: 1.2578, Train Acc: 66.67% - Val Loss: 1.2963, Val Acc: 50.00%
2025-05-06 11:12:14,665 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:14,665 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:12:14,665 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:14,665 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:14,669 - INFO - Epoche 18: Observer-Learning deaktiviert
2025-05-06 11:12:14,671 - INFO - Epoche 18: Fake-Quantisierung aktiviert
2025-05-06 11:12:14,838 - INFO - Epoch 18/30 - Train Loss: 1.3496, Train Acc: 40.00% - Val Loss: 1.2777, Val Acc: 50.00%
2025-05-06 11:12:14,838 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:14,838 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:12:14,838 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:14,838 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:14,843 - INFO - Epoche 19: Observer-Learning deaktiviert
2025-05-06 11:12:14,844 - INFO - Epoche 19: Fake-Quantisierung aktiviert
2025-05-06 11:12:14,995 - INFO - Epoch 19/30 - Train Loss: 1.2726, Train Acc: 51.11% - Val Loss: 1.2674, Val Acc: 50.00%
2025-05-06 11:12:14,995 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:14,995 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:12:14,995 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:14,995 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:14,999 - INFO - Epoche 20: Observer-Learning deaktiviert
2025-05-06 11:12:15,000 - INFO - Epoche 20: Fake-Quantisierung aktiviert
2025-05-06 11:12:15,142 - INFO - Epoch 20/30 - Train Loss: 1.2433, Train Acc: 48.89% - Val Loss: 1.2472, Val Acc: 58.33%
2025-05-06 11:12:15,142 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:15,142 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:12:15,142 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:15,142 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:12:15,154 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch20.pth
2025-05-06 11:12:15,155 - INFO - Epoche 21: Observer-Learning aktiviert
2025-05-06 11:12:15,155 - INFO - Epoche 21: Fake-Quantisierung aktiviert
2025-05-06 11:12:15,316 - INFO - Epoch 21/30 - Train Loss: 1.2720, Train Acc: 60.00% - Val Loss: 1.2276, Val Acc: 50.00%
2025-05-06 11:12:15,316 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:15,316 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:12:15,316 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:15,316 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:12:15,320 - INFO - Epoche 22: Observer-Learning deaktiviert
2025-05-06 11:12:15,320 - INFO - Epoche 22: Fake-Quantisierung aktiviert
2025-05-06 11:12:15,485 - INFO - Epoch 22/30 - Train Loss: 1.2574, Train Acc: 44.44% - Val Loss: 1.2018, Val Acc: 66.67%
2025-05-06 11:12:15,485 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:15,485 - INFO -   basic: 87.50% (7/8)
2025-05-06 11:12:15,485 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:15,485 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:12:15,490 - INFO - Epoche 23: Observer-Learning deaktiviert
2025-05-06 11:12:15,492 - INFO - Epoche 23: Fake-Quantisierung aktiviert
2025-05-06 11:12:15,650 - INFO - Epoch 23/30 - Train Loss: 1.1798, Train Acc: 60.00% - Val Loss: 1.2094, Val Acc: 58.33%
2025-05-06 11:12:15,650 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:15,650 - INFO -   basic: 75.00% (6/8)
2025-05-06 11:12:15,650 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:15,650 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:12:15,650 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:12:15,650 - INFO - Epoche 24: Observer-Learning deaktiviert
2025-05-06 11:12:15,651 - INFO - Epoche 24: Fake-Quantisierung aktiviert
2025-05-06 11:12:15,791 - INFO - Epoch 24/30 - Train Loss: 1.2797, Train Acc: 57.78% - Val Loss: 1.2051, Val Acc: 58.33%
2025-05-06 11:12:15,792 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:15,792 - INFO -   basic: 75.00% (6/8)
2025-05-06 11:12:15,792 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:15,792 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:12:15,792 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:12:15,792 - INFO - Epoche 25: Observer-Learning aktiviert
2025-05-06 11:12:15,792 - INFO - Epoche 25: Fake-Quantisierung aktiviert
2025-05-06 11:12:15,965 - INFO - Epoch 25/30 - Train Loss: 1.2925, Train Acc: 44.44% - Val Loss: 1.2332, Val Acc: 58.33%
2025-05-06 11:12:15,965 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:15,965 - INFO -   basic: 75.00% (6/8)
2025-05-06 11:12:15,965 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:15,965 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:12:15,965 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:12:15,965 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:12:15,974 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch25.pth
2025-05-06 11:12:15,974 - INFO - Epoche 26: Observer-Learning deaktiviert
2025-05-06 11:12:15,975 - INFO - Epoche 26: Fake-Quantisierung aktiviert
2025-05-06 11:12:16,115 - INFO - Epoch 26/30 - Train Loss: 1.2673, Train Acc: 60.00% - Val Loss: 1.2002, Val Acc: 66.67%
2025-05-06 11:12:16,116 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:16,116 - INFO -   basic: 87.50% (7/8)
2025-05-06 11:12:16,116 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:16,116 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:12:16,119 - INFO - Epoche 27: Observer-Learning deaktiviert
2025-05-06 11:12:16,120 - INFO - Epoche 27: Fake-Quantisierung aktiviert
2025-05-06 11:12:16,267 - INFO - Epoch 27/30 - Train Loss: 1.2304, Train Acc: 51.11% - Val Loss: 1.2098, Val Acc: 58.33%
2025-05-06 11:12:16,267 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:16,267 - INFO -   basic: 75.00% (6/8)
2025-05-06 11:12:16,267 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:16,267 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:12:16,267 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:12:16,267 - INFO - Epoche 28: Observer-Learning deaktiviert
2025-05-06 11:12:16,268 - INFO - Epoche 28: Fake-Quantisierung aktiviert
2025-05-06 11:12:16,415 - INFO - Epoch 28/30 - Train Loss: 1.2355, Train Acc: 48.89% - Val Loss: 1.2083, Val Acc: 58.33%
2025-05-06 11:12:16,415 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:16,415 - INFO -   basic: 75.00% (6/8)
2025-05-06 11:12:16,415 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:16,415 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:12:16,415 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:12:16,415 - INFO - Epoche 29: Observer-Learning aktiviert
2025-05-06 11:12:16,416 - INFO - Epoche 29: Fake-Quantisierung aktiviert
2025-05-06 11:12:16,583 - INFO - Epoch 29/30 - Train Loss: 1.2215, Train Acc: 44.44% - Val Loss: 1.2008, Val Acc: 66.67%
2025-05-06 11:12:16,584 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:16,584 - INFO -   basic: 87.50% (7/8)
2025-05-06 11:12:16,584 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:16,584 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:12:16,584 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:12:16,584 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:12:16,584 - INFO - Epoche 30: Observer-Learning deaktiviert
2025-05-06 11:12:16,584 - INFO - Epoche 30: Fake-Quantisierung aktiviert
2025-05-06 11:12:16,729 - INFO - Epoch 30/30 - Train Loss: 1.3251, Train Acc: 37.78% - Val Loss: 1.2047, Val Acc: 58.33%
2025-05-06 11:12:16,729 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:12:16,729 - INFO -   basic: 75.00% (6/8)
2025-05-06 11:12:16,729 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:12:16,729 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:12:16,729 - INFO - EarlyStopping counter: 9/10
2025-05-06 11:12:16,738 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch30.pth
2025-05-06 11:12:16,738 - INFO - Training abgeschlossen in 4.97 Sekunden
2025-05-06 11:12:16,743 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 11:12:16,751 - INFO - Modell gespeichert als: models_optimized/qat_pizza_model.pth
2025-05-06 11:12:17,071 - INFO - Trainingshistorie gespeichert unter output/quantization_aware_training/qat_training_history.png
2025-05-06 11:12:17,071 - INFO - Konvertiere QAT-Modell zu quantisiertem Inferenzmodell...
2025-05-06 11:12:17,107 - INFO - Quantisiertes Modell gespeichert als: models_optimized/pizza_model_int8_qat.pth
2025-05-06 11:12:17,107 - INFO - Quantisierte Modellgröße: 126.08 KB
2025-05-06 11:12:17,107 - INFO - Evaluiere quantisiertes Modell...
2025-05-06 11:14:42,104 - INFO - Verwende Gerät: cuda
2025-05-06 11:14:42,104 - INFO - ================================================================================
2025-05-06 11:14:42,104 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:14:42,104 - INFO - ================================================================================
2025-05-06 11:14:42,104 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:14:42,104 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:14:42,104 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:14:42,104 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:14:42,104 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:14:42,104 - INFO - ================================================================================
2025-05-06 11:14:42,104 - INFO - Preparing optimized data loaders...
2025-05-06 11:14:42,105 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:14:42,142 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:14:42,142 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:14:42,143 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:14:42,143 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:14:42,143 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:14:42,143 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:14:42,143 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:14:42,144 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:14:42,144 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:14:42,144 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:14:42,289 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:14:42,464 - INFO - Speicheranalyse:
2025-05-06 11:14:42,464 - INFO -   Modellgröße (Float32): 309.99 KB
2025-05-06 11:14:42,464 - INFO -   Modellgröße (Int8): 77.50 KB (3.8% des Flash)
2025-05-06 11:14:42,464 - INFO -   Aktivierungsspeicher: 834.67 KB
2025-05-06 11:14:42,464 - INFO -   Gesamter Laufzeitspeicher: 912.17 KB (345.5% des RAM)
2025-05-06 11:14:42,464 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (912.17KB > 100KB)
2025-05-06 11:14:42,527 - INFO - Klassengewichte für Loss-Funktion: [0.83, 0.68, 0.62, 0.58, 1.0, 1.0]
2025-05-06 11:14:42,528 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:14:42,805 - INFO - Epoch 1/30 - Train Loss: 1.7993, Train Acc: 13.33% - Val Loss: 1.8016, Val Acc: 0.00%
2025-05-06 11:14:42,805 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:42,805 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:14:42,805 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:42,805 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:42,809 - INFO - Epoche 2: Observer-Learning deaktiviert
2025-05-06 11:14:42,952 - INFO - Epoch 2/30 - Train Loss: 1.8097, Train Acc: 6.67% - Val Loss: 1.8063, Val Acc: 0.00%
2025-05-06 11:14:42,952 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:42,952 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:14:42,952 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:42,952 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:42,952 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:14:42,952 - INFO - Epoche 3: Observer-Learning deaktiviert
2025-05-06 11:14:42,953 - INFO - Epoche 3: Fake-Quantisierung aktiviert
2025-05-06 11:14:43,099 - INFO - Epoch 3/30 - Train Loss: 1.7980, Train Acc: 11.11% - Val Loss: 1.8068, Val Acc: 0.00%
2025-05-06 11:14:43,100 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:43,100 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:14:43,100 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:43,100 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:43,100 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:14:43,100 - INFO - Epoche 4: Observer-Learning deaktiviert
2025-05-06 11:14:43,101 - INFO - Epoche 4: Fake-Quantisierung aktiviert
2025-05-06 11:14:43,242 - INFO - Epoch 4/30 - Train Loss: 1.7837, Train Acc: 37.78% - Val Loss: 1.7989, Val Acc: 8.33%
2025-05-06 11:14:43,242 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:43,242 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:14:43,242 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:14:43,242 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:43,261 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch4.pth
2025-05-06 11:14:43,261 - INFO - Epoche 5: Observer-Learning aktiviert
2025-05-06 11:14:43,263 - INFO - Epoche 5: Fake-Quantisierung aktiviert
2025-05-06 11:14:43,435 - INFO - Epoch 5/30 - Train Loss: 1.7724, Train Acc: 17.78% - Val Loss: 1.7817, Val Acc: 0.00%
2025-05-06 11:14:43,435 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:43,435 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:14:43,435 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:43,435 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:43,458 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch5.pth
2025-05-06 11:14:43,458 - INFO - Epoche 6: Observer-Learning deaktiviert
2025-05-06 11:14:43,459 - INFO - Epoche 6: Fake-Quantisierung aktiviert
2025-05-06 11:14:43,599 - INFO - Epoch 6/30 - Train Loss: 1.7271, Train Acc: 37.78% - Val Loss: 1.7443, Val Acc: 0.00%
2025-05-06 11:14:43,599 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:43,599 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:14:43,599 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:43,599 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:43,603 - INFO - Epoche 7: Observer-Learning deaktiviert
2025-05-06 11:14:43,603 - INFO - Epoche 7: Fake-Quantisierung aktiviert
2025-05-06 11:14:43,748 - INFO - Epoch 7/30 - Train Loss: 1.6677, Train Acc: 37.78% - Val Loss: 1.6880, Val Acc: 66.67%
2025-05-06 11:14:43,748 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:43,748 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:43,748 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:43,748 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:43,763 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch7.pth
2025-05-06 11:14:43,764 - INFO - Epoche 8: Observer-Learning deaktiviert
2025-05-06 11:14:43,764 - INFO - Epoche 8: Fake-Quantisierung aktiviert
2025-05-06 11:14:43,908 - INFO - Epoch 8/30 - Train Loss: 1.6807, Train Acc: 33.33% - Val Loss: 1.6373, Val Acc: 66.67%
2025-05-06 11:14:43,908 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:43,908 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:43,908 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:43,908 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:43,913 - INFO - Epoche 9: Observer-Learning aktiviert
2025-05-06 11:14:43,914 - INFO - Epoche 9: Fake-Quantisierung aktiviert
2025-05-06 11:14:44,089 - INFO - Epoch 9/30 - Train Loss: 1.5635, Train Acc: 42.22% - Val Loss: 1.5538, Val Acc: 66.67%
2025-05-06 11:14:44,089 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:44,089 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:44,089 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:44,089 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:44,093 - INFO - Epoche 10: Observer-Learning deaktiviert
2025-05-06 11:14:44,094 - INFO - Epoche 10: Fake-Quantisierung aktiviert
2025-05-06 11:14:44,238 - INFO - Epoch 10/30 - Train Loss: 1.5286, Train Acc: 48.89% - Val Loss: 1.4677, Val Acc: 66.67%
2025-05-06 11:14:44,238 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:44,238 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:44,238 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:44,238 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:44,254 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch10.pth
2025-05-06 11:14:44,254 - INFO - Epoche 11: Observer-Learning deaktiviert
2025-05-06 11:14:44,255 - INFO - Epoche 11: Fake-Quantisierung aktiviert
2025-05-06 11:14:44,404 - INFO - Epoch 11/30 - Train Loss: 1.4930, Train Acc: 40.00% - Val Loss: 1.4094, Val Acc: 66.67%
2025-05-06 11:14:44,404 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:44,404 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:44,404 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:44,404 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:44,409 - INFO - Epoche 12: Observer-Learning deaktiviert
2025-05-06 11:14:44,410 - INFO - Epoche 12: Fake-Quantisierung aktiviert
2025-05-06 11:14:44,560 - INFO - Epoch 12/30 - Train Loss: 1.4888, Train Acc: 42.22% - Val Loss: 1.3676, Val Acc: 66.67%
2025-05-06 11:14:44,560 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:44,561 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:44,561 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:44,561 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:44,564 - INFO - Epoche 13: Observer-Learning aktiviert
2025-05-06 11:14:44,565 - INFO - Epoche 13: Fake-Quantisierung aktiviert
2025-05-06 11:14:44,734 - INFO - Epoch 13/30 - Train Loss: 1.3526, Train Acc: 53.33% - Val Loss: 1.2700, Val Acc: 66.67%
2025-05-06 11:14:44,734 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:44,734 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:44,734 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:44,734 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:44,738 - INFO - Epoche 14: Observer-Learning deaktiviert
2025-05-06 11:14:44,740 - INFO - Epoche 14: Fake-Quantisierung aktiviert
2025-05-06 11:14:44,898 - INFO - Epoch 14/30 - Train Loss: 1.3151, Train Acc: 53.33% - Val Loss: 1.2244, Val Acc: 66.67%
2025-05-06 11:14:44,898 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:44,898 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:44,898 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:44,898 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:44,902 - INFO - Epoche 15: Observer-Learning deaktiviert
2025-05-06 11:14:44,903 - INFO - Epoche 15: Fake-Quantisierung aktiviert
2025-05-06 11:14:45,050 - INFO - Epoch 15/30 - Train Loss: 1.3579, Train Acc: 51.11% - Val Loss: 1.1809, Val Acc: 66.67%
2025-05-06 11:14:45,050 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:45,050 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:45,050 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:45,050 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:45,067 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch15.pth
2025-05-06 11:14:45,067 - INFO - Epoche 16: Observer-Learning deaktiviert
2025-05-06 11:14:45,068 - INFO - Epoche 16: Fake-Quantisierung aktiviert
2025-05-06 11:14:45,211 - INFO - Epoch 16/30 - Train Loss: 1.3009, Train Acc: 46.67% - Val Loss: 1.1492, Val Acc: 66.67%
2025-05-06 11:14:45,211 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:45,211 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:45,211 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:45,211 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:45,215 - INFO - Epoche 17: Observer-Learning aktiviert
2025-05-06 11:14:45,215 - INFO - Epoche 17: Fake-Quantisierung aktiviert
2025-05-06 11:14:45,389 - INFO - Epoch 17/30 - Train Loss: 1.2532, Train Acc: 51.11% - Val Loss: 1.1138, Val Acc: 66.67%
2025-05-06 11:14:45,389 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:45,389 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:45,389 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:45,389 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:45,393 - INFO - Epoche 18: Observer-Learning deaktiviert
2025-05-06 11:14:45,394 - INFO - Epoche 18: Fake-Quantisierung aktiviert
2025-05-06 11:14:45,546 - INFO - Epoch 18/30 - Train Loss: 1.2578, Train Acc: 48.89% - Val Loss: 1.0848, Val Acc: 66.67%
2025-05-06 11:14:45,546 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:45,546 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:45,546 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:45,546 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:45,550 - INFO - Epoche 19: Observer-Learning deaktiviert
2025-05-06 11:14:45,553 - INFO - Epoche 19: Fake-Quantisierung aktiviert
2025-05-06 11:14:45,710 - INFO - Epoch 19/30 - Train Loss: 1.1510, Train Acc: 57.78% - Val Loss: 1.0617, Val Acc: 66.67%
2025-05-06 11:14:45,710 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:45,710 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:45,710 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:14:45,710 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:45,714 - INFO - Epoche 20: Observer-Learning deaktiviert
2025-05-06 11:14:45,716 - INFO - Epoche 20: Fake-Quantisierung aktiviert
2025-05-06 11:14:45,874 - INFO - Epoch 20/30 - Train Loss: 1.2158, Train Acc: 46.67% - Val Loss: 1.0800, Val Acc: 75.00%
2025-05-06 11:14:45,874 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:45,874 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:45,874 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:14:45,874 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:45,874 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:14:45,883 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch20.pth
2025-05-06 11:14:45,883 - INFO - Epoche 21: Observer-Learning aktiviert
2025-05-06 11:14:45,884 - INFO - Epoche 21: Fake-Quantisierung aktiviert
2025-05-06 11:14:46,054 - INFO - Epoch 21/30 - Train Loss: 1.2758, Train Acc: 44.44% - Val Loss: 1.0801, Val Acc: 75.00%
2025-05-06 11:14:46,054 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:46,055 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:46,055 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:14:46,055 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:46,055 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:14:46,055 - INFO - Epoche 22: Observer-Learning deaktiviert
2025-05-06 11:14:46,055 - INFO - Epoche 22: Fake-Quantisierung aktiviert
2025-05-06 11:14:46,215 - INFO - Epoch 22/30 - Train Loss: 1.2884, Train Acc: 37.78% - Val Loss: 1.0486, Val Acc: 75.00%
2025-05-06 11:14:46,216 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:46,216 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:46,216 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:14:46,216 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:46,220 - INFO - Epoche 23: Observer-Learning deaktiviert
2025-05-06 11:14:46,221 - INFO - Epoche 23: Fake-Quantisierung aktiviert
2025-05-06 11:14:46,380 - INFO - Epoch 23/30 - Train Loss: 1.1946, Train Acc: 48.89% - Val Loss: 1.0694, Val Acc: 75.00%
2025-05-06 11:14:46,380 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:46,380 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:46,380 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:14:46,380 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:46,381 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:14:46,381 - INFO - Epoche 24: Observer-Learning deaktiviert
2025-05-06 11:14:46,382 - INFO - Epoche 24: Fake-Quantisierung aktiviert
2025-05-06 11:14:46,533 - INFO - Epoch 24/30 - Train Loss: 1.1485, Train Acc: 53.33% - Val Loss: 1.0911, Val Acc: 75.00%
2025-05-06 11:14:46,533 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:46,533 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:46,533 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:14:46,533 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:46,533 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:14:46,533 - INFO - Epoche 25: Observer-Learning aktiviert
2025-05-06 11:14:46,534 - INFO - Epoche 25: Fake-Quantisierung aktiviert
2025-05-06 11:14:46,706 - INFO - Epoch 25/30 - Train Loss: 1.1025, Train Acc: 53.33% - Val Loss: 1.0979, Val Acc: 75.00%
2025-05-06 11:14:46,706 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:46,706 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:46,706 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:14:46,706 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:46,706 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:14:46,706 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:14:46,716 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch25.pth
2025-05-06 11:14:46,716 - INFO - Epoche 26: Observer-Learning deaktiviert
2025-05-06 11:14:46,717 - INFO - Epoche 26: Fake-Quantisierung aktiviert
2025-05-06 11:14:46,861 - INFO - Epoch 26/30 - Train Loss: 1.1024, Train Acc: 53.33% - Val Loss: 1.1209, Val Acc: 75.00%
2025-05-06 11:14:46,862 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:46,862 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:46,862 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:14:46,862 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:46,862 - INFO - EarlyStopping counter: 9/10
2025-05-06 11:14:46,862 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:14:46,862 - INFO - Epoche 27: Observer-Learning deaktiviert
2025-05-06 11:14:46,862 - INFO - Epoche 27: Fake-Quantisierung aktiviert
2025-05-06 11:14:47,012 - INFO - Epoch 27/30 - Train Loss: 1.1294, Train Acc: 53.33% - Val Loss: 1.1519, Val Acc: 75.00%
2025-05-06 11:14:47,012 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:14:47,012 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:14:47,012 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:14:47,012 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:14:47,013 - INFO - EarlyStopping counter: 10/10
2025-05-06 11:14:47,013 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:14:47,013 - INFO - Early Stopping in Epoche 27
2025-05-06 11:14:47,013 - INFO - Training abgeschlossen in 4.48 Sekunden
2025-05-06 11:14:47,018 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 11:14:47,027 - INFO - Modell gespeichert als: models_optimized/qat_pizza_model.pth
2025-05-06 11:14:47,337 - INFO - Trainingshistorie gespeichert unter output/quantization_aware_training/qat_training_history.png
2025-05-06 11:14:47,338 - INFO - Konvertiere QAT-Modell zu quantisiertem Inferenzmodell...
2025-05-06 11:14:47,431 - INFO - Quantisiertes Modell gespeichert als: models_optimized/pizza_model_int8_qat.pth
2025-05-06 11:14:47,431 - INFO - Quantisierte Modellgröße: 126.08 KB
2025-05-06 11:14:47,431 - INFO - Evaluiere quantisiertes Modell...
2025-05-06 11:14:47,496 - WARNING - Fehler bei der Evaluierung des quantisierten Modells: 'FakeQuantize' object has no attribute 'activation_post_process'
2025-05-06 11:14:47,496 - INFO - Fahre mit der Speicherung des Modells fort ohne Evaluierung...
2025-05-06 11:14:47,497 - INFO - Vergleiche Modelle: Standard vs. QAT vs. Quantisiert...
2025-05-06 11:15:14,235 - INFO - Verwende Gerät: cuda
2025-05-06 11:15:14,235 - INFO - ================================================================================
2025-05-06 11:15:14,235 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:15:14,235 - INFO - ================================================================================
2025-05-06 11:15:14,235 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:15:14,235 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:15:14,235 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:15:14,235 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:15:14,235 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:15:14,235 - INFO - ================================================================================
2025-05-06 11:15:14,235 - INFO - Preparing optimized data loaders...
2025-05-06 11:15:14,236 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:15:14,272 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:15:14,273 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:15:14,273 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:15:14,273 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:15:14,273 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:15:14,273 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:15:14,273 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:15:14,274 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:15:14,274 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:15:14,274 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:15:14,412 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:15:14,578 - INFO - Speicheranalyse:
2025-05-06 11:15:14,578 - INFO -   Modellgröße (Float32): 309.99 KB
2025-05-06 11:15:14,578 - INFO -   Modellgröße (Int8): 77.50 KB (3.8% des Flash)
2025-05-06 11:15:14,578 - INFO -   Aktivierungsspeicher: 834.67 KB
2025-05-06 11:15:14,578 - INFO -   Gesamter Laufzeitspeicher: 912.17 KB (345.5% des RAM)
2025-05-06 11:15:14,578 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (912.17KB > 100KB)
2025-05-06 11:15:14,646 - INFO - Klassengewichte für Loss-Funktion: [0.62, 0.54, 0.94, 0.68, 1.0, 1.0]
2025-05-06 11:15:14,647 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:15:14,928 - INFO - Epoch 1/30 - Train Loss: 1.8308, Train Acc: 11.11% - Val Loss: 1.7934, Val Acc: 8.33%
2025-05-06 11:15:14,928 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:14,928 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:14,928 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:15:14,928 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:14,946 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch1.pth
2025-05-06 11:15:14,946 - INFO - Epoche 2: Observer-Learning deaktiviert
2025-05-06 11:15:15,097 - INFO - Epoch 2/30 - Train Loss: 1.8164, Train Acc: 8.89% - Val Loss: 1.7927, Val Acc: 8.33%
2025-05-06 11:15:15,097 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:15,097 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:15,097 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:15:15,097 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:15,097 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:15:15,097 - INFO - Epoche 3: Observer-Learning deaktiviert
2025-05-06 11:15:15,098 - INFO - Epoche 3: Fake-Quantisierung aktiviert
2025-05-06 11:15:15,247 - INFO - Epoch 3/30 - Train Loss: 1.7924, Train Acc: 13.33% - Val Loss: 1.7919, Val Acc: 8.33%
2025-05-06 11:15:15,247 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:15,247 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:15,247 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:15:15,247 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:15,251 - INFO - Epoche 4: Observer-Learning deaktiviert
2025-05-06 11:15:15,252 - INFO - Epoche 4: Fake-Quantisierung aktiviert
2025-05-06 11:15:15,407 - INFO - Epoch 4/30 - Train Loss: 1.7690, Train Acc: 33.33% - Val Loss: 1.7886, Val Acc: 8.33%
2025-05-06 11:15:15,407 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:15,407 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:15,407 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:15:15,407 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:15,411 - INFO - Epoche 5: Observer-Learning aktiviert
2025-05-06 11:15:15,412 - INFO - Epoche 5: Fake-Quantisierung aktiviert
2025-05-06 11:15:15,594 - INFO - Epoch 5/30 - Train Loss: 1.7341, Train Acc: 40.00% - Val Loss: 1.7802, Val Acc: 8.33%
2025-05-06 11:15:15,594 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:15,594 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:15,594 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:15:15,594 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:15,608 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch5.pth
2025-05-06 11:15:15,608 - INFO - Epoche 6: Observer-Learning deaktiviert
2025-05-06 11:15:15,609 - INFO - Epoche 6: Fake-Quantisierung aktiviert
2025-05-06 11:15:15,759 - INFO - Epoch 6/30 - Train Loss: 1.7258, Train Acc: 28.89% - Val Loss: 1.7679, Val Acc: 8.33%
2025-05-06 11:15:15,760 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:15,760 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:15,760 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:15:15,760 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:15,764 - INFO - Epoche 7: Observer-Learning deaktiviert
2025-05-06 11:15:15,764 - INFO - Epoche 7: Fake-Quantisierung aktiviert
2025-05-06 11:15:15,929 - INFO - Epoch 7/30 - Train Loss: 1.6695, Train Acc: 40.00% - Val Loss: 1.7505, Val Acc: 0.00%
2025-05-06 11:15:15,929 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:15,929 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:15,929 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:15:15,929 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:15:15,933 - INFO - Epoche 8: Observer-Learning deaktiviert
2025-05-06 11:15:15,935 - INFO - Epoche 8: Fake-Quantisierung aktiviert
2025-05-06 11:15:16,099 - INFO - Epoch 8/30 - Train Loss: 1.6305, Train Acc: 44.44% - Val Loss: 1.7286, Val Acc: 8.33%
2025-05-06 11:15:16,099 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:16,099 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:16,100 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:15:16,100 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:16,104 - INFO - Epoche 9: Observer-Learning aktiviert
2025-05-06 11:15:16,106 - INFO - Epoche 9: Fake-Quantisierung aktiviert
2025-05-06 11:15:16,300 - INFO - Epoch 9/30 - Train Loss: 1.5031, Train Acc: 57.78% - Val Loss: 1.7163, Val Acc: 16.67%
2025-05-06 11:15:16,300 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:16,300 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:16,300 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:16,300 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:16,323 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch9.pth
2025-05-06 11:15:16,323 - INFO - Epoche 10: Observer-Learning deaktiviert
2025-05-06 11:15:16,324 - INFO - Epoche 10: Fake-Quantisierung aktiviert
2025-05-06 11:15:16,474 - INFO - Epoch 10/30 - Train Loss: 1.4857, Train Acc: 53.33% - Val Loss: 1.6948, Val Acc: 16.67%
2025-05-06 11:15:16,474 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:16,474 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:16,474 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:16,474 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:16,494 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch10.pth
2025-05-06 11:15:16,494 - INFO - Epoche 11: Observer-Learning deaktiviert
2025-05-06 11:15:16,495 - INFO - Epoche 11: Fake-Quantisierung aktiviert
2025-05-06 11:15:16,656 - INFO - Epoch 11/30 - Train Loss: 1.4628, Train Acc: 48.89% - Val Loss: 1.6678, Val Acc: 16.67%
2025-05-06 11:15:16,656 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:16,656 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:16,656 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:16,656 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:16,660 - INFO - Epoche 12: Observer-Learning deaktiviert
2025-05-06 11:15:16,662 - INFO - Epoche 12: Fake-Quantisierung aktiviert
2025-05-06 11:15:16,823 - INFO - Epoch 12/30 - Train Loss: 1.4288, Train Acc: 42.22% - Val Loss: 1.6602, Val Acc: 16.67%
2025-05-06 11:15:16,823 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:16,823 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:16,823 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:16,823 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:16,827 - INFO - Epoche 13: Observer-Learning aktiviert
2025-05-06 11:15:16,828 - INFO - Epoche 13: Fake-Quantisierung aktiviert
2025-05-06 11:15:17,009 - INFO - Epoch 13/30 - Train Loss: 1.3898, Train Acc: 46.67% - Val Loss: 1.6211, Val Acc: 16.67%
2025-05-06 11:15:17,009 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:17,009 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:17,009 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:17,009 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:17,013 - INFO - Epoche 14: Observer-Learning deaktiviert
2025-05-06 11:15:17,015 - INFO - Epoche 14: Fake-Quantisierung aktiviert
2025-05-06 11:15:17,175 - INFO - Epoch 14/30 - Train Loss: 1.3249, Train Acc: 46.67% - Val Loss: 1.5770, Val Acc: 8.33%
2025-05-06 11:15:17,175 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:17,176 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:17,176 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:17,176 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:15:17,179 - INFO - Epoche 15: Observer-Learning deaktiviert
2025-05-06 11:15:17,180 - INFO - Epoche 15: Fake-Quantisierung aktiviert
2025-05-06 11:15:17,333 - INFO - Epoch 15/30 - Train Loss: 1.3527, Train Acc: 42.22% - Val Loss: 1.5326, Val Acc: 8.33%
2025-05-06 11:15:17,334 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:17,334 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:17,334 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:17,334 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:15:17,350 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch15.pth
2025-05-06 11:15:17,350 - INFO - Epoche 16: Observer-Learning deaktiviert
2025-05-06 11:15:17,351 - INFO - Epoche 16: Fake-Quantisierung aktiviert
2025-05-06 11:15:17,505 - INFO - Epoch 16/30 - Train Loss: 1.3468, Train Acc: 51.11% - Val Loss: 1.5050, Val Acc: 16.67%
2025-05-06 11:15:17,505 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:17,505 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:17,505 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:17,505 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:17,509 - INFO - Epoche 17: Observer-Learning aktiviert
2025-05-06 11:15:17,511 - INFO - Epoche 17: Fake-Quantisierung aktiviert
2025-05-06 11:15:17,691 - INFO - Epoch 17/30 - Train Loss: 1.2478, Train Acc: 64.44% - Val Loss: 1.4556, Val Acc: 16.67%
2025-05-06 11:15:17,691 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:17,691 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:17,691 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:17,691 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:17,695 - INFO - Epoche 18: Observer-Learning deaktiviert
2025-05-06 11:15:17,697 - INFO - Epoche 18: Fake-Quantisierung aktiviert
2025-05-06 11:15:17,863 - INFO - Epoch 18/30 - Train Loss: 1.2198, Train Acc: 46.67% - Val Loss: 1.4739, Val Acc: 16.67%
2025-05-06 11:15:17,864 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:17,864 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:17,864 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:17,864 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:17,864 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:15:17,864 - INFO - Epoche 19: Observer-Learning deaktiviert
2025-05-06 11:15:17,864 - INFO - Epoche 19: Fake-Quantisierung aktiviert
2025-05-06 11:15:18,015 - INFO - Epoch 19/30 - Train Loss: 1.2143, Train Acc: 48.89% - Val Loss: 1.4703, Val Acc: 8.33%
2025-05-06 11:15:18,015 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:18,015 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:18,015 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:18,015 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:15:18,015 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:15:18,015 - INFO - Epoche 20: Observer-Learning deaktiviert
2025-05-06 11:15:18,017 - INFO - Epoche 20: Fake-Quantisierung aktiviert
2025-05-06 11:15:18,173 - INFO - Epoch 20/30 - Train Loss: 1.2132, Train Acc: 48.89% - Val Loss: 1.4503, Val Acc: 16.67%
2025-05-06 11:15:18,173 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:18,173 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:18,173 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:18,173 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:18,194 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch20.pth
2025-05-06 11:15:18,194 - INFO - Epoche 21: Observer-Learning aktiviert
2025-05-06 11:15:18,195 - INFO - Epoche 21: Fake-Quantisierung aktiviert
2025-05-06 11:15:18,365 - INFO - Epoch 21/30 - Train Loss: 1.3107, Train Acc: 44.44% - Val Loss: 1.4172, Val Acc: 16.67%
2025-05-06 11:15:18,365 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:18,366 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:18,366 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:18,366 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:15:18,373 - INFO - Epoche 22: Observer-Learning deaktiviert
2025-05-06 11:15:18,376 - INFO - Epoche 22: Fake-Quantisierung aktiviert
2025-05-06 11:15:18,551 - INFO - Epoch 22/30 - Train Loss: 1.2320, Train Acc: 51.11% - Val Loss: 1.4334, Val Acc: 8.33%
2025-05-06 11:15:18,551 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:18,551 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:18,551 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:18,552 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:15:18,552 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:15:18,552 - INFO - Epoche 23: Observer-Learning deaktiviert
2025-05-06 11:15:18,552 - INFO - Epoche 23: Fake-Quantisierung aktiviert
2025-05-06 11:15:18,716 - INFO - Epoch 23/30 - Train Loss: 1.1994, Train Acc: 57.78% - Val Loss: 1.4466, Val Acc: 8.33%
2025-05-06 11:15:18,716 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:18,716 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:18,716 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:18,717 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:15:18,717 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:15:18,717 - INFO - Epoche 24: Observer-Learning deaktiviert
2025-05-06 11:15:18,717 - INFO - Epoche 24: Fake-Quantisierung aktiviert
2025-05-06 11:15:18,875 - INFO - Epoch 24/30 - Train Loss: 1.4045, Train Acc: 42.22% - Val Loss: 1.4478, Val Acc: 8.33%
2025-05-06 11:15:18,875 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:18,875 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:18,875 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:18,875 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:15:18,875 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:15:18,875 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:15:18,875 - INFO - Epoche 25: Observer-Learning aktiviert
2025-05-06 11:15:18,876 - INFO - Epoche 25: Fake-Quantisierung aktiviert
2025-05-06 11:15:19,053 - INFO - Epoch 25/30 - Train Loss: 1.3149, Train Acc: 44.44% - Val Loss: 1.4364, Val Acc: 8.33%
2025-05-06 11:15:19,053 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:19,053 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:19,053 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:19,053 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:15:19,053 - INFO - EarlyStopping counter: 9/10
2025-05-06 11:15:19,053 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:15:19,062 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch25.pth
2025-05-06 11:15:19,062 - INFO - Epoche 26: Observer-Learning deaktiviert
2025-05-06 11:15:19,063 - INFO - Epoche 26: Fake-Quantisierung aktiviert
2025-05-06 11:15:19,210 - INFO - Epoch 26/30 - Train Loss: 1.2249, Train Acc: 44.44% - Val Loss: 1.4361, Val Acc: 8.33%
2025-05-06 11:15:19,210 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:15:19,210 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:15:19,210 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:15:19,210 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:15:19,210 - INFO - EarlyStopping counter: 10/10
2025-05-06 11:15:19,211 - INFO - Early Stopping in Epoche 26
2025-05-06 11:15:19,211 - INFO - Training abgeschlossen in 4.56 Sekunden
2025-05-06 11:15:19,215 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 11:15:19,224 - INFO - Modell gespeichert als: models_optimized/qat_pizza_model.pth
2025-05-06 11:15:19,523 - INFO - Trainingshistorie gespeichert unter output/quantization_aware_training/qat_training_history.png
2025-05-06 11:15:19,524 - INFO - Konvertiere QAT-Modell zu quantisiertem Inferenzmodell...
2025-05-06 11:15:19,624 - INFO - Quantisiertes Modell gespeichert als: models_optimized/pizza_model_int8_qat.pth
2025-05-06 11:15:19,624 - INFO - Quantisierte Modellgröße: 126.08 KB
2025-05-06 11:15:19,624 - INFO - Evaluiere quantisiertes Modell...
2025-05-06 11:15:19,705 - WARNING - Fehler bei der Evaluierung des quantisierten Modells: 'FakeQuantize' object has no attribute 'activation_post_process'
2025-05-06 11:15:19,705 - INFO - Fahre mit der Speicherung des Modells fort ohne Evaluierung...
2025-05-06 11:15:19,705 - INFO - Vergleiche Modelle: Standard vs. QAT vs. Quantisiert...
2025-05-06 11:17:06,503 - INFO - Verwende Gerät: cuda
2025-05-06 11:17:06,503 - INFO - ================================================================================
2025-05-06 11:17:06,503 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:17:06,503 - INFO - ================================================================================
2025-05-06 11:17:06,503 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:17:06,503 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:17:06,503 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:17:06,503 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:17:06,503 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:17:06,503 - INFO - ================================================================================
2025-05-06 11:17:06,503 - INFO - Preparing optimized data loaders...
2025-05-06 11:17:06,503 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:17:06,540 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:17:06,540 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:17:06,540 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:17:06,540 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:17:06,540 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:17:06,540 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:17:06,540 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:17:06,541 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:17:06,542 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:17:06,542 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:17:06,683 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:17:06,852 - INFO - Speicheranalyse:
2025-05-06 11:17:06,852 - INFO -   Modellgröße (Float32): 309.99 KB
2025-05-06 11:17:06,852 - INFO -   Modellgröße (Int8): 77.50 KB (3.8% des Flash)
2025-05-06 11:17:06,852 - INFO -   Aktivierungsspeicher: 834.67 KB
2025-05-06 11:17:06,852 - INFO -   Gesamter Laufzeitspeicher: 912.17 KB (345.5% des RAM)
2025-05-06 11:17:06,852 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (912.17KB > 100KB)
2025-05-06 11:17:06,918 - INFO - Klassengewichte für Loss-Funktion: [0.83, 0.39, 1.07, 0.75, 1.0, 1.0]
2025-05-06 11:17:06,918 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:17:07,206 - INFO - Epoch 1/30 - Train Loss: 1.7888, Train Acc: 8.89% - Val Loss: 1.7826, Val Acc: 66.67%
2025-05-06 11:17:07,206 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:07,206 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:17:07,206 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:17:07,206 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:07,226 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch1.pth
2025-05-06 11:17:07,226 - INFO - Epoche 2: Observer-Learning deaktiviert
2025-05-06 11:17:07,388 - INFO - Epoch 2/30 - Train Loss: 1.7952, Train Acc: 11.11% - Val Loss: 1.7750, Val Acc: 66.67%
2025-05-06 11:17:07,388 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:07,388 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:17:07,388 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:17:07,388 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:07,394 - INFO - Epoche 3: Observer-Learning deaktiviert
2025-05-06 11:17:07,395 - INFO - Epoche 3: Fake-Quantisierung aktiviert
2025-05-06 11:17:07,557 - INFO - Epoch 3/30 - Train Loss: 1.7611, Train Acc: 20.00% - Val Loss: 1.7636, Val Acc: 66.67%
2025-05-06 11:17:07,557 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:07,558 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:17:07,558 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:17:07,558 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:07,561 - INFO - Epoche 4: Observer-Learning deaktiviert
2025-05-06 11:17:07,562 - INFO - Epoche 4: Fake-Quantisierung aktiviert
2025-05-06 11:17:07,726 - INFO - Epoch 4/30 - Train Loss: 1.7458, Train Acc: 31.11% - Val Loss: 1.7500, Val Acc: 66.67%
2025-05-06 11:17:07,726 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:07,726 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:17:07,726 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:17:07,726 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:07,731 - INFO - Epoche 5: Observer-Learning aktiviert
2025-05-06 11:17:07,732 - INFO - Epoche 5: Fake-Quantisierung aktiviert
2025-05-06 11:17:07,922 - INFO - Epoch 5/30 - Train Loss: 1.7143, Train Acc: 33.33% - Val Loss: 1.7240, Val Acc: 66.67%
2025-05-06 11:17:07,922 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:07,922 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:17:07,922 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:17:07,922 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:07,942 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch5.pth
2025-05-06 11:17:07,942 - INFO - Epoche 6: Observer-Learning deaktiviert
2025-05-06 11:17:07,943 - INFO - Epoche 6: Fake-Quantisierung aktiviert
2025-05-06 11:17:08,108 - INFO - Epoch 6/30 - Train Loss: 1.6842, Train Acc: 28.89% - Val Loss: 1.7001, Val Acc: 66.67%
2025-05-06 11:17:08,108 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:08,108 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:17:08,108 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:17:08,108 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:08,112 - INFO - Epoche 7: Observer-Learning deaktiviert
2025-05-06 11:17:08,113 - INFO - Epoche 7: Fake-Quantisierung aktiviert
2025-05-06 11:17:08,282 - INFO - Epoch 7/30 - Train Loss: 1.6471, Train Acc: 31.11% - Val Loss: 1.6749, Val Acc: 66.67%
2025-05-06 11:17:08,283 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:08,283 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:17:08,283 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:17:08,283 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:08,288 - INFO - Epoche 8: Observer-Learning deaktiviert
2025-05-06 11:17:08,290 - INFO - Epoche 8: Fake-Quantisierung aktiviert
2025-05-06 11:17:08,455 - INFO - Epoch 8/30 - Train Loss: 1.6187, Train Acc: 31.11% - Val Loss: 1.6446, Val Acc: 25.00%
2025-05-06 11:17:08,455 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:08,455 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:17:08,455 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:17:08,455 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:08,459 - INFO - Epoche 9: Observer-Learning aktiviert
2025-05-06 11:17:08,460 - INFO - Epoche 9: Fake-Quantisierung aktiviert
2025-05-06 11:17:08,648 - INFO - Epoch 9/30 - Train Loss: 1.5605, Train Acc: 31.11% - Val Loss: 1.6120, Val Acc: 8.33%
2025-05-06 11:17:08,648 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:08,649 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:17:08,649 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:17:08,649 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:08,652 - INFO - Epoche 10: Observer-Learning deaktiviert
2025-05-06 11:17:08,654 - INFO - Epoche 10: Fake-Quantisierung aktiviert
2025-05-06 11:17:08,815 - INFO - Epoch 10/30 - Train Loss: 1.5740, Train Acc: 17.78% - Val Loss: 1.5923, Val Acc: 0.00%
2025-05-06 11:17:08,815 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:08,815 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:17:08,815 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:17:08,815 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:08,837 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch10.pth
2025-05-06 11:17:08,837 - INFO - Epoche 11: Observer-Learning deaktiviert
2025-05-06 11:17:08,839 - INFO - Epoche 11: Fake-Quantisierung aktiviert
2025-05-06 11:17:08,999 - INFO - Epoch 11/30 - Train Loss: 1.4497, Train Acc: 31.11% - Val Loss: 1.5577, Val Acc: 8.33%
2025-05-06 11:17:09,000 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:09,000 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:17:09,000 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:09,000 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:09,004 - INFO - Epoche 12: Observer-Learning deaktiviert
2025-05-06 11:17:09,005 - INFO - Epoche 12: Fake-Quantisierung aktiviert
2025-05-06 11:17:09,159 - INFO - Epoch 12/30 - Train Loss: 1.4566, Train Acc: 31.11% - Val Loss: 1.5238, Val Acc: 16.67%
2025-05-06 11:17:09,160 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:09,160 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:17:09,160 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:09,160 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:09,164 - INFO - Epoche 13: Observer-Learning aktiviert
2025-05-06 11:17:09,165 - INFO - Epoche 13: Fake-Quantisierung aktiviert
2025-05-06 11:17:09,373 - INFO - Epoch 13/30 - Train Loss: 1.3614, Train Acc: 33.33% - Val Loss: 1.4634, Val Acc: 33.33%
2025-05-06 11:17:09,373 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:09,373 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:17:09,373 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:09,373 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:09,378 - INFO - Epoche 14: Observer-Learning deaktiviert
2025-05-06 11:17:09,380 - INFO - Epoche 14: Fake-Quantisierung aktiviert
2025-05-06 11:17:09,568 - INFO - Epoch 14/30 - Train Loss: 1.4448, Train Acc: 20.00% - Val Loss: 1.4002, Val Acc: 33.33%
2025-05-06 11:17:09,568 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:09,568 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:17:09,568 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:09,568 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:09,572 - INFO - Epoche 15: Observer-Learning deaktiviert
2025-05-06 11:17:09,573 - INFO - Epoche 15: Fake-Quantisierung aktiviert
2025-05-06 11:17:09,733 - INFO - Epoch 15/30 - Train Loss: 1.3385, Train Acc: 31.11% - Val Loss: 1.3512, Val Acc: 41.67%
2025-05-06 11:17:09,733 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:09,733 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:17:09,733 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:09,733 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:09,753 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch15.pth
2025-05-06 11:17:09,753 - INFO - Epoche 16: Observer-Learning deaktiviert
2025-05-06 11:17:09,755 - INFO - Epoche 16: Fake-Quantisierung aktiviert
2025-05-06 11:17:09,911 - INFO - Epoch 16/30 - Train Loss: 1.3857, Train Acc: 26.67% - Val Loss: 1.3132, Val Acc: 41.67%
2025-05-06 11:17:09,911 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:09,911 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:17:09,911 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:09,911 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:09,915 - INFO - Epoche 17: Observer-Learning aktiviert
2025-05-06 11:17:09,916 - INFO - Epoche 17: Fake-Quantisierung aktiviert
2025-05-06 11:17:10,108 - INFO - Epoch 17/30 - Train Loss: 1.3016, Train Acc: 31.11% - Val Loss: 1.2651, Val Acc: 50.00%
2025-05-06 11:17:10,108 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:10,108 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:17:10,108 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:10,108 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:10,113 - INFO - Epoche 18: Observer-Learning deaktiviert
2025-05-06 11:17:10,114 - INFO - Epoche 18: Fake-Quantisierung aktiviert
2025-05-06 11:17:10,282 - INFO - Epoch 18/30 - Train Loss: 1.2129, Train Acc: 42.22% - Val Loss: 1.2796, Val Acc: 41.67%
2025-05-06 11:17:10,282 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:10,282 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:17:10,282 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:10,282 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:10,282 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:17:10,282 - INFO - Epoche 19: Observer-Learning deaktiviert
2025-05-06 11:17:10,283 - INFO - Epoche 19: Fake-Quantisierung aktiviert
2025-05-06 11:17:10,445 - INFO - Epoch 19/30 - Train Loss: 1.2498, Train Acc: 51.11% - Val Loss: 1.2715, Val Acc: 41.67%
2025-05-06 11:17:10,445 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:10,445 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:17:10,445 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:10,445 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:10,445 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:17:10,445 - INFO - Epoche 20: Observer-Learning deaktiviert
2025-05-06 11:17:10,446 - INFO - Epoche 20: Fake-Quantisierung aktiviert
2025-05-06 11:17:10,596 - INFO - Epoch 20/30 - Train Loss: 1.3402, Train Acc: 37.78% - Val Loss: 1.2447, Val Acc: 41.67%
2025-05-06 11:17:10,596 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:10,596 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:17:10,596 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:10,596 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:10,610 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch20.pth
2025-05-06 11:17:10,610 - INFO - Epoche 21: Observer-Learning aktiviert
2025-05-06 11:17:10,611 - INFO - Epoche 21: Fake-Quantisierung aktiviert
2025-05-06 11:17:10,797 - INFO - Epoch 21/30 - Train Loss: 1.2982, Train Acc: 28.89% - Val Loss: 1.2212, Val Acc: 41.67%
2025-05-06 11:17:10,798 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:10,798 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:17:10,798 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:10,798 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:10,802 - INFO - Epoche 22: Observer-Learning deaktiviert
2025-05-06 11:17:10,803 - INFO - Epoche 22: Fake-Quantisierung aktiviert
2025-05-06 11:17:10,966 - INFO - Epoch 22/30 - Train Loss: 1.2520, Train Acc: 33.33% - Val Loss: 1.2188, Val Acc: 41.67%
2025-05-06 11:17:10,967 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:10,967 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:17:10,967 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:10,967 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:10,971 - INFO - Epoche 23: Observer-Learning deaktiviert
2025-05-06 11:17:10,974 - INFO - Epoche 23: Fake-Quantisierung aktiviert
2025-05-06 11:17:11,145 - INFO - Epoch 23/30 - Train Loss: 1.3291, Train Acc: 35.56% - Val Loss: 1.2192, Val Acc: 41.67%
2025-05-06 11:17:11,145 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:11,145 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:17:11,145 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:11,145 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:11,145 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:17:11,145 - INFO - Epoche 24: Observer-Learning deaktiviert
2025-05-06 11:17:11,146 - INFO - Epoche 24: Fake-Quantisierung aktiviert
2025-05-06 11:17:11,305 - INFO - Epoch 24/30 - Train Loss: 1.1965, Train Acc: 46.67% - Val Loss: 1.1891, Val Acc: 50.00%
2025-05-06 11:17:11,305 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:11,305 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:17:11,305 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:11,305 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:11,310 - INFO - Epoche 25: Observer-Learning aktiviert
2025-05-06 11:17:11,311 - INFO - Epoche 25: Fake-Quantisierung aktiviert
2025-05-06 11:17:11,520 - INFO - Epoch 25/30 - Train Loss: 1.2495, Train Acc: 37.78% - Val Loss: 1.2127, Val Acc: 41.67%
2025-05-06 11:17:11,520 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:11,520 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:17:11,520 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:11,520 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:11,520 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:17:11,529 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch25.pth
2025-05-06 11:17:11,529 - INFO - Epoche 26: Observer-Learning deaktiviert
2025-05-06 11:17:11,529 - INFO - Epoche 26: Fake-Quantisierung aktiviert
2025-05-06 11:17:11,689 - INFO - Epoch 26/30 - Train Loss: 1.2585, Train Acc: 44.44% - Val Loss: 1.2245, Val Acc: 41.67%
2025-05-06 11:17:11,689 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:11,689 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:17:11,689 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:11,689 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:11,689 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:17:11,689 - INFO - Epoche 27: Observer-Learning deaktiviert
2025-05-06 11:17:11,690 - INFO - Epoche 27: Fake-Quantisierung aktiviert
2025-05-06 11:17:11,850 - INFO - Epoch 27/30 - Train Loss: 1.1980, Train Acc: 35.56% - Val Loss: 1.2395, Val Acc: 41.67%
2025-05-06 11:17:11,850 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:11,851 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:17:11,851 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:11,851 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:11,851 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:17:11,851 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:17:11,851 - INFO - Epoche 28: Observer-Learning deaktiviert
2025-05-06 11:17:11,852 - INFO - Epoche 28: Fake-Quantisierung aktiviert
2025-05-06 11:17:12,014 - INFO - Epoch 28/30 - Train Loss: 1.2784, Train Acc: 37.78% - Val Loss: 1.2519, Val Acc: 41.67%
2025-05-06 11:17:12,014 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:12,014 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:17:12,014 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:12,014 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:12,014 - INFO - EarlyStopping counter: 9/10
2025-05-06 11:17:12,014 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:17:12,014 - INFO - Epoche 29: Observer-Learning aktiviert
2025-05-06 11:17:12,015 - INFO - Epoche 29: Fake-Quantisierung aktiviert
2025-05-06 11:17:12,197 - INFO - Epoch 29/30 - Train Loss: 1.2146, Train Acc: 42.22% - Val Loss: 1.2427, Val Acc: 41.67%
2025-05-06 11:17:12,197 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:17:12,197 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:17:12,197 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:17:12,197 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:17:12,197 - INFO - EarlyStopping counter: 10/10
2025-05-06 11:17:12,197 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:17:12,197 - INFO - Early Stopping in Epoche 29
2025-05-06 11:17:12,197 - INFO - Training abgeschlossen in 5.28 Sekunden
2025-05-06 11:17:12,202 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 11:17:12,211 - INFO - Modell gespeichert als: models_optimized/qat_pizza_model.pth
2025-05-06 11:17:12,536 - INFO - Trainingshistorie gespeichert unter output/quantization_aware_training/qat_training_history.png
2025-05-06 11:17:12,536 - INFO - Konvertiere QAT-Modell zu quantisiertem Inferenzmodell...
2025-05-06 11:17:12,628 - INFO - Quantisiertes Modell gespeichert als: models_optimized/pizza_model_int8_qat.pth
2025-05-06 11:17:12,628 - INFO - Quantisierte Modellgröße: 126.08 KB
2025-05-06 11:17:12,628 - INFO - Evaluiere quantisiertes Modell...
2025-05-06 11:17:12,696 - WARNING - Fehler bei der Evaluierung des quantisierten Modells: 'FakeQuantize' object has no attribute 'activation_post_process'
2025-05-06 11:17:12,696 - INFO - Fahre mit der Speicherung des Modells fort ohne Evaluierung...
2025-05-06 11:17:12,697 - INFO - Vergleiche Modelle: Standard vs. QAT vs. Quantisiert...
2025-05-06 11:18:00,270 - INFO - Verwende Gerät: cuda
2025-05-06 11:18:00,270 - INFO - ================================================================================
2025-05-06 11:18:00,270 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:18:00,270 - INFO - ================================================================================
2025-05-06 11:18:00,270 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:18:00,270 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:18:00,270 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:18:00,270 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:18:00,270 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:18:00,270 - INFO - ================================================================================
2025-05-06 11:18:00,270 - INFO - Preparing optimized data loaders...
2025-05-06 11:18:00,271 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:18:00,308 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:18:00,308 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:18:00,308 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:18:00,308 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:18:00,308 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:18:00,308 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:18:00,308 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:18:00,309 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:18:00,309 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:18:00,309 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:18:00,459 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:18:00,634 - INFO - Speicheranalyse:
2025-05-06 11:18:00,634 - INFO -   Modellgröße (Float32): 309.99 KB
2025-05-06 11:18:00,634 - INFO -   Modellgröße (Int8): 77.50 KB (3.8% des Flash)
2025-05-06 11:18:00,634 - INFO -   Aktivierungsspeicher: 834.67 KB
2025-05-06 11:18:00,634 - INFO -   Gesamter Laufzeitspeicher: 912.17 KB (345.5% des RAM)
2025-05-06 11:18:00,634 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (912.17KB > 100KB)
2025-05-06 11:18:00,703 - INFO - Klassengewichte für Loss-Funktion: [0.54, 0.58, 0.83, 0.83, 1.0, 1.0]
2025-05-06 11:18:00,703 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:18:00,992 - INFO - Epoch 1/30 - Train Loss: 1.7999, Train Acc: 13.33% - Val Loss: 1.7943, Val Acc: 25.00%
2025-05-06 11:18:00,992 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:00,992 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:00,992 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:18:00,992 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:01,012 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch1.pth
2025-05-06 11:18:01,012 - INFO - Epoche 2: Observer-Learning deaktiviert
2025-05-06 11:18:01,167 - INFO - Epoch 2/30 - Train Loss: 1.8221, Train Acc: 13.33% - Val Loss: 1.7945, Val Acc: 25.00%
2025-05-06 11:18:01,167 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:01,167 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:01,167 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:18:01,168 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:01,168 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:18:01,168 - INFO - Epoche 3: Observer-Learning deaktiviert
2025-05-06 11:18:01,168 - INFO - Epoche 3: Fake-Quantisierung aktiviert
2025-05-06 11:18:01,330 - INFO - Epoch 3/30 - Train Loss: 1.7887, Train Acc: 22.22% - Val Loss: 1.7934, Val Acc: 25.00%
2025-05-06 11:18:01,330 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:01,330 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:01,330 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:18:01,330 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:01,330 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:18:01,330 - INFO - Epoche 4: Observer-Learning deaktiviert
2025-05-06 11:18:01,332 - INFO - Epoche 4: Fake-Quantisierung aktiviert
2025-05-06 11:18:01,503 - INFO - Epoch 4/30 - Train Loss: 1.7871, Train Acc: 15.56% - Val Loss: 1.7889, Val Acc: 25.00%
2025-05-06 11:18:01,503 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:01,503 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:01,503 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:18:01,503 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:01,508 - INFO - Epoche 5: Observer-Learning aktiviert
2025-05-06 11:18:01,509 - INFO - Epoche 5: Fake-Quantisierung aktiviert
2025-05-06 11:18:01,699 - INFO - Epoch 5/30 - Train Loss: 1.7401, Train Acc: 31.11% - Val Loss: 1.7782, Val Acc: 25.00%
2025-05-06 11:18:01,699 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:01,699 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:01,699 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:18:01,699 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:01,713 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch5.pth
2025-05-06 11:18:01,713 - INFO - Epoche 6: Observer-Learning deaktiviert
2025-05-06 11:18:01,714 - INFO - Epoche 6: Fake-Quantisierung aktiviert
2025-05-06 11:18:01,874 - INFO - Epoch 6/30 - Train Loss: 1.6914, Train Acc: 46.67% - Val Loss: 1.7610, Val Acc: 25.00%
2025-05-06 11:18:01,874 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:01,874 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:01,875 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:18:01,875 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:01,879 - INFO - Epoche 7: Observer-Learning deaktiviert
2025-05-06 11:18:01,881 - INFO - Epoche 7: Fake-Quantisierung aktiviert
2025-05-06 11:18:02,046 - INFO - Epoch 7/30 - Train Loss: 1.6608, Train Acc: 42.22% - Val Loss: 1.7438, Val Acc: 25.00%
2025-05-06 11:18:02,046 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:02,046 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:02,046 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:18:02,046 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:02,051 - INFO - Epoche 8: Observer-Learning deaktiviert
2025-05-06 11:18:02,052 - INFO - Epoche 8: Fake-Quantisierung aktiviert
2025-05-06 11:18:02,220 - INFO - Epoch 8/30 - Train Loss: 1.6081, Train Acc: 37.78% - Val Loss: 1.7195, Val Acc: 16.67%
2025-05-06 11:18:02,220 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:02,220 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:02,220 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:02,220 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:18:02,224 - INFO - Epoche 9: Observer-Learning aktiviert
2025-05-06 11:18:02,226 - INFO - Epoche 9: Fake-Quantisierung aktiviert
2025-05-06 11:18:02,430 - INFO - Epoch 9/30 - Train Loss: 1.5688, Train Acc: 28.89% - Val Loss: 1.6863, Val Acc: 16.67%
2025-05-06 11:18:02,430 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:02,430 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:02,430 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:02,430 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:18:02,436 - INFO - Epoche 10: Observer-Learning deaktiviert
2025-05-06 11:18:02,438 - INFO - Epoche 10: Fake-Quantisierung aktiviert
2025-05-06 11:18:02,602 - INFO - Epoch 10/30 - Train Loss: 1.5046, Train Acc: 37.78% - Val Loss: 1.6350, Val Acc: 8.33%
2025-05-06 11:18:02,602 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:02,602 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:02,602 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:02,602 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:02,623 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch10.pth
2025-05-06 11:18:02,623 - INFO - Epoche 11: Observer-Learning deaktiviert
2025-05-06 11:18:02,623 - INFO - Epoche 11: Fake-Quantisierung aktiviert
2025-05-06 11:18:02,778 - INFO - Epoch 11/30 - Train Loss: 1.3854, Train Acc: 64.44% - Val Loss: 1.6031, Val Acc: 8.33%
2025-05-06 11:18:02,778 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:02,778 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:02,778 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:02,778 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:02,782 - INFO - Epoche 12: Observer-Learning deaktiviert
2025-05-06 11:18:02,784 - INFO - Epoche 12: Fake-Quantisierung aktiviert
2025-05-06 11:18:02,954 - INFO - Epoch 12/30 - Train Loss: 1.4633, Train Acc: 46.67% - Val Loss: 1.5911, Val Acc: 8.33%
2025-05-06 11:18:02,955 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:02,955 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:02,955 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:02,955 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:02,963 - INFO - Epoche 13: Observer-Learning aktiviert
2025-05-06 11:18:02,964 - INFO - Epoche 13: Fake-Quantisierung aktiviert
2025-05-06 11:18:03,153 - INFO - Epoch 13/30 - Train Loss: 1.3755, Train Acc: 46.67% - Val Loss: 1.5791, Val Acc: 8.33%
2025-05-06 11:18:03,153 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:03,153 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:03,153 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:03,153 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:03,157 - INFO - Epoche 14: Observer-Learning deaktiviert
2025-05-06 11:18:03,158 - INFO - Epoche 14: Fake-Quantisierung aktiviert
2025-05-06 11:18:03,318 - INFO - Epoch 14/30 - Train Loss: 1.4282, Train Acc: 33.33% - Val Loss: 1.5815, Val Acc: 8.33%
2025-05-06 11:18:03,318 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:03,318 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:03,318 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:03,318 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:03,318 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:18:03,318 - INFO - Epoche 15: Observer-Learning deaktiviert
2025-05-06 11:18:03,319 - INFO - Epoche 15: Fake-Quantisierung aktiviert
2025-05-06 11:18:03,474 - INFO - Epoch 15/30 - Train Loss: 1.2684, Train Acc: 57.78% - Val Loss: 1.5673, Val Acc: 8.33%
2025-05-06 11:18:03,474 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:03,474 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:03,474 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:03,474 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:03,492 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch15.pth
2025-05-06 11:18:03,493 - INFO - Epoche 16: Observer-Learning deaktiviert
2025-05-06 11:18:03,494 - INFO - Epoche 16: Fake-Quantisierung aktiviert
2025-05-06 11:18:03,657 - INFO - Epoch 16/30 - Train Loss: 1.3310, Train Acc: 46.67% - Val Loss: 1.5568, Val Acc: 8.33%
2025-05-06 11:18:03,657 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:03,657 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:03,657 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:03,657 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:03,661 - INFO - Epoche 17: Observer-Learning aktiviert
2025-05-06 11:18:03,664 - INFO - Epoche 17: Fake-Quantisierung aktiviert
2025-05-06 11:18:03,854 - INFO - Epoch 17/30 - Train Loss: 1.2505, Train Acc: 53.33% - Val Loss: 1.5387, Val Acc: 8.33%
2025-05-06 11:18:03,854 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:03,854 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:03,854 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:03,854 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:03,859 - INFO - Epoche 18: Observer-Learning deaktiviert
2025-05-06 11:18:03,860 - INFO - Epoche 18: Fake-Quantisierung aktiviert
2025-05-06 11:18:04,033 - INFO - Epoch 18/30 - Train Loss: 1.2534, Train Acc: 53.33% - Val Loss: 1.5177, Val Acc: 8.33%
2025-05-06 11:18:04,033 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:04,033 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:04,033 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:04,033 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:04,037 - INFO - Epoche 19: Observer-Learning deaktiviert
2025-05-06 11:18:04,038 - INFO - Epoche 19: Fake-Quantisierung aktiviert
2025-05-06 11:18:04,197 - INFO - Epoch 19/30 - Train Loss: 1.3137, Train Acc: 35.56% - Val Loss: 1.5369, Val Acc: 8.33%
2025-05-06 11:18:04,197 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:04,197 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:04,197 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:04,197 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:04,197 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:18:04,197 - INFO - Epoche 20: Observer-Learning deaktiviert
2025-05-06 11:18:04,198 - INFO - Epoche 20: Fake-Quantisierung aktiviert
2025-05-06 11:18:04,348 - INFO - Epoch 20/30 - Train Loss: 1.2024, Train Acc: 48.89% - Val Loss: 1.5302, Val Acc: 8.33%
2025-05-06 11:18:04,349 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:04,349 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:04,349 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:04,349 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:04,349 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:18:04,358 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch20.pth
2025-05-06 11:18:04,358 - INFO - Epoche 21: Observer-Learning aktiviert
2025-05-06 11:18:04,358 - INFO - Epoche 21: Fake-Quantisierung aktiviert
2025-05-06 11:18:04,534 - INFO - Epoch 21/30 - Train Loss: 1.2485, Train Acc: 42.22% - Val Loss: 1.5426, Val Acc: 8.33%
2025-05-06 11:18:04,534 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:04,534 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:04,534 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:04,534 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:04,534 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:18:04,534 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:18:04,534 - INFO - Epoche 22: Observer-Learning deaktiviert
2025-05-06 11:18:04,535 - INFO - Epoche 22: Fake-Quantisierung aktiviert
2025-05-06 11:18:04,701 - INFO - Epoch 22/30 - Train Loss: 1.2362, Train Acc: 51.11% - Val Loss: 1.4912, Val Acc: 8.33%
2025-05-06 11:18:04,701 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:04,701 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:04,701 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:04,701 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:04,705 - INFO - Epoche 23: Observer-Learning deaktiviert
2025-05-06 11:18:04,706 - INFO - Epoche 23: Fake-Quantisierung aktiviert
2025-05-06 11:18:04,863 - INFO - Epoch 23/30 - Train Loss: 1.1744, Train Acc: 51.11% - Val Loss: 1.4809, Val Acc: 8.33%
2025-05-06 11:18:04,864 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:04,864 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:04,864 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:04,864 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:04,867 - INFO - Epoche 24: Observer-Learning deaktiviert
2025-05-06 11:18:04,868 - INFO - Epoche 24: Fake-Quantisierung aktiviert
2025-05-06 11:18:05,021 - INFO - Epoch 24/30 - Train Loss: 1.1134, Train Acc: 60.00% - Val Loss: 1.4630, Val Acc: 8.33%
2025-05-06 11:18:05,021 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:05,021 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:05,022 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:05,022 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:05,025 - INFO - Epoche 25: Observer-Learning aktiviert
2025-05-06 11:18:05,026 - INFO - Epoche 25: Fake-Quantisierung aktiviert
2025-05-06 11:18:05,211 - INFO - Epoch 25/30 - Train Loss: 1.1750, Train Acc: 55.56% - Val Loss: 1.4494, Val Acc: 8.33%
2025-05-06 11:18:05,212 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:05,212 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:05,212 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:05,212 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:05,238 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch25.pth
2025-05-06 11:18:05,239 - INFO - Epoche 26: Observer-Learning deaktiviert
2025-05-06 11:18:05,239 - INFO - Epoche 26: Fake-Quantisierung aktiviert
2025-05-06 11:18:05,393 - INFO - Epoch 26/30 - Train Loss: 1.2041, Train Acc: 51.11% - Val Loss: 1.4462, Val Acc: 8.33%
2025-05-06 11:18:05,393 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:05,393 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:05,393 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:05,393 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:05,397 - INFO - Epoche 27: Observer-Learning deaktiviert
2025-05-06 11:18:05,398 - INFO - Epoche 27: Fake-Quantisierung aktiviert
2025-05-06 11:18:05,558 - INFO - Epoch 27/30 - Train Loss: 1.2053, Train Acc: 44.44% - Val Loss: 1.4562, Val Acc: 8.33%
2025-05-06 11:18:05,559 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:05,559 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:05,559 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:05,559 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:05,559 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:18:05,559 - INFO - Epoche 28: Observer-Learning deaktiviert
2025-05-06 11:18:05,559 - INFO - Epoche 28: Fake-Quantisierung aktiviert
2025-05-06 11:18:05,731 - INFO - Epoch 28/30 - Train Loss: 1.1793, Train Acc: 48.89% - Val Loss: 1.4721, Val Acc: 8.33%
2025-05-06 11:18:05,731 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:05,731 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:05,731 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:05,731 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:05,731 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:18:05,731 - INFO - Epoche 29: Observer-Learning aktiviert
2025-05-06 11:18:05,732 - INFO - Epoche 29: Fake-Quantisierung aktiviert
2025-05-06 11:18:05,928 - INFO - Epoch 29/30 - Train Loss: 1.1686, Train Acc: 60.00% - Val Loss: 1.4467, Val Acc: 8.33%
2025-05-06 11:18:05,928 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:05,928 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:05,928 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:05,928 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:05,928 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:18:05,928 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:18:05,928 - INFO - Epoche 30: Observer-Learning deaktiviert
2025-05-06 11:18:05,929 - INFO - Epoche 30: Fake-Quantisierung aktiviert
2025-05-06 11:18:06,088 - INFO - Epoch 30/30 - Train Loss: 1.2056, Train Acc: 57.78% - Val Loss: 1.4590, Val Acc: 8.33%
2025-05-06 11:18:06,088 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:18:06,088 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:18:06,089 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:18:06,089 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:18:06,089 - INFO - EarlyStopping counter: 9/10
2025-05-06 11:18:06,100 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch30.pth
2025-05-06 11:18:06,100 - INFO - Training abgeschlossen in 5.40 Sekunden
2025-05-06 11:18:06,105 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 11:18:06,114 - INFO - Modell gespeichert als: models_optimized/qat_pizza_model.pth
2025-05-06 11:18:06,453 - INFO - Trainingshistorie gespeichert unter output/quantization_aware_training/qat_training_history.png
2025-05-06 11:18:06,454 - INFO - Konvertiere QAT-Modell zu quantisiertem Inferenzmodell...
2025-05-06 11:18:06,545 - INFO - Quantisiertes Modell gespeichert als: models_optimized/pizza_model_int8_qat.pth
2025-05-06 11:18:06,545 - INFO - Quantisierte Modellgröße: 126.08 KB
2025-05-06 11:18:06,546 - INFO - Evaluiere quantisiertes Modell...
2025-05-06 11:18:06,620 - WARNING - Fehler bei der Evaluierung des quantisierten Modells: 'FakeQuantize' object has no attribute 'activation_post_process'
2025-05-06 11:18:06,620 - INFO - Fahre mit der Speicherung des Modells fort ohne Evaluierung...
2025-05-06 11:18:06,620 - INFO - Vergleiche Modelle: Standard vs. QAT vs. Quantisiert...
2025-05-06 11:20:01,357 - INFO - Verwende Gerät: cuda
2025-05-06 11:20:01,357 - INFO - ================================================================================
2025-05-06 11:20:01,357 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:20:01,357 - INFO - ================================================================================
2025-05-06 11:20:01,357 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:20:01,357 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:20:01,357 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:20:01,357 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:20:01,357 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:20:01,357 - INFO - ================================================================================
2025-05-06 11:20:01,357 - INFO - Preparing optimized data loaders...
2025-05-06 11:20:01,358 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:20:01,400 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:20:01,400 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:20:01,400 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:20:01,400 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:20:01,400 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:20:01,400 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:20:01,401 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:20:01,403 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:20:01,403 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:20:01,403 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:20:01,545 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:20:01,721 - INFO - Speicheranalyse:
2025-05-06 11:20:01,722 - INFO -   Modellgröße (Float32): 309.99 KB
2025-05-06 11:20:01,722 - INFO -   Modellgröße (Int8): 77.50 KB (3.8% des Flash)
2025-05-06 11:20:01,722 - INFO -   Aktivierungsspeicher: 834.67 KB
2025-05-06 11:20:01,722 - INFO -   Gesamter Laufzeitspeicher: 912.17 KB (345.5% des RAM)
2025-05-06 11:20:01,722 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (912.17KB > 100KB)
2025-05-06 11:20:01,787 - INFO - Klassengewichte für Loss-Funktion: [0.68, 0.83, 0.75, 0.5, 1.0, 1.0]
2025-05-06 11:20:01,788 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:20:02,075 - INFO - Epoch 1/30 - Train Loss: 1.7978, Train Acc: 11.11% - Val Loss: 1.7950, Val Acc: 25.00%
2025-05-06 11:20:02,075 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:02,075 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:20:02,075 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:20:02,075 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:02,093 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch1.pth
2025-05-06 11:20:02,093 - INFO - Epoche 2: Observer-Learning deaktiviert
2025-05-06 11:20:02,260 - INFO - Epoch 2/30 - Train Loss: 1.8092, Train Acc: 15.56% - Val Loss: 1.7956, Val Acc: 25.00%
2025-05-06 11:20:02,261 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:02,261 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:20:02,261 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:20:02,261 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:02,261 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:20:02,261 - INFO - Epoche 3: Observer-Learning deaktiviert
2025-05-06 11:20:02,262 - INFO - Epoche 3: Fake-Quantisierung aktiviert
2025-05-06 11:20:02,438 - INFO - Epoch 3/30 - Train Loss: 1.7957, Train Acc: 8.89% - Val Loss: 1.7916, Val Acc: 25.00%
2025-05-06 11:20:02,438 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:02,438 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:20:02,438 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:20:02,438 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:02,442 - INFO - Epoche 4: Observer-Learning deaktiviert
2025-05-06 11:20:02,443 - INFO - Epoche 4: Fake-Quantisierung aktiviert
2025-05-06 11:20:02,607 - INFO - Epoch 4/30 - Train Loss: 1.7679, Train Acc: 33.33% - Val Loss: 1.7822, Val Acc: 25.00%
2025-05-06 11:20:02,607 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:02,607 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:20:02,607 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:20:02,607 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:02,612 - INFO - Epoche 5: Observer-Learning aktiviert
2025-05-06 11:20:02,613 - INFO - Epoche 5: Fake-Quantisierung aktiviert
2025-05-06 11:20:02,813 - INFO - Epoch 5/30 - Train Loss: 1.7574, Train Acc: 24.44% - Val Loss: 1.7687, Val Acc: 8.33%
2025-05-06 11:20:02,814 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:02,814 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:20:02,814 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:20:02,814 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:02,834 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch5.pth
2025-05-06 11:20:02,834 - INFO - Epoche 6: Observer-Learning deaktiviert
2025-05-06 11:20:02,835 - INFO - Epoche 6: Fake-Quantisierung aktiviert
2025-05-06 11:20:02,991 - INFO - Epoch 6/30 - Train Loss: 1.6942, Train Acc: 42.22% - Val Loss: 1.7526, Val Acc: 0.00%
2025-05-06 11:20:02,991 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:02,991 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:20:02,991 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:20:02,991 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:02,995 - INFO - Epoche 7: Observer-Learning deaktiviert
2025-05-06 11:20:02,996 - INFO - Epoche 7: Fake-Quantisierung aktiviert
2025-05-06 11:20:03,156 - INFO - Epoch 7/30 - Train Loss: 1.6712, Train Acc: 35.56% - Val Loss: 1.7364, Val Acc: 0.00%
2025-05-06 11:20:03,156 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:03,156 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:20:03,156 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:20:03,156 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:03,160 - INFO - Epoche 8: Observer-Learning deaktiviert
2025-05-06 11:20:03,161 - INFO - Epoche 8: Fake-Quantisierung aktiviert
2025-05-06 11:20:03,324 - INFO - Epoch 8/30 - Train Loss: 1.6707, Train Acc: 17.78% - Val Loss: 1.7192, Val Acc: 8.33%
2025-05-06 11:20:03,324 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:03,324 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:20:03,325 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:20:03,325 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:03,332 - INFO - Epoche 9: Observer-Learning aktiviert
2025-05-06 11:20:03,333 - INFO - Epoche 9: Fake-Quantisierung aktiviert
2025-05-06 11:20:03,525 - INFO - Epoch 9/30 - Train Loss: 1.5592, Train Acc: 44.44% - Val Loss: 1.6926, Val Acc: 8.33%
2025-05-06 11:20:03,525 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:03,525 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:20:03,525 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:20:03,525 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:03,529 - INFO - Epoche 10: Observer-Learning deaktiviert
2025-05-06 11:20:03,531 - INFO - Epoche 10: Fake-Quantisierung aktiviert
2025-05-06 11:20:03,704 - INFO - Epoch 10/30 - Train Loss: 1.5397, Train Acc: 40.00% - Val Loss: 1.6736, Val Acc: 8.33%
2025-05-06 11:20:03,704 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:03,704 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:20:03,705 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:20:03,705 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:03,723 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch10.pth
2025-05-06 11:20:03,724 - INFO - Epoche 11: Observer-Learning deaktiviert
2025-05-06 11:20:03,724 - INFO - Epoche 11: Fake-Quantisierung aktiviert
2025-05-06 11:20:03,892 - INFO - Epoch 11/30 - Train Loss: 1.4400, Train Acc: 55.56% - Val Loss: 1.6363, Val Acc: 8.33%
2025-05-06 11:20:03,892 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:03,892 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:20:03,892 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:20:03,892 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:03,896 - INFO - Epoche 12: Observer-Learning deaktiviert
2025-05-06 11:20:03,897 - INFO - Epoche 12: Fake-Quantisierung aktiviert
2025-05-06 11:20:04,062 - INFO - Epoch 12/30 - Train Loss: 1.4801, Train Acc: 40.00% - Val Loss: 1.5951, Val Acc: 25.00%
2025-05-06 11:20:04,062 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:04,062 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:20:04,062 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:20:04,062 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:04,068 - INFO - Epoche 13: Observer-Learning aktiviert
2025-05-06 11:20:04,071 - INFO - Epoche 13: Fake-Quantisierung aktiviert
2025-05-06 11:20:04,272 - INFO - Epoch 13/30 - Train Loss: 1.3394, Train Acc: 60.00% - Val Loss: 1.5429, Val Acc: 33.33%
2025-05-06 11:20:04,272 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:04,272 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:20:04,272 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:20:04,272 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:04,301 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch13.pth
2025-05-06 11:20:04,301 - INFO - Epoche 14: Observer-Learning deaktiviert
2025-05-06 11:20:04,302 - INFO - Epoche 14: Fake-Quantisierung aktiviert
2025-05-06 11:20:04,470 - INFO - Epoch 14/30 - Train Loss: 1.3150, Train Acc: 55.56% - Val Loss: 1.5132, Val Acc: 41.67%
2025-05-06 11:20:04,471 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:04,471 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:20:04,471 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:20:04,471 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:04,489 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch14.pth
2025-05-06 11:20:04,489 - INFO - Epoche 15: Observer-Learning deaktiviert
2025-05-06 11:20:04,489 - INFO - Epoche 15: Fake-Quantisierung aktiviert
2025-05-06 11:20:04,662 - INFO - Epoch 15/30 - Train Loss: 1.3103, Train Acc: 48.89% - Val Loss: 1.4468, Val Acc: 41.67%
2025-05-06 11:20:04,662 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:04,662 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:20:04,662 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:20:04,662 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:04,675 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch15.pth
2025-05-06 11:20:04,675 - INFO - Epoche 16: Observer-Learning deaktiviert
2025-05-06 11:20:04,676 - INFO - Epoche 16: Fake-Quantisierung aktiviert
2025-05-06 11:20:04,838 - INFO - Epoch 16/30 - Train Loss: 1.3332, Train Acc: 42.22% - Val Loss: 1.4203, Val Acc: 41.67%
2025-05-06 11:20:04,838 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:04,838 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:20:04,838 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:20:04,838 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:04,843 - INFO - Epoche 17: Observer-Learning aktiviert
2025-05-06 11:20:04,845 - INFO - Epoche 17: Fake-Quantisierung aktiviert
2025-05-06 11:20:05,052 - INFO - Epoch 17/30 - Train Loss: 1.2927, Train Acc: 46.67% - Val Loss: 1.4328, Val Acc: 41.67%
2025-05-06 11:20:05,052 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:05,052 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:20:05,052 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:20:05,052 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:05,052 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:20:05,052 - INFO - Epoche 18: Observer-Learning deaktiviert
2025-05-06 11:20:05,053 - INFO - Epoche 18: Fake-Quantisierung aktiviert
2025-05-06 11:20:05,217 - INFO - Epoch 18/30 - Train Loss: 1.2783, Train Acc: 46.67% - Val Loss: 1.4329, Val Acc: 41.67%
2025-05-06 11:20:05,217 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:05,217 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:20:05,217 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:20:05,217 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:05,217 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:20:05,217 - INFO - Epoche 19: Observer-Learning deaktiviert
2025-05-06 11:20:05,218 - INFO - Epoche 19: Fake-Quantisierung aktiviert
2025-05-06 11:20:05,372 - INFO - Epoch 19/30 - Train Loss: 1.1721, Train Acc: 48.89% - Val Loss: 1.4567, Val Acc: 41.67%
2025-05-06 11:20:05,372 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:05,372 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:20:05,372 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:20:05,372 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:05,372 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:20:05,372 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:20:05,372 - INFO - Epoche 20: Observer-Learning deaktiviert
2025-05-06 11:20:05,373 - INFO - Epoche 20: Fake-Quantisierung aktiviert
2025-05-06 11:20:05,533 - INFO - Epoch 20/30 - Train Loss: 1.2287, Train Acc: 55.56% - Val Loss: 1.4370, Val Acc: 41.67%
2025-05-06 11:20:05,533 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:05,533 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:20:05,533 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:20:05,533 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:05,533 - INFO - EarlyStopping counter: 9/10
2025-05-06 11:20:05,533 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:20:05,542 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch20.pth
2025-05-06 11:20:05,542 - INFO - Epoche 21: Observer-Learning aktiviert
2025-05-06 11:20:05,543 - INFO - Epoche 21: Fake-Quantisierung aktiviert
2025-05-06 11:20:05,726 - INFO - Epoch 21/30 - Train Loss: 1.2426, Train Acc: 48.89% - Val Loss: 1.4219, Val Acc: 41.67%
2025-05-06 11:20:05,727 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:20:05,727 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:20:05,727 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:20:05,727 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:20:05,727 - INFO - EarlyStopping counter: 10/10
2025-05-06 11:20:05,727 - INFO - Early Stopping in Epoche 21
2025-05-06 11:20:05,727 - INFO - Training abgeschlossen in 3.94 Sekunden
2025-05-06 11:20:05,731 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 11:20:05,740 - INFO - Modell gespeichert als: models_optimized/qat_pizza_model.pth
2025-05-06 11:20:06,070 - INFO - Trainingshistorie gespeichert unter output/quantization_aware_training/qat_training_history.png
2025-05-06 11:20:06,070 - INFO - Konvertiere QAT-Modell zu quantisiertem Inferenzmodell...
2025-05-06 11:20:06,163 - INFO - Quantisiertes Modell gespeichert als: models_optimized/pizza_model_int8_qat.pth
2025-05-06 11:20:06,163 - INFO - Quantisierte Modellgröße: 126.08 KB
2025-05-06 11:20:06,163 - INFO - Evaluiere quantisiertes Modell...
2025-05-06 11:20:06,241 - WARNING - Fehler bei der Evaluierung des quantisierten Modells: 'FakeQuantize' object has no attribute 'activation_post_process'
2025-05-06 11:20:06,241 - INFO - Fahre mit der Speicherung des Modells fort ohne Evaluierung...
2025-05-06 11:20:06,242 - INFO - Vergleiche Modelle: Standard vs. QAT vs. Quantisiert...
2025-05-06 11:26:32,310 - INFO - Verwende Gerät: cuda
2025-05-06 11:26:32,310 - INFO - ================================================================================
2025-05-06 11:26:32,310 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:26:32,310 - INFO - ================================================================================
2025-05-06 11:26:32,310 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:26:32,310 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:26:32,310 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:26:32,310 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:26:32,310 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:26:32,310 - INFO - ================================================================================
2025-05-06 11:26:32,310 - INFO - Preparing optimized data loaders...
2025-05-06 11:26:32,311 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:26:32,349 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:26:32,349 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:26:32,349 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:26:32,349 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:26:32,349 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:26:32,349 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:26:32,349 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:26:32,350 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:26:32,350 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:26:32,350 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:26:32,496 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:26:32,667 - INFO - Speicheranalyse:
2025-05-06 11:26:32,667 - INFO -   Modellgröße (Float32): 309.99 KB
2025-05-06 11:26:32,667 - INFO -   Modellgröße (Int8): 77.50 KB (3.8% des Flash)
2025-05-06 11:26:32,667 - INFO -   Aktivierungsspeicher: 834.67 KB
2025-05-06 11:26:32,667 - INFO -   Gesamter Laufzeitspeicher: 912.17 KB (345.5% des RAM)
2025-05-06 11:26:32,667 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (912.17KB > 100KB)
2025-05-06 11:26:32,717 - INFO - Klassengewichte für Loss-Funktion: [0.68, 0.83, 0.58, 0.62, 1.0, 1.0]
2025-05-06 11:26:32,718 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:26:32,996 - INFO - Epoch 1/30 - Train Loss: 1.7821, Train Acc: 22.22% - Val Loss: 1.7866, Val Acc: 0.00%
2025-05-06 11:26:32,996 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:32,996 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:26:32,996 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:32,996 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:33,000 - INFO - Epoche 2: Observer-Learning deaktiviert
2025-05-06 11:26:33,136 - INFO - Epoch 2/30 - Train Loss: 1.7837, Train Acc: 13.33% - Val Loss: 1.7835, Val Acc: 0.00%
2025-05-06 11:26:33,137 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:33,137 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:26:33,137 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:33,137 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:33,141 - INFO - Epoche 3: Observer-Learning deaktiviert
2025-05-06 11:26:33,143 - INFO - Epoche 3: Fake-Quantisierung aktiviert
2025-05-06 11:26:33,290 - INFO - Epoch 3/30 - Train Loss: 1.7757, Train Acc: 15.56% - Val Loss: 1.7762, Val Acc: 66.67%
2025-05-06 11:26:33,290 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:33,290 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:26:33,290 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:33,290 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:33,313 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch3.pth
2025-05-06 11:26:33,313 - INFO - Epoche 4: Observer-Learning deaktiviert
2025-05-06 11:26:33,314 - INFO - Epoche 4: Fake-Quantisierung aktiviert
2025-05-06 11:26:33,468 - INFO - Epoch 4/30 - Train Loss: 1.7577, Train Acc: 28.89% - Val Loss: 1.7610, Val Acc: 66.67%
2025-05-06 11:26:33,468 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:33,468 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:26:33,468 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:33,468 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:33,475 - INFO - Epoche 5: Observer-Learning aktiviert
2025-05-06 11:26:33,477 - INFO - Epoche 5: Fake-Quantisierung aktiviert
2025-05-06 11:26:33,658 - INFO - Epoch 5/30 - Train Loss: 1.7250, Train Acc: 26.67% - Val Loss: 1.7412, Val Acc: 66.67%
2025-05-06 11:26:33,658 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:33,658 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:26:33,658 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:33,658 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:33,700 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch5.pth
2025-05-06 11:26:33,701 - INFO - Epoche 6: Observer-Learning deaktiviert
2025-05-06 11:26:33,702 - INFO - Epoche 6: Fake-Quantisierung aktiviert
2025-05-06 11:26:33,830 - INFO - Epoch 6/30 - Train Loss: 1.7016, Train Acc: 28.89% - Val Loss: 1.7135, Val Acc: 66.67%
2025-05-06 11:26:33,830 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:33,830 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:26:33,830 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:33,830 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:33,835 - INFO - Epoche 7: Observer-Learning deaktiviert
2025-05-06 11:26:33,837 - INFO - Epoche 7: Fake-Quantisierung aktiviert
2025-05-06 11:26:33,973 - INFO - Epoch 7/30 - Train Loss: 1.6763, Train Acc: 22.22% - Val Loss: 1.6778, Val Acc: 66.67%
2025-05-06 11:26:33,973 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:33,973 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:26:33,973 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:33,973 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:33,979 - INFO - Epoche 8: Observer-Learning deaktiviert
2025-05-06 11:26:33,980 - INFO - Epoche 8: Fake-Quantisierung aktiviert
2025-05-06 11:26:34,122 - INFO - Epoch 8/30 - Train Loss: 1.6292, Train Acc: 44.44% - Val Loss: 1.6487, Val Acc: 66.67%
2025-05-06 11:26:34,123 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:34,123 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:26:34,123 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:34,123 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:34,127 - INFO - Epoche 9: Observer-Learning aktiviert
2025-05-06 11:26:34,128 - INFO - Epoche 9: Fake-Quantisierung aktiviert
2025-05-06 11:26:34,289 - INFO - Epoch 9/30 - Train Loss: 1.5888, Train Acc: 31.11% - Val Loss: 1.6245, Val Acc: 66.67%
2025-05-06 11:26:34,289 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:34,289 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:26:34,289 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:34,289 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:34,293 - INFO - Epoche 10: Observer-Learning deaktiviert
2025-05-06 11:26:34,295 - INFO - Epoche 10: Fake-Quantisierung aktiviert
2025-05-06 11:26:34,428 - INFO - Epoch 10/30 - Train Loss: 1.5253, Train Acc: 37.78% - Val Loss: 1.5954, Val Acc: 66.67%
2025-05-06 11:26:34,429 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:34,429 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:26:34,429 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:34,429 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:34,457 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch10.pth
2025-05-06 11:26:34,458 - INFO - Epoche 11: Observer-Learning deaktiviert
2025-05-06 11:26:34,459 - INFO - Epoche 11: Fake-Quantisierung aktiviert
2025-05-06 11:26:34,591 - INFO - Epoch 11/30 - Train Loss: 1.5038, Train Acc: 35.56% - Val Loss: 1.5640, Val Acc: 50.00%
2025-05-06 11:26:34,591 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:34,591 - INFO -   basic: 75.00% (6/8)
2025-05-06 11:26:34,592 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:34,592 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:34,596 - INFO - Epoche 12: Observer-Learning deaktiviert
2025-05-06 11:26:34,597 - INFO - Epoche 12: Fake-Quantisierung aktiviert
2025-05-06 11:26:34,736 - INFO - Epoch 12/30 - Train Loss: 1.4607, Train Acc: 33.33% - Val Loss: 1.5455, Val Acc: 8.33%
2025-05-06 11:26:34,736 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:34,736 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:26:34,736 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:34,736 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:34,740 - INFO - Epoche 13: Observer-Learning aktiviert
2025-05-06 11:26:34,741 - INFO - Epoche 13: Fake-Quantisierung aktiviert
2025-05-06 11:26:34,893 - INFO - Epoch 13/30 - Train Loss: 1.3795, Train Acc: 57.78% - Val Loss: 1.5180, Val Acc: 8.33%
2025-05-06 11:26:34,893 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:34,893 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:26:34,893 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:34,893 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:34,897 - INFO - Epoche 14: Observer-Learning deaktiviert
2025-05-06 11:26:34,898 - INFO - Epoche 14: Fake-Quantisierung aktiviert
2025-05-06 11:26:35,024 - INFO - Epoch 14/30 - Train Loss: 1.3879, Train Acc: 48.89% - Val Loss: 1.4997, Val Acc: 8.33%
2025-05-06 11:26:35,024 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:35,024 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:26:35,024 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:35,024 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:35,027 - INFO - Epoche 15: Observer-Learning deaktiviert
2025-05-06 11:26:35,028 - INFO - Epoche 15: Fake-Quantisierung aktiviert
2025-05-06 11:26:35,162 - INFO - Epoch 15/30 - Train Loss: 1.3151, Train Acc: 60.00% - Val Loss: 1.4863, Val Acc: 8.33%
2025-05-06 11:26:35,162 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:35,162 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:26:35,162 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:35,162 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:35,177 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch15.pth
2025-05-06 11:26:35,177 - INFO - Epoche 16: Observer-Learning deaktiviert
2025-05-06 11:26:35,177 - INFO - Epoche 16: Fake-Quantisierung aktiviert
2025-05-06 11:26:35,308 - INFO - Epoch 16/30 - Train Loss: 1.3498, Train Acc: 48.89% - Val Loss: 1.4873, Val Acc: 8.33%
2025-05-06 11:26:35,308 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:35,308 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:26:35,308 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:35,308 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:35,308 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:26:35,308 - INFO - Epoche 17: Observer-Learning aktiviert
2025-05-06 11:26:35,309 - INFO - Epoche 17: Fake-Quantisierung aktiviert
2025-05-06 11:26:35,464 - INFO - Epoch 17/30 - Train Loss: 1.2649, Train Acc: 53.33% - Val Loss: 1.4546, Val Acc: 25.00%
2025-05-06 11:26:35,465 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:35,465 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:26:35,465 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:35,465 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:35,468 - INFO - Epoche 18: Observer-Learning deaktiviert
2025-05-06 11:26:35,469 - INFO - Epoche 18: Fake-Quantisierung aktiviert
2025-05-06 11:26:35,600 - INFO - Epoch 18/30 - Train Loss: 1.2172, Train Acc: 51.11% - Val Loss: 1.4379, Val Acc: 25.00%
2025-05-06 11:26:35,600 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:35,600 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:26:35,600 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:35,600 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:35,605 - INFO - Epoche 19: Observer-Learning deaktiviert
2025-05-06 11:26:35,606 - INFO - Epoche 19: Fake-Quantisierung aktiviert
2025-05-06 11:26:35,740 - INFO - Epoch 19/30 - Train Loss: 1.2274, Train Acc: 42.22% - Val Loss: 1.4279, Val Acc: 25.00%
2025-05-06 11:26:35,740 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:35,740 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:26:35,740 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:35,740 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:35,744 - INFO - Epoche 20: Observer-Learning deaktiviert
2025-05-06 11:26:35,746 - INFO - Epoche 20: Fake-Quantisierung aktiviert
2025-05-06 11:26:35,889 - INFO - Epoch 20/30 - Train Loss: 1.2795, Train Acc: 55.56% - Val Loss: 1.4191, Val Acc: 33.33%
2025-05-06 11:26:35,889 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:35,889 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:26:35,889 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:35,889 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:35,907 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch20.pth
2025-05-06 11:26:35,907 - INFO - Epoche 21: Observer-Learning aktiviert
2025-05-06 11:26:35,908 - INFO - Epoche 21: Fake-Quantisierung aktiviert
2025-05-06 11:26:36,061 - INFO - Epoch 21/30 - Train Loss: 1.2204, Train Acc: 51.11% - Val Loss: 1.4456, Val Acc: 33.33%
2025-05-06 11:26:36,061 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:36,061 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:26:36,061 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:36,061 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:36,061 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:26:36,061 - INFO - Epoche 22: Observer-Learning deaktiviert
2025-05-06 11:26:36,062 - INFO - Epoche 22: Fake-Quantisierung aktiviert
2025-05-06 11:26:36,202 - INFO - Epoch 22/30 - Train Loss: 1.3869, Train Acc: 22.22% - Val Loss: 1.4640, Val Acc: 33.33%
2025-05-06 11:26:36,203 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:36,203 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:26:36,203 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:36,203 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:36,203 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:26:36,203 - INFO - Epoche 23: Observer-Learning deaktiviert
2025-05-06 11:26:36,203 - INFO - Epoche 23: Fake-Quantisierung aktiviert
2025-05-06 11:26:36,338 - INFO - Epoch 23/30 - Train Loss: 1.2026, Train Acc: 46.67% - Val Loss: 1.4593, Val Acc: 33.33%
2025-05-06 11:26:36,338 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:36,338 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:26:36,338 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:36,338 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:36,338 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:26:36,338 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:26:36,338 - INFO - Epoche 24: Observer-Learning deaktiviert
2025-05-06 11:26:36,339 - INFO - Epoche 24: Fake-Quantisierung aktiviert
2025-05-06 11:26:36,467 - INFO - Epoch 24/30 - Train Loss: 1.1756, Train Acc: 57.78% - Val Loss: 1.4432, Val Acc: 33.33%
2025-05-06 11:26:36,467 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:36,467 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:26:36,467 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:36,467 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:36,467 - INFO - EarlyStopping counter: 9/10
2025-05-06 11:26:36,467 - INFO - Epoche 25: Observer-Learning aktiviert
2025-05-06 11:26:36,469 - INFO - Epoche 25: Fake-Quantisierung aktiviert
2025-05-06 11:26:36,623 - INFO - Epoch 25/30 - Train Loss: 1.0323, Train Acc: 68.89% - Val Loss: 1.4228, Val Acc: 33.33%
2025-05-06 11:26:36,623 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:26:36,623 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:26:36,623 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:26:36,623 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:26:36,623 - INFO - EarlyStopping counter: 10/10
2025-05-06 11:26:36,632 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch25.pth
2025-05-06 11:26:36,632 - INFO - Early Stopping in Epoche 25
2025-05-06 11:26:36,632 - INFO - Training abgeschlossen in 3.91 Sekunden
2025-05-06 11:26:36,637 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 11:26:36,649 - INFO - Modell gespeichert als: models_optimized/qat_pizza_model.pth
2025-05-06 11:26:36,959 - INFO - Trainingshistorie gespeichert unter output/quantization_aware_training/qat_training_history.png
2025-05-06 11:26:36,959 - INFO - Konvertiere QAT-Modell zu quantisiertem Inferenzmodell...
2025-05-06 11:26:37,058 - INFO - Quantisiertes Modell gespeichert als: models_optimized/pizza_model_int8_qat.pth
2025-05-06 11:26:37,058 - INFO - Quantisierte Modellgröße: 126.08 KB
2025-05-06 11:26:37,058 - INFO - Evaluiere quantisiertes Modell...
2025-05-06 11:26:37,132 - WARNING - Fehler bei der Evaluierung des quantisierten Modells: 'FakeQuantize' object has no attribute 'activation_post_process'
2025-05-06 11:26:37,132 - INFO - Fahre mit der Speicherung des Modells fort ohne Evaluierung...
2025-05-06 11:26:37,133 - INFO - Vergleiche Modelle: Standard vs. QAT vs. Quantisiert...
2025-05-06 11:31:53,946 - INFO - Verwende Gerät: cuda
2025-05-06 11:31:53,946 - INFO - ================================================================================
2025-05-06 11:31:53,946 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:31:53,946 - INFO - ================================================================================
2025-05-06 11:31:53,946 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:31:53,946 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:31:53,946 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:31:53,946 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:31:53,946 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:31:53,946 - INFO - ================================================================================
2025-05-06 11:31:53,946 - INFO - Preparing optimized data loaders...
2025-05-06 11:31:53,946 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:31:53,984 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:31:53,984 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:31:53,984 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:31:53,984 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:31:53,984 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:31:53,985 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:31:53,985 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:31:53,986 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:31:53,986 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:31:53,986 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:31:54,134 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:31:54,310 - INFO - Speicheranalyse:
2025-05-06 11:31:54,310 - INFO -   Modellgröße (Float32): 309.99 KB
2025-05-06 11:31:54,310 - INFO -   Modellgröße (Int8): 77.50 KB (3.8% des Flash)
2025-05-06 11:31:54,310 - INFO -   Aktivierungsspeicher: 834.67 KB
2025-05-06 11:31:54,310 - INFO -   Gesamter Laufzeitspeicher: 912.17 KB (345.5% des RAM)
2025-05-06 11:31:54,310 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (912.17KB > 100KB)
2025-05-06 11:31:54,386 - INFO - Klassengewichte für Loss-Funktion: [0.68, 0.68, 0.83, 0.54, 1.0, 1.0]
2025-05-06 11:31:54,387 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:31:54,685 - INFO - Epoch 1/30 - Train Loss: 1.7987, Train Acc: 20.00% - Val Loss: 1.7904, Val Acc: 8.33%
2025-05-06 11:31:54,685 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:54,685 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:31:54,685 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:31:54,685 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:31:54,705 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch1.pth
2025-05-06 11:31:54,705 - INFO - Epoche 2: Observer-Learning deaktiviert
2025-05-06 11:31:54,878 - INFO - Epoch 2/30 - Train Loss: 1.8087, Train Acc: 8.89% - Val Loss: 1.7885, Val Acc: 8.33%
2025-05-06 11:31:54,878 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:54,879 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:31:54,879 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:31:54,879 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:31:54,882 - INFO - Epoche 3: Observer-Learning deaktiviert
2025-05-06 11:31:54,883 - INFO - Epoche 3: Fake-Quantisierung aktiviert
2025-05-06 11:31:55,056 - INFO - Epoch 3/30 - Train Loss: 1.7609, Train Acc: 31.11% - Val Loss: 1.7866, Val Acc: 8.33%
2025-05-06 11:31:55,056 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:55,056 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:31:55,056 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:31:55,056 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:31:55,060 - INFO - Epoche 4: Observer-Learning deaktiviert
2025-05-06 11:31:55,061 - INFO - Epoche 4: Fake-Quantisierung aktiviert
2025-05-06 11:31:55,237 - INFO - Epoch 4/30 - Train Loss: 1.7684, Train Acc: 22.22% - Val Loss: 1.7804, Val Acc: 8.33%
2025-05-06 11:31:55,237 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:55,237 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:31:55,237 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:31:55,238 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:31:55,243 - INFO - Epoche 5: Observer-Learning aktiviert
2025-05-06 11:31:55,245 - INFO - Epoche 5: Fake-Quantisierung aktiviert
2025-05-06 11:31:55,442 - INFO - Epoch 5/30 - Train Loss: 1.7360, Train Acc: 28.89% - Val Loss: 1.7710, Val Acc: 8.33%
2025-05-06 11:31:55,442 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:55,442 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:31:55,442 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:31:55,442 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:31:55,461 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch5.pth
2025-05-06 11:31:55,461 - INFO - Epoche 6: Observer-Learning deaktiviert
2025-05-06 11:31:55,462 - INFO - Epoche 6: Fake-Quantisierung aktiviert
2025-05-06 11:31:55,638 - INFO - Epoch 6/30 - Train Loss: 1.7121, Train Acc: 28.89% - Val Loss: 1.7576, Val Acc: 8.33%
2025-05-06 11:31:55,639 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:55,639 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:31:55,639 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:31:55,639 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:31:55,643 - INFO - Epoche 7: Observer-Learning deaktiviert
2025-05-06 11:31:55,643 - INFO - Epoche 7: Fake-Quantisierung aktiviert
2025-05-06 11:31:55,814 - INFO - Epoch 7/30 - Train Loss: 1.6757, Train Acc: 24.44% - Val Loss: 1.7456, Val Acc: 8.33%
2025-05-06 11:31:55,814 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:55,814 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:31:55,814 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:31:55,814 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:31:55,818 - INFO - Epoche 8: Observer-Learning deaktiviert
2025-05-06 11:31:55,819 - INFO - Epoche 8: Fake-Quantisierung aktiviert
2025-05-06 11:31:55,989 - INFO - Epoch 8/30 - Train Loss: 1.6214, Train Acc: 35.56% - Val Loss: 1.7259, Val Acc: 8.33%
2025-05-06 11:31:55,989 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:55,989 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:31:55,989 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:31:55,989 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:31:55,993 - INFO - Epoche 9: Observer-Learning aktiviert
2025-05-06 11:31:55,994 - INFO - Epoche 9: Fake-Quantisierung aktiviert
2025-05-06 11:31:56,203 - INFO - Epoch 9/30 - Train Loss: 1.5904, Train Acc: 26.67% - Val Loss: 1.6924, Val Acc: 8.33%
2025-05-06 11:31:56,203 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:56,203 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:31:56,203 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:31:56,203 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:31:56,207 - INFO - Epoche 10: Observer-Learning deaktiviert
2025-05-06 11:31:56,208 - INFO - Epoche 10: Fake-Quantisierung aktiviert
2025-05-06 11:31:56,407 - INFO - Epoch 10/30 - Train Loss: 1.5241, Train Acc: 42.22% - Val Loss: 1.6680, Val Acc: 0.00%
2025-05-06 11:31:56,407 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:56,407 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:31:56,407 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:31:56,407 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:31:56,453 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch10.pth
2025-05-06 11:31:56,453 - INFO - Epoche 11: Observer-Learning deaktiviert
2025-05-06 11:31:56,454 - INFO - Epoche 11: Fake-Quantisierung aktiviert
2025-05-06 11:31:56,626 - INFO - Epoch 11/30 - Train Loss: 1.4567, Train Acc: 44.44% - Val Loss: 1.6280, Val Acc: 0.00%
2025-05-06 11:31:56,626 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:56,626 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:31:56,626 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:31:56,626 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:31:56,631 - INFO - Epoche 12: Observer-Learning deaktiviert
2025-05-06 11:31:56,633 - INFO - Epoche 12: Fake-Quantisierung aktiviert
2025-05-06 11:31:56,827 - INFO - Epoch 12/30 - Train Loss: 1.4123, Train Acc: 48.89% - Val Loss: 1.5804, Val Acc: 8.33%
2025-05-06 11:31:56,827 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:56,827 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:31:56,827 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:31:56,827 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:31:56,831 - INFO - Epoche 13: Observer-Learning aktiviert
2025-05-06 11:31:56,833 - INFO - Epoche 13: Fake-Quantisierung aktiviert
2025-05-06 11:31:57,030 - INFO - Epoch 13/30 - Train Loss: 1.3985, Train Acc: 42.22% - Val Loss: 1.5356, Val Acc: 8.33%
2025-05-06 11:31:57,030 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:57,030 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:31:57,030 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:31:57,030 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:31:57,034 - INFO - Epoche 14: Observer-Learning deaktiviert
2025-05-06 11:31:57,036 - INFO - Epoche 14: Fake-Quantisierung aktiviert
2025-05-06 11:31:57,206 - INFO - Epoch 14/30 - Train Loss: 1.3157, Train Acc: 60.00% - Val Loss: 1.5015, Val Acc: 16.67%
2025-05-06 11:31:57,206 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:57,206 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:31:57,206 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:31:57,206 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:31:57,223 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch14.pth
2025-05-06 11:31:57,223 - INFO - Epoche 15: Observer-Learning deaktiviert
2025-05-06 11:31:57,223 - INFO - Epoche 15: Fake-Quantisierung aktiviert
2025-05-06 11:31:57,389 - INFO - Epoch 15/30 - Train Loss: 1.3290, Train Acc: 57.78% - Val Loss: 1.4693, Val Acc: 25.00%
2025-05-06 11:31:57,389 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:57,389 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:31:57,389 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:31:57,389 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:31:57,412 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch15.pth
2025-05-06 11:31:57,412 - INFO - Epoche 16: Observer-Learning deaktiviert
2025-05-06 11:31:57,413 - INFO - Epoche 16: Fake-Quantisierung aktiviert
2025-05-06 11:31:57,586 - INFO - Epoch 16/30 - Train Loss: 1.3042, Train Acc: 51.11% - Val Loss: 1.4324, Val Acc: 50.00%
2025-05-06 11:31:57,586 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:57,586 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:31:57,587 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:31:57,587 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:31:57,599 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch16.pth
2025-05-06 11:31:57,599 - INFO - Epoche 17: Observer-Learning aktiviert
2025-05-06 11:31:57,600 - INFO - Epoche 17: Fake-Quantisierung aktiviert
2025-05-06 11:31:57,797 - INFO - Epoch 17/30 - Train Loss: 1.2754, Train Acc: 46.67% - Val Loss: 1.3897, Val Acc: 41.67%
2025-05-06 11:31:57,797 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:57,797 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:31:57,797 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:31:57,797 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:31:57,801 - INFO - Epoche 18: Observer-Learning deaktiviert
2025-05-06 11:31:57,802 - INFO - Epoche 18: Fake-Quantisierung aktiviert
2025-05-06 11:31:57,969 - INFO - Epoch 18/30 - Train Loss: 1.2225, Train Acc: 48.89% - Val Loss: 1.3644, Val Acc: 41.67%
2025-05-06 11:31:57,970 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:57,970 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:31:57,970 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:31:57,970 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:31:57,973 - INFO - Epoche 19: Observer-Learning deaktiviert
2025-05-06 11:31:57,974 - INFO - Epoche 19: Fake-Quantisierung aktiviert
2025-05-06 11:31:58,155 - INFO - Epoch 19/30 - Train Loss: 1.3072, Train Acc: 37.78% - Val Loss: 1.3475, Val Acc: 50.00%
2025-05-06 11:31:58,155 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:58,155 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:31:58,155 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:31:58,155 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:31:58,160 - INFO - Epoche 20: Observer-Learning deaktiviert
2025-05-06 11:31:58,161 - INFO - Epoche 20: Fake-Quantisierung aktiviert
2025-05-06 11:31:58,334 - INFO - Epoch 20/30 - Train Loss: 1.1783, Train Acc: 55.56% - Val Loss: 1.3439, Val Acc: 50.00%
2025-05-06 11:31:58,334 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:58,334 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:31:58,334 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:31:58,335 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:31:58,347 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch20.pth
2025-05-06 11:31:58,347 - INFO - Epoche 21: Observer-Learning aktiviert
2025-05-06 11:31:58,348 - INFO - Epoche 21: Fake-Quantisierung aktiviert
2025-05-06 11:31:58,547 - INFO - Epoch 21/30 - Train Loss: 1.3066, Train Acc: 37.78% - Val Loss: 1.3771, Val Acc: 41.67%
2025-05-06 11:31:58,547 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:58,547 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:31:58,548 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:31:58,548 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:31:58,548 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:31:58,548 - INFO - Epoche 22: Observer-Learning deaktiviert
2025-05-06 11:31:58,550 - INFO - Epoche 22: Fake-Quantisierung aktiviert
2025-05-06 11:31:58,716 - INFO - Epoch 22/30 - Train Loss: 1.1420, Train Acc: 53.33% - Val Loss: 1.3623, Val Acc: 50.00%
2025-05-06 11:31:58,716 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:58,716 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:31:58,716 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:31:58,716 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:31:58,716 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:31:58,716 - INFO - Epoche 23: Observer-Learning deaktiviert
2025-05-06 11:31:58,717 - INFO - Epoche 23: Fake-Quantisierung aktiviert
2025-05-06 11:31:58,885 - INFO - Epoch 23/30 - Train Loss: 1.1614, Train Acc: 46.67% - Val Loss: 1.3644, Val Acc: 50.00%
2025-05-06 11:31:58,885 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:58,885 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:31:58,885 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:31:58,885 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:31:58,885 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:31:58,885 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:31:58,885 - INFO - Epoche 24: Observer-Learning deaktiviert
2025-05-06 11:31:58,886 - INFO - Epoche 24: Fake-Quantisierung aktiviert
2025-05-06 11:31:59,053 - INFO - Epoch 24/30 - Train Loss: 1.1060, Train Acc: 57.78% - Val Loss: 1.3563, Val Acc: 41.67%
2025-05-06 11:31:59,053 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:59,053 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:31:59,053 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:31:59,053 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:31:59,053 - INFO - EarlyStopping counter: 9/10
2025-05-06 11:31:59,053 - INFO - Epoche 25: Observer-Learning aktiviert
2025-05-06 11:31:59,054 - INFO - Epoche 25: Fake-Quantisierung aktiviert
2025-05-06 11:31:59,255 - INFO - Epoch 25/30 - Train Loss: 1.1877, Train Acc: 48.89% - Val Loss: 1.3437, Val Acc: 50.00%
2025-05-06 11:31:59,255 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:31:59,255 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:31:59,255 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:31:59,255 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:31:59,255 - INFO - EarlyStopping counter: 10/10
2025-05-06 11:31:59,264 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch25.pth
2025-05-06 11:31:59,264 - INFO - Early Stopping in Epoche 25
2025-05-06 11:31:59,264 - INFO - Training abgeschlossen in 4.88 Sekunden
2025-05-06 11:31:59,270 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 11:31:59,278 - INFO - Modell gespeichert als: models_optimized/qat_pizza_model.pth
2025-05-06 11:31:59,599 - INFO - Trainingshistorie gespeichert unter output/quantization_aware_training/qat_training_history.png
2025-05-06 11:31:59,599 - INFO - Konvertiere QAT-Modell zu quantisiertem Inferenzmodell...
2025-05-06 11:31:59,694 - INFO - Quantisiertes Modell gespeichert als: models_optimized/pizza_model_int8_qat.pth
2025-05-06 11:31:59,694 - INFO - Quantisierte Modellgröße: 126.08 KB
2025-05-06 11:31:59,694 - INFO - Evaluiere quantisiertes Modell...
2025-05-06 11:31:59,765 - WARNING - Fehler bei der Evaluierung des quantisierten Modells: 'FakeQuantize' object has no attribute 'activation_post_process'
2025-05-06 11:31:59,765 - INFO - Fahre mit der Speicherung des Modells fort ohne Evaluierung...
2025-05-06 11:31:59,765 - INFO - Vergleiche Modelle: Standard vs. QAT vs. Quantisiert...
2025-05-06 11:32:12,729 - INFO - Verwende Gerät: cuda
2025-05-06 11:32:12,729 - INFO - ================================================================================
2025-05-06 11:32:12,729 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:32:12,729 - INFO - ================================================================================
2025-05-06 11:32:12,729 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:32:12,729 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:32:12,729 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:32:12,729 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:32:12,729 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:32:12,729 - INFO - ================================================================================
2025-05-06 11:32:12,729 - INFO - Preparing optimized data loaders...
2025-05-06 11:32:12,730 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:32:12,768 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:32:12,768 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:32:12,768 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:32:12,768 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:32:12,768 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:32:12,768 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:32:12,768 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:32:12,769 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:32:12,770 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:32:12,770 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:32:12,907 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:32:13,084 - INFO - Speicheranalyse:
2025-05-06 11:32:13,084 - INFO -   Modellgröße (Float32): 309.99 KB
2025-05-06 11:32:13,084 - INFO -   Modellgröße (Int8): 77.50 KB (3.8% des Flash)
2025-05-06 11:32:13,084 - INFO -   Aktivierungsspeicher: 834.67 KB
2025-05-06 11:32:13,084 - INFO -   Gesamter Laufzeitspeicher: 912.17 KB (345.5% des RAM)
2025-05-06 11:32:13,084 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (912.17KB > 100KB)
2025-05-06 11:32:13,154 - INFO - Klassengewichte für Loss-Funktion: [0.83, 0.68, 0.75, 0.5, 1.0, 1.0]
2025-05-06 11:32:13,155 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:32:13,471 - INFO - Epoch 1/30 - Train Loss: 1.8140, Train Acc: 4.44% - Val Loss: 1.8058, Val Acc: 0.00%
2025-05-06 11:32:13,472 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:13,472 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:32:13,472 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:32:13,472 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:13,476 - INFO - Epoche 2: Observer-Learning deaktiviert
2025-05-06 11:32:13,656 - INFO - Epoch 2/30 - Train Loss: 1.8076, Train Acc: 17.78% - Val Loss: 1.8114, Val Acc: 8.33%
2025-05-06 11:32:13,656 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:13,656 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:32:13,656 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:32:13,656 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:32:13,656 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:32:13,666 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch2.pth
2025-05-06 11:32:13,666 - INFO - Epoche 3: Observer-Learning deaktiviert
2025-05-06 11:32:13,667 - INFO - Epoche 3: Fake-Quantisierung aktiviert
2025-05-06 11:32:13,843 - INFO - Epoch 3/30 - Train Loss: 1.7872, Train Acc: 20.00% - Val Loss: 1.8106, Val Acc: 8.33%
2025-05-06 11:32:13,843 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:13,844 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:32:13,844 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:32:13,844 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:32:13,844 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:32:13,844 - INFO - Epoche 4: Observer-Learning deaktiviert
2025-05-06 11:32:13,844 - INFO - Epoche 4: Fake-Quantisierung aktiviert
2025-05-06 11:32:14,057 - INFO - Epoch 4/30 - Train Loss: 1.7627, Train Acc: 28.89% - Val Loss: 1.8035, Val Acc: 0.00%
2025-05-06 11:32:14,057 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:14,057 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:32:14,057 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:32:14,057 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:14,064 - INFO - Epoche 5: Observer-Learning aktiviert
2025-05-06 11:32:14,065 - INFO - Epoche 5: Fake-Quantisierung aktiviert
2025-05-06 11:32:14,268 - INFO - Epoch 5/30 - Train Loss: 1.7503, Train Acc: 13.33% - Val Loss: 1.7896, Val Acc: 0.00%
2025-05-06 11:32:14,269 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:14,269 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:32:14,269 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:32:14,269 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:14,282 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch5.pth
2025-05-06 11:32:14,282 - INFO - Epoche 6: Observer-Learning deaktiviert
2025-05-06 11:32:14,283 - INFO - Epoche 6: Fake-Quantisierung aktiviert
2025-05-06 11:32:14,463 - INFO - Epoch 6/30 - Train Loss: 1.7164, Train Acc: 26.67% - Val Loss: 1.7611, Val Acc: 0.00%
2025-05-06 11:32:14,463 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:14,463 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:32:14,463 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:32:14,463 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:14,467 - INFO - Epoche 7: Observer-Learning deaktiviert
2025-05-06 11:32:14,468 - INFO - Epoche 7: Fake-Quantisierung aktiviert
2025-05-06 11:32:14,637 - INFO - Epoch 7/30 - Train Loss: 1.6806, Train Acc: 31.11% - Val Loss: 1.7240, Val Acc: 0.00%
2025-05-06 11:32:14,637 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:14,637 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:32:14,637 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:32:14,637 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:14,641 - INFO - Epoche 8: Observer-Learning deaktiviert
2025-05-06 11:32:14,643 - INFO - Epoche 8: Fake-Quantisierung aktiviert
2025-05-06 11:32:14,824 - INFO - Epoch 8/30 - Train Loss: 1.6741, Train Acc: 37.78% - Val Loss: 1.6966, Val Acc: 8.33%
2025-05-06 11:32:14,824 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:14,824 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:32:14,824 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:32:14,824 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:14,829 - INFO - Epoche 9: Observer-Learning aktiviert
2025-05-06 11:32:14,829 - INFO - Epoche 9: Fake-Quantisierung aktiviert
2025-05-06 11:32:15,035 - INFO - Epoch 9/30 - Train Loss: 1.5721, Train Acc: 37.78% - Val Loss: 1.6663, Val Acc: 8.33%
2025-05-06 11:32:15,036 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:15,036 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:32:15,036 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:32:15,036 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:15,039 - INFO - Epoche 10: Observer-Learning deaktiviert
2025-05-06 11:32:15,040 - INFO - Epoche 10: Fake-Quantisierung aktiviert
2025-05-06 11:32:15,211 - INFO - Epoch 10/30 - Train Loss: 1.5141, Train Acc: 51.11% - Val Loss: 1.6311, Val Acc: 8.33%
2025-05-06 11:32:15,211 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:15,211 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:32:15,211 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:32:15,211 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:15,234 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch10.pth
2025-05-06 11:32:15,234 - INFO - Epoche 11: Observer-Learning deaktiviert
2025-05-06 11:32:15,236 - INFO - Epoche 11: Fake-Quantisierung aktiviert
2025-05-06 11:32:15,407 - INFO - Epoch 11/30 - Train Loss: 1.5416, Train Acc: 24.44% - Val Loss: 1.5695, Val Acc: 8.33%
2025-05-06 11:32:15,408 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:15,408 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:32:15,408 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:32:15,408 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:15,412 - INFO - Epoche 12: Observer-Learning deaktiviert
2025-05-06 11:32:15,413 - INFO - Epoche 12: Fake-Quantisierung aktiviert
2025-05-06 11:32:15,598 - INFO - Epoch 12/30 - Train Loss: 1.4999, Train Acc: 35.56% - Val Loss: 1.5408, Val Acc: 8.33%
2025-05-06 11:32:15,598 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:15,598 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:32:15,598 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:32:15,598 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:15,603 - INFO - Epoche 13: Observer-Learning aktiviert
2025-05-06 11:32:15,604 - INFO - Epoche 13: Fake-Quantisierung aktiviert
2025-05-06 11:32:15,816 - INFO - Epoch 13/30 - Train Loss: 1.4765, Train Acc: 42.22% - Val Loss: 1.5048, Val Acc: 8.33%
2025-05-06 11:32:15,816 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:15,817 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:32:15,817 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:32:15,817 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:15,820 - INFO - Epoche 14: Observer-Learning deaktiviert
2025-05-06 11:32:15,822 - INFO - Epoche 14: Fake-Quantisierung aktiviert
2025-05-06 11:32:15,993 - INFO - Epoch 14/30 - Train Loss: 1.4001, Train Acc: 55.56% - Val Loss: 1.4766, Val Acc: 33.33%
2025-05-06 11:32:15,993 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:15,993 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:32:15,993 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:32:15,993 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:16,010 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch14.pth
2025-05-06 11:32:16,010 - INFO - Epoche 15: Observer-Learning deaktiviert
2025-05-06 11:32:16,011 - INFO - Epoche 15: Fake-Quantisierung aktiviert
2025-05-06 11:32:16,189 - INFO - Epoch 15/30 - Train Loss: 1.3042, Train Acc: 57.78% - Val Loss: 1.4427, Val Acc: 33.33%
2025-05-06 11:32:16,190 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:16,190 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:32:16,190 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:32:16,190 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:16,206 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch15.pth
2025-05-06 11:32:16,206 - INFO - Epoche 16: Observer-Learning deaktiviert
2025-05-06 11:32:16,207 - INFO - Epoche 16: Fake-Quantisierung aktiviert
2025-05-06 11:32:16,395 - INFO - Epoch 16/30 - Train Loss: 1.2744, Train Acc: 55.56% - Val Loss: 1.4037, Val Acc: 41.67%
2025-05-06 11:32:16,395 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:16,395 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:32:16,395 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:32:16,395 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:16,416 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch16.pth
2025-05-06 11:32:16,416 - INFO - Epoche 17: Observer-Learning aktiviert
2025-05-06 11:32:16,417 - INFO - Epoche 17: Fake-Quantisierung aktiviert
2025-05-06 11:32:16,617 - INFO - Epoch 17/30 - Train Loss: 1.3397, Train Acc: 44.44% - Val Loss: 1.3672, Val Acc: 41.67%
2025-05-06 11:32:16,617 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:16,618 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:32:16,618 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:32:16,618 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:16,622 - INFO - Epoche 18: Observer-Learning deaktiviert
2025-05-06 11:32:16,623 - INFO - Epoche 18: Fake-Quantisierung aktiviert
2025-05-06 11:32:16,807 - INFO - Epoch 18/30 - Train Loss: 1.2742, Train Acc: 51.11% - Val Loss: 1.3530, Val Acc: 41.67%
2025-05-06 11:32:16,807 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:16,807 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:32:16,807 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:32:16,807 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:16,812 - INFO - Epoche 19: Observer-Learning deaktiviert
2025-05-06 11:32:16,813 - INFO - Epoche 19: Fake-Quantisierung aktiviert
2025-05-06 11:32:17,009 - INFO - Epoch 19/30 - Train Loss: 1.2043, Train Acc: 51.11% - Val Loss: 1.3626, Val Acc: 50.00%
2025-05-06 11:32:17,009 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:17,009 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:32:17,009 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:32:17,009 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:17,009 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:32:17,018 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch19.pth
2025-05-06 11:32:17,018 - INFO - Epoche 20: Observer-Learning deaktiviert
2025-05-06 11:32:17,018 - INFO - Epoche 20: Fake-Quantisierung aktiviert
2025-05-06 11:32:17,193 - INFO - Epoch 20/30 - Train Loss: 1.3109, Train Acc: 37.78% - Val Loss: 1.3919, Val Acc: 50.00%
2025-05-06 11:32:17,193 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:17,194 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:32:17,194 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:32:17,194 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:17,194 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:32:17,203 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch20.pth
2025-05-06 11:32:17,203 - INFO - Epoche 21: Observer-Learning aktiviert
2025-05-06 11:32:17,203 - INFO - Epoche 21: Fake-Quantisierung aktiviert
2025-05-06 11:32:17,419 - INFO - Epoch 21/30 - Train Loss: 1.1557, Train Acc: 57.78% - Val Loss: 1.3934, Val Acc: 33.33%
2025-05-06 11:32:17,419 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:17,419 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:32:17,419 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:32:17,419 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:17,419 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:32:17,419 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:32:17,419 - INFO - Epoche 22: Observer-Learning deaktiviert
2025-05-06 11:32:17,420 - INFO - Epoche 22: Fake-Quantisierung aktiviert
2025-05-06 11:32:17,589 - INFO - Epoch 22/30 - Train Loss: 1.2871, Train Acc: 44.44% - Val Loss: 1.4044, Val Acc: 25.00%
2025-05-06 11:32:17,589 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:17,589 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:32:17,589 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:32:17,589 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:17,589 - INFO - EarlyStopping counter: 9/10
2025-05-06 11:32:17,589 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:32:17,589 - INFO - Epoche 23: Observer-Learning deaktiviert
2025-05-06 11:32:17,590 - INFO - Epoche 23: Fake-Quantisierung aktiviert
2025-05-06 11:32:17,760 - INFO - Epoch 23/30 - Train Loss: 1.2797, Train Acc: 42.22% - Val Loss: 1.3617, Val Acc: 50.00%
2025-05-06 11:32:17,760 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:32:17,760 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:32:17,760 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:32:17,760 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:32:17,760 - INFO - EarlyStopping counter: 10/10
2025-05-06 11:32:17,760 - INFO - Early Stopping in Epoche 23
2025-05-06 11:32:17,761 - INFO - Training abgeschlossen in 4.61 Sekunden
2025-05-06 11:32:17,766 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 11:32:17,774 - INFO - Modell gespeichert als: models_optimized/qat_pizza_model.pth
2025-05-06 11:32:18,099 - INFO - Trainingshistorie gespeichert unter output/quantization_aware_training/qat_training_history.png
2025-05-06 11:32:18,099 - INFO - Konvertiere QAT-Modell zu quantisiertem Inferenzmodell...
2025-05-06 11:32:18,193 - INFO - Quantisiertes Modell gespeichert als: models_optimized/pizza_model_int8_qat.pth
2025-05-06 11:32:18,193 - INFO - Quantisierte Modellgröße: 126.08 KB
2025-05-06 11:32:18,193 - INFO - Evaluiere quantisiertes Modell...
2025-05-06 11:32:18,263 - WARNING - Fehler bei der Evaluierung des quantisierten Modells: 'FakeQuantize' object has no attribute 'activation_post_process'
2025-05-06 11:32:18,263 - INFO - Fahre mit der Speicherung des Modells fort ohne Evaluierung...
2025-05-06 11:32:18,263 - INFO - Vergleiche Modelle: Standard vs. QAT vs. Quantisiert...
2025-05-06 11:33:10,596 - INFO - Verwende Gerät: cpu
2025-05-06 11:33:10,596 - INFO - ================================================================================
2025-05-06 11:33:10,596 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:33:10,596 - INFO - ================================================================================
2025-05-06 11:33:10,596 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:33:10,596 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:33:10,596 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:33:10,596 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:33:10,596 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:33:10,596 - INFO - ================================================================================
2025-05-06 11:33:10,596 - INFO - Preparing optimized data loaders...
2025-05-06 11:33:10,596 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:33:10,636 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:33:10,636 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:33:10,636 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:33:10,636 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:33:10,636 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:33:10,636 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:33:10,636 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:33:10,638 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:33:10,638 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:33:10,638 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:33:10,669 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:33:10,729 - INFO - Speicheranalyse:
2025-05-06 11:33:10,729 - INFO -   Modellgröße (Float32): 309.99 KB
2025-05-06 11:33:10,729 - INFO -   Modellgröße (Int8): 77.50 KB (3.8% des Flash)
2025-05-06 11:33:10,729 - INFO -   Aktivierungsspeicher: 834.67 KB
2025-05-06 11:33:10,729 - INFO -   Gesamter Laufzeitspeicher: 912.17 KB (345.5% des RAM)
2025-05-06 11:33:10,729 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (912.17KB > 100KB)
2025-05-06 11:33:10,904 - INFO - Klassengewichte für Loss-Funktion: [0.94, 0.58, 1.07, 0.44, 1.0, 1.0]
2025-05-06 11:33:10,905 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:36:53,916 - INFO - Verwende Gerät: cuda
2025-05-06 11:36:53,916 - INFO - ================================================================================
2025-05-06 11:36:53,916 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:36:53,916 - INFO - ================================================================================
2025-05-06 11:36:53,916 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:36:53,916 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:36:53,916 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:36:53,916 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:36:53,916 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:36:53,916 - INFO - ================================================================================
2025-05-06 11:36:53,916 - INFO - Preparing optimized data loaders...
2025-05-06 11:36:53,916 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:36:53,953 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:36:53,953 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:36:53,953 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:36:53,953 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:36:53,953 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:36:53,953 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:36:53,954 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:36:53,955 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:36:53,955 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:36:53,955 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:36:54,098 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:36:54,272 - INFO - Speicheranalyse:
2025-05-06 11:36:54,272 - INFO -   Modellgröße (Float32): 309.99 KB
2025-05-06 11:36:54,272 - INFO -   Modellgröße (Int8): 77.50 KB (3.8% des Flash)
2025-05-06 11:36:54,272 - INFO -   Aktivierungsspeicher: 834.67 KB
2025-05-06 11:36:54,272 - INFO -   Gesamter Laufzeitspeicher: 912.17 KB (345.5% des RAM)
2025-05-06 11:36:54,272 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (912.17KB > 100KB)
2025-05-06 11:36:54,342 - INFO - Klassengewichte für Loss-Funktion: [0.54, 0.68, 0.94, 0.62, 1.0, 1.0]
2025-05-06 11:36:54,343 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:36:54,636 - INFO - Epoch 1/30 - Train Loss: 1.7792, Train Acc: 17.78% - Val Loss: 1.7877, Val Acc: 25.00%
2025-05-06 11:36:54,636 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:54,636 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:36:54,636 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:36:54,636 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:54,676 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch1.pth
2025-05-06 11:36:54,676 - INFO - Epoche 2: Observer-Learning deaktiviert
2025-05-06 11:36:54,830 - INFO - Epoch 2/30 - Train Loss: 1.7859, Train Acc: 20.00% - Val Loss: 1.7844, Val Acc: 25.00%
2025-05-06 11:36:54,830 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:54,830 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:36:54,830 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:36:54,830 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:54,834 - INFO - Epoche 3: Observer-Learning deaktiviert
2025-05-06 11:36:54,835 - INFO - Epoche 3: Fake-Quantisierung aktiviert
2025-05-06 11:36:54,990 - INFO - Epoch 3/30 - Train Loss: 1.7826, Train Acc: 11.11% - Val Loss: 1.7763, Val Acc: 25.00%
2025-05-06 11:36:54,990 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:54,990 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:36:54,990 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:36:54,990 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:54,994 - INFO - Epoche 4: Observer-Learning deaktiviert
2025-05-06 11:36:54,994 - INFO - Epoche 4: Fake-Quantisierung aktiviert
2025-05-06 11:36:55,146 - INFO - Epoch 4/30 - Train Loss: 1.7461, Train Acc: 24.44% - Val Loss: 1.7700, Val Acc: 16.67%
2025-05-06 11:36:55,146 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:55,146 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:36:55,146 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:55,146 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:36:55,150 - INFO - Epoche 5: Observer-Learning aktiviert
2025-05-06 11:36:55,150 - INFO - Epoche 5: Fake-Quantisierung aktiviert
2025-05-06 11:36:55,329 - INFO - Epoch 5/30 - Train Loss: 1.6972, Train Acc: 44.44% - Val Loss: 1.7594, Val Acc: 16.67%
2025-05-06 11:36:55,329 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:55,329 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:36:55,329 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:55,329 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:36:55,349 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch5.pth
2025-05-06 11:36:55,349 - INFO - Epoche 6: Observer-Learning deaktiviert
2025-05-06 11:36:55,349 - INFO - Epoche 6: Fake-Quantisierung aktiviert
2025-05-06 11:36:55,511 - INFO - Epoch 6/30 - Train Loss: 1.7135, Train Acc: 24.44% - Val Loss: 1.7436, Val Acc: 16.67%
2025-05-06 11:36:55,511 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:55,511 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:36:55,511 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:55,511 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:36:55,515 - INFO - Epoche 7: Observer-Learning deaktiviert
2025-05-06 11:36:55,516 - INFO - Epoche 7: Fake-Quantisierung aktiviert
2025-05-06 11:36:55,674 - INFO - Epoch 7/30 - Train Loss: 1.6588, Train Acc: 33.33% - Val Loss: 1.7347, Val Acc: 16.67%
2025-05-06 11:36:55,674 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:55,674 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:36:55,674 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:55,674 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:36:55,679 - INFO - Epoche 8: Observer-Learning deaktiviert
2025-05-06 11:36:55,681 - INFO - Epoche 8: Fake-Quantisierung aktiviert
2025-05-06 11:36:55,844 - INFO - Epoch 8/30 - Train Loss: 1.6246, Train Acc: 35.56% - Val Loss: 1.7200, Val Acc: 16.67%
2025-05-06 11:36:55,844 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:55,844 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:36:55,844 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:55,844 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:36:55,848 - INFO - Epoche 9: Observer-Learning aktiviert
2025-05-06 11:36:55,849 - INFO - Epoche 9: Fake-Quantisierung aktiviert
2025-05-06 11:36:56,035 - INFO - Epoch 9/30 - Train Loss: 1.5681, Train Acc: 35.56% - Val Loss: 1.7016, Val Acc: 8.33%
2025-05-06 11:36:56,035 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:56,035 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:36:56,035 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:56,035 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:56,039 - INFO - Epoche 10: Observer-Learning deaktiviert
2025-05-06 11:36:56,040 - INFO - Epoche 10: Fake-Quantisierung aktiviert
2025-05-06 11:36:56,197 - INFO - Epoch 10/30 - Train Loss: 1.4985, Train Acc: 42.22% - Val Loss: 1.6795, Val Acc: 8.33%
2025-05-06 11:36:56,197 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:56,197 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:36:56,197 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:56,197 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:56,220 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch10.pth
2025-05-06 11:36:56,221 - INFO - Epoche 11: Observer-Learning deaktiviert
2025-05-06 11:36:56,222 - INFO - Epoche 11: Fake-Quantisierung aktiviert
2025-05-06 11:36:56,380 - INFO - Epoch 11/30 - Train Loss: 1.4509, Train Acc: 48.89% - Val Loss: 1.6482, Val Acc: 8.33%
2025-05-06 11:36:56,380 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:56,380 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:36:56,380 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:56,380 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:56,385 - INFO - Epoche 12: Observer-Learning deaktiviert
2025-05-06 11:36:56,387 - INFO - Epoche 12: Fake-Quantisierung aktiviert
2025-05-06 11:36:56,549 - INFO - Epoch 12/30 - Train Loss: 1.4164, Train Acc: 46.67% - Val Loss: 1.6236, Val Acc: 8.33%
2025-05-06 11:36:56,549 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:56,549 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:36:56,549 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:56,549 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:56,553 - INFO - Epoche 13: Observer-Learning aktiviert
2025-05-06 11:36:56,555 - INFO - Epoche 13: Fake-Quantisierung aktiviert
2025-05-06 11:36:56,764 - INFO - Epoch 13/30 - Train Loss: 1.3471, Train Acc: 48.89% - Val Loss: 1.5789, Val Acc: 8.33%
2025-05-06 11:36:56,764 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:56,764 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:36:56,764 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:56,764 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:56,769 - INFO - Epoche 14: Observer-Learning deaktiviert
2025-05-06 11:36:56,772 - INFO - Epoche 14: Fake-Quantisierung aktiviert
2025-05-06 11:36:56,947 - INFO - Epoch 14/30 - Train Loss: 1.4601, Train Acc: 35.56% - Val Loss: 1.5567, Val Acc: 8.33%
2025-05-06 11:36:56,947 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:56,947 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:36:56,947 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:56,947 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:56,952 - INFO - Epoche 15: Observer-Learning deaktiviert
2025-05-06 11:36:56,955 - INFO - Epoche 15: Fake-Quantisierung aktiviert
2025-05-06 11:36:57,112 - INFO - Epoch 15/30 - Train Loss: 1.3569, Train Acc: 46.67% - Val Loss: 1.5423, Val Acc: 8.33%
2025-05-06 11:36:57,113 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:57,113 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:36:57,113 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:57,113 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:57,126 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch15.pth
2025-05-06 11:36:57,127 - INFO - Epoche 16: Observer-Learning deaktiviert
2025-05-06 11:36:57,127 - INFO - Epoche 16: Fake-Quantisierung aktiviert
2025-05-06 11:36:57,285 - INFO - Epoch 16/30 - Train Loss: 1.3547, Train Acc: 46.67% - Val Loss: 1.5164, Val Acc: 16.67%
2025-05-06 11:36:57,285 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:57,285 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:36:57,285 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:57,285 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:57,289 - INFO - Epoche 17: Observer-Learning aktiviert
2025-05-06 11:36:57,290 - INFO - Epoche 17: Fake-Quantisierung aktiviert
2025-05-06 11:36:57,473 - INFO - Epoch 17/30 - Train Loss: 1.2292, Train Acc: 57.78% - Val Loss: 1.3989, Val Acc: 25.00%
2025-05-06 11:36:57,473 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:57,473 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:36:57,473 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:57,473 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:57,477 - INFO - Epoche 18: Observer-Learning deaktiviert
2025-05-06 11:36:57,478 - INFO - Epoche 18: Fake-Quantisierung aktiviert
2025-05-06 11:36:57,628 - INFO - Epoch 18/30 - Train Loss: 1.2798, Train Acc: 44.44% - Val Loss: 1.3671, Val Acc: 33.33%
2025-05-06 11:36:57,629 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:57,629 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:36:57,629 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:57,629 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:57,643 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch18.pth
2025-05-06 11:36:57,643 - INFO - Epoche 19: Observer-Learning deaktiviert
2025-05-06 11:36:57,644 - INFO - Epoche 19: Fake-Quantisierung aktiviert
2025-05-06 11:36:57,792 - INFO - Epoch 19/30 - Train Loss: 1.3117, Train Acc: 46.67% - Val Loss: 1.3700, Val Acc: 33.33%
2025-05-06 11:36:57,792 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:57,792 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:36:57,792 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:57,792 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:57,792 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:36:57,792 - INFO - Epoche 20: Observer-Learning deaktiviert
2025-05-06 11:36:57,793 - INFO - Epoche 20: Fake-Quantisierung aktiviert
2025-05-06 11:36:57,953 - INFO - Epoch 20/30 - Train Loss: 1.2943, Train Acc: 51.11% - Val Loss: 1.3674, Val Acc: 33.33%
2025-05-06 11:36:57,953 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:57,953 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:36:57,953 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:57,953 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:57,953 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:36:57,962 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch20.pth
2025-05-06 11:36:57,962 - INFO - Epoche 21: Observer-Learning aktiviert
2025-05-06 11:36:57,964 - INFO - Epoche 21: Fake-Quantisierung aktiviert
2025-05-06 11:36:58,145 - INFO - Epoch 21/30 - Train Loss: 1.1743, Train Acc: 62.22% - Val Loss: 1.3130, Val Acc: 41.67%
2025-05-06 11:36:58,145 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:58,145 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:36:58,145 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:58,145 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:58,173 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch21.pth
2025-05-06 11:36:58,173 - INFO - Epoche 22: Observer-Learning deaktiviert
2025-05-06 11:36:58,174 - INFO - Epoche 22: Fake-Quantisierung aktiviert
2025-05-06 11:36:58,338 - INFO - Epoch 22/30 - Train Loss: 1.2379, Train Acc: 48.89% - Val Loss: 1.3192, Val Acc: 41.67%
2025-05-06 11:36:58,338 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:58,338 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:36:58,338 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:58,338 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:58,339 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:36:58,339 - INFO - Epoche 23: Observer-Learning deaktiviert
2025-05-06 11:36:58,339 - INFO - Epoche 23: Fake-Quantisierung aktiviert
2025-05-06 11:36:58,504 - INFO - Epoch 23/30 - Train Loss: 1.1983, Train Acc: 53.33% - Val Loss: 1.3408, Val Acc: 41.67%
2025-05-06 11:36:58,505 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:58,505 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:36:58,505 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:58,505 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:58,505 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:36:58,505 - INFO - Epoche 24: Observer-Learning deaktiviert
2025-05-06 11:36:58,505 - INFO - Epoche 24: Fake-Quantisierung aktiviert
2025-05-06 11:36:58,658 - INFO - Epoch 24/30 - Train Loss: 1.2366, Train Acc: 42.22% - Val Loss: 1.3879, Val Acc: 25.00%
2025-05-06 11:36:58,659 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:58,659 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:36:58,659 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:58,659 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:58,659 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:36:58,659 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:36:58,659 - INFO - Epoche 25: Observer-Learning aktiviert
2025-05-06 11:36:58,659 - INFO - Epoche 25: Fake-Quantisierung aktiviert
2025-05-06 11:36:58,834 - INFO - Epoch 25/30 - Train Loss: 1.1842, Train Acc: 57.78% - Val Loss: 1.3729, Val Acc: 25.00%
2025-05-06 11:36:58,835 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:58,835 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:36:58,835 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:58,835 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:58,835 - INFO - EarlyStopping counter: 9/10
2025-05-06 11:36:58,835 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:36:58,843 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch25.pth
2025-05-06 11:36:58,844 - INFO - Epoche 26: Observer-Learning deaktiviert
2025-05-06 11:36:58,844 - INFO - Epoche 26: Fake-Quantisierung aktiviert
2025-05-06 11:36:58,996 - INFO - Epoch 26/30 - Train Loss: 1.2028, Train Acc: 40.00% - Val Loss: 1.3725, Val Acc: 33.33%
2025-05-06 11:36:58,996 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:36:58,996 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:36:58,996 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:36:58,996 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:36:58,996 - INFO - EarlyStopping counter: 10/10
2025-05-06 11:36:58,996 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:36:58,996 - INFO - Early Stopping in Epoche 26
2025-05-06 11:36:58,996 - INFO - Training abgeschlossen in 4.65 Sekunden
2025-05-06 11:36:59,001 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 11:36:59,010 - INFO - Modell gespeichert als: models_optimized/qat_pizza_model.pth
2025-05-06 11:36:59,330 - INFO - Trainingshistorie gespeichert unter output/quantization_aware_training/qat_training_history.png
2025-05-06 11:36:59,330 - INFO - Konvertiere QAT-Modell zu quantisiertem Inferenzmodell...
2025-05-06 11:36:59,438 - INFO - Quantisiertes Modell gespeichert als: models_optimized/pizza_model_int8_qat.pth
2025-05-06 11:36:59,438 - INFO - Quantisierte Modellgröße: 126.08 KB
2025-05-06 11:36:59,438 - INFO - Evaluiere quantisiertes Modell...
2025-05-06 11:36:59,520 - WARNING - Fehler bei der Evaluierung des quantisierten Modells: 'FakeQuantize' object has no attribute 'activation_post_process'
2025-05-06 11:36:59,520 - INFO - Fahre mit der Speicherung des Modells fort ohne Evaluierung...
2025-05-06 11:36:59,521 - INFO - Vergleiche Modelle: Standard vs. QAT vs. Quantisiert...
2025-05-06 11:38:00,097 - INFO - Verwende Gerät: cpu
2025-05-06 11:38:00,098 - INFO - ================================================================================
2025-05-06 11:38:00,098 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:38:00,098 - INFO - ================================================================================
2025-05-06 11:38:00,098 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:38:00,098 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:38:00,098 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:38:00,098 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:38:00,098 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:38:00,098 - INFO - ================================================================================
2025-05-06 11:38:00,098 - INFO - Preparing optimized data loaders...
2025-05-06 11:38:00,098 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:38:00,137 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:38:00,137 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:38:00,137 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:38:00,137 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:38:00,137 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:38:00,137 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:38:00,137 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:38:00,138 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:38:00,138 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:38:00,138 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:38:00,169 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:38:00,178 - INFO - Speicheranalyse:
2025-05-06 11:38:00,178 - INFO -   Modellgröße (Float32): 309.99 KB
2025-05-06 11:38:00,178 - INFO -   Modellgröße (Int8): 77.50 KB (3.8% des Flash)
2025-05-06 11:38:00,178 - INFO -   Aktivierungsspeicher: 834.67 KB
2025-05-06 11:38:00,178 - INFO -   Gesamter Laufzeitspeicher: 912.17 KB (345.5% des RAM)
2025-05-06 11:38:00,178 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (912.17KB > 100KB)
2025-05-06 11:38:00,344 - INFO - Klassengewichte für Loss-Funktion: [0.83, 0.47, 0.83, 0.68, 1.0, 1.0]
2025-05-06 11:38:00,344 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:38:00,437 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:00,437 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:00,509 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:00,510 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:00,534 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:00,534 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:00,621 - INFO - Epoch 1/30 - Train Loss: 1.7740, Train Acc: 22.22% - Val Loss: 1.7976, Val Acc: 0.00%
2025-05-06 11:38:00,621 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:00,621 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:38:00,621 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:38:00,621 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:38:00,623 - INFO - Epoche 2: Observer-Learning deaktiviert
2025-05-06 11:38:00,679 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:00,679 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:00,703 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:00,703 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:00,720 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:00,721 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:00,824 - INFO - Epoch 2/30 - Train Loss: 1.7792, Train Acc: 22.22% - Val Loss: 1.8005, Val Acc: 0.00%
2025-05-06 11:38:00,824 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:00,824 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:38:00,824 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:38:00,824 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:38:00,824 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:38:00,824 - INFO - Epoche 3: Observer-Learning deaktiviert
2025-05-06 11:38:00,825 - INFO - Epoche 3: Fake-Quantisierung aktiviert
2025-05-06 11:38:00,876 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:00,876 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:00,899 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:00,899 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:00,920 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:00,920 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:01,013 - INFO - Epoch 3/30 - Train Loss: 1.7843, Train Acc: 15.56% - Val Loss: 1.7976, Val Acc: 0.00%
2025-05-06 11:38:01,014 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:01,014 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:38:01,014 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:38:01,014 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:38:01,014 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:38:01,014 - INFO - Epoche 4: Observer-Learning deaktiviert
2025-05-06 11:38:01,014 - INFO - Epoche 4: Fake-Quantisierung aktiviert
2025-05-06 11:38:01,065 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:01,065 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:01,088 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:01,088 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:01,106 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:01,106 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:01,197 - INFO - Epoch 4/30 - Train Loss: 1.7494, Train Acc: 31.11% - Val Loss: 1.7889, Val Acc: 0.00%
2025-05-06 11:38:01,197 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:01,197 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:38:01,197 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:38:01,197 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:38:01,200 - INFO - Epoche 5: Observer-Learning aktiviert
2025-05-06 11:38:01,200 - INFO - Epoche 5: Fake-Quantisierung aktiviert
2025-05-06 11:38:01,254 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:01,255 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:01,296 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:01,296 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:01,339 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:01,340 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:01,440 - INFO - Epoch 5/30 - Train Loss: 1.7230, Train Acc: 35.56% - Val Loss: 1.7726, Val Acc: 8.33%
2025-05-06 11:38:01,441 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:01,441 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:38:01,441 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:38:01,441 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:38:01,456 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch5.pth
2025-05-06 11:38:01,456 - INFO - Epoche 6: Observer-Learning deaktiviert
2025-05-06 11:38:01,457 - INFO - Epoche 6: Fake-Quantisierung aktiviert
2025-05-06 11:38:01,511 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:01,511 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:01,539 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:01,539 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:01,567 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:01,567 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:01,653 - INFO - Epoch 6/30 - Train Loss: 1.6875, Train Acc: 35.56% - Val Loss: 1.7497, Val Acc: 8.33%
2025-05-06 11:38:01,653 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:01,653 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:38:01,653 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:38:01,653 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:38:01,655 - INFO - Epoche 7: Observer-Learning deaktiviert
2025-05-06 11:38:01,655 - INFO - Epoche 7: Fake-Quantisierung aktiviert
2025-05-06 11:38:01,707 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:01,707 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:01,734 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:01,734 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:01,753 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:01,753 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:01,860 - INFO - Epoch 7/30 - Train Loss: 1.6600, Train Acc: 33.33% - Val Loss: 1.7264, Val Acc: 16.67%
2025-05-06 11:38:01,860 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:01,860 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:38:01,860 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:38:01,861 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:38:01,884 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch7.pth
2025-05-06 11:38:01,884 - INFO - Epoche 8: Observer-Learning deaktiviert
2025-05-06 11:38:01,885 - INFO - Epoche 8: Fake-Quantisierung aktiviert
2025-05-06 11:38:01,937 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:01,937 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:01,970 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:01,970 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:01,998 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:01,998 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:02,107 - INFO - Epoch 8/30 - Train Loss: 1.6394, Train Acc: 33.33% - Val Loss: 1.6849, Val Acc: 16.67%
2025-05-06 11:38:02,108 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:02,108 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:38:02,108 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:38:02,108 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:38:02,111 - INFO - Epoche 9: Observer-Learning aktiviert
2025-05-06 11:38:02,111 - INFO - Epoche 9: Fake-Quantisierung aktiviert
2025-05-06 11:38:02,176 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:02,177 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:02,232 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:02,232 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:02,275 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:02,275 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:02,399 - INFO - Epoch 9/30 - Train Loss: 1.5704, Train Acc: 37.78% - Val Loss: 1.6407, Val Acc: 25.00%
2025-05-06 11:38:02,399 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:02,399 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:38:02,399 - INFO -   combined: 66.67% (2/3)
2025-05-06 11:38:02,399 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:38:02,408 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch9.pth
2025-05-06 11:38:02,408 - INFO - Epoche 10: Observer-Learning deaktiviert
2025-05-06 11:38:02,408 - INFO - Epoche 10: Fake-Quantisierung aktiviert
2025-05-06 11:38:02,466 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:02,467 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:02,515 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:02,515 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:02,544 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:02,544 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:02,637 - INFO - Epoch 10/30 - Train Loss: 1.5299, Train Acc: 35.56% - Val Loss: 1.5709, Val Acc: 16.67%
2025-05-06 11:38:02,637 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:02,637 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:38:02,638 - INFO -   combined: 66.67% (2/3)
2025-05-06 11:38:02,638 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:38:02,647 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch10.pth
2025-05-06 11:38:02,647 - INFO - Epoche 11: Observer-Learning deaktiviert
2025-05-06 11:38:02,647 - INFO - Epoche 11: Fake-Quantisierung aktiviert
2025-05-06 11:38:02,704 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:02,704 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:02,730 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:02,730 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:02,758 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:02,758 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:02,847 - INFO - Epoch 11/30 - Train Loss: 1.4490, Train Acc: 53.33% - Val Loss: 1.5164, Val Acc: 16.67%
2025-05-06 11:38:02,848 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:02,848 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:38:02,848 - INFO -   combined: 66.67% (2/3)
2025-05-06 11:38:02,848 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:38:02,850 - INFO - Epoche 12: Observer-Learning deaktiviert
2025-05-06 11:38:02,850 - INFO - Epoche 12: Fake-Quantisierung aktiviert
2025-05-06 11:38:02,906 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:02,906 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:02,932 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:02,932 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:02,958 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:02,959 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:03,050 - INFO - Epoch 12/30 - Train Loss: 1.4801, Train Acc: 31.11% - Val Loss: 1.4498, Val Acc: 33.33%
2025-05-06 11:38:03,051 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:03,051 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:38:03,051 - INFO -   combined: 66.67% (2/3)
2025-05-06 11:38:03,051 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:38:03,058 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch12.pth
2025-05-06 11:38:03,058 - INFO - Epoche 13: Observer-Learning aktiviert
2025-05-06 11:38:03,058 - INFO - Epoche 13: Fake-Quantisierung aktiviert
2025-05-06 11:38:03,114 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:03,114 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:03,144 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:03,144 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:03,166 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:03,166 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:03,255 - INFO - Epoch 13/30 - Train Loss: 1.3791, Train Acc: 31.11% - Val Loss: 1.3590, Val Acc: 58.33%
2025-05-06 11:38:03,255 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:03,255 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:38:03,255 - INFO -   combined: 66.67% (2/3)
2025-05-06 11:38:03,255 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:38:03,263 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch13.pth
2025-05-06 11:38:03,263 - INFO - Epoche 14: Observer-Learning deaktiviert
2025-05-06 11:38:03,263 - INFO - Epoche 14: Fake-Quantisierung aktiviert
2025-05-06 11:38:03,321 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:03,322 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:03,359 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:03,359 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:03,386 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:03,386 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:03,483 - INFO - Epoch 14/30 - Train Loss: 1.3694, Train Acc: 35.56% - Val Loss: 1.3295, Val Acc: 58.33%
2025-05-06 11:38:03,483 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:03,483 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:38:03,483 - INFO -   combined: 66.67% (2/3)
2025-05-06 11:38:03,483 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:38:03,485 - INFO - Epoche 15: Observer-Learning deaktiviert
2025-05-06 11:38:03,486 - INFO - Epoche 15: Fake-Quantisierung aktiviert
2025-05-06 11:38:03,540 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:03,540 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:03,585 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:03,585 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:03,613 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:03,613 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:03,722 - INFO - Epoch 15/30 - Train Loss: 1.4689, Train Acc: 24.44% - Val Loss: 1.3613, Val Acc: 41.67%
2025-05-06 11:38:03,722 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:03,723 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:38:03,723 - INFO -   combined: 66.67% (2/3)
2025-05-06 11:38:03,723 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:38:03,723 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:38:03,731 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch15.pth
2025-05-06 11:38:03,731 - INFO - Epoche 16: Observer-Learning deaktiviert
2025-05-06 11:38:03,732 - INFO - Epoche 16: Fake-Quantisierung aktiviert
2025-05-06 11:38:03,782 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:03,782 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:03,806 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:03,806 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:03,825 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:03,825 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:03,912 - INFO - Epoch 16/30 - Train Loss: 1.3588, Train Acc: 35.56% - Val Loss: 1.2829, Val Acc: 66.67%
2025-05-06 11:38:03,912 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:03,912 - INFO -   basic: 75.00% (6/8)
2025-05-06 11:38:03,912 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:38:03,912 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:38:03,921 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch16.pth
2025-05-06 11:38:03,921 - INFO - Epoche 17: Observer-Learning aktiviert
2025-05-06 11:38:03,921 - INFO - Epoche 17: Fake-Quantisierung aktiviert
2025-05-06 11:38:03,972 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:03,973 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:04,001 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:04,001 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:04,030 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:04,030 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:04,130 - INFO - Epoch 17/30 - Train Loss: 1.2895, Train Acc: 55.56% - Val Loss: 1.2991, Val Acc: 50.00%
2025-05-06 11:38:04,131 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:04,131 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:38:04,131 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:38:04,131 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:38:04,131 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:38:04,131 - INFO - Epoche 18: Observer-Learning deaktiviert
2025-05-06 11:38:04,131 - INFO - Epoche 18: Fake-Quantisierung aktiviert
2025-05-06 11:38:04,189 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:04,189 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:04,213 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:04,213 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:04,232 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:04,233 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:04,311 - INFO - Epoch 18/30 - Train Loss: 1.3247, Train Acc: 40.00% - Val Loss: 1.3005, Val Acc: 50.00%
2025-05-06 11:38:04,311 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:04,311 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:38:04,311 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:38:04,311 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:38:04,311 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:38:04,311 - INFO - Epoche 19: Observer-Learning deaktiviert
2025-05-06 11:38:04,312 - INFO - Epoche 19: Fake-Quantisierung aktiviert
2025-05-06 11:38:04,365 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:04,365 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:04,425 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:04,425 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:04,454 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:04,454 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:04,553 - INFO - Epoch 19/30 - Train Loss: 1.3668, Train Acc: 46.67% - Val Loss: 1.3361, Val Acc: 25.00%
2025-05-06 11:38:04,553 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:04,553 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:38:04,553 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:38:04,553 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:38:04,553 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:38:04,553 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:38:04,553 - INFO - Epoche 20: Observer-Learning deaktiviert
2025-05-06 11:38:04,553 - INFO - Epoche 20: Fake-Quantisierung aktiviert
2025-05-06 11:38:04,605 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:04,606 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:04,634 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:04,634 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:04,652 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:04,652 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:04,735 - INFO - Epoch 20/30 - Train Loss: 1.4214, Train Acc: 35.56% - Val Loss: 1.3509, Val Acc: 33.33%
2025-05-06 11:38:04,735 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:04,735 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:38:04,735 - INFO -   combined: 66.67% (2/3)
2025-05-06 11:38:04,735 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:38:04,735 - INFO - EarlyStopping counter: 9/10
2025-05-06 11:38:04,735 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:38:04,741 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch20.pth
2025-05-06 11:38:04,741 - INFO - Epoche 21: Observer-Learning aktiviert
2025-05-06 11:38:04,742 - INFO - Epoche 21: Fake-Quantisierung aktiviert
2025-05-06 11:38:04,793 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:38:04,794 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:04,824 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:04,825 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:04,859 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:38:04,859 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:38:04,964 - INFO - Epoch 21/30 - Train Loss: 1.2353, Train Acc: 60.00% - Val Loss: 1.3396, Val Acc: 41.67%
2025-05-06 11:38:04,964 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:38:04,964 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:38:04,964 - INFO -   combined: 66.67% (2/3)
2025-05-06 11:38:04,964 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:38:04,965 - INFO - EarlyStopping counter: 10/10
2025-05-06 11:38:04,965 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:38:04,965 - INFO - Early Stopping in Epoche 21
2025-05-06 11:38:04,965 - INFO - Training abgeschlossen in 4.62 Sekunden
2025-05-06 11:38:04,967 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 11:38:04,973 - INFO - Modell gespeichert als: models_optimized/qat_pizza_model.pth
2025-05-06 11:38:05,296 - INFO - Trainingshistorie gespeichert unter output/quantization_aware_training/qat_training_history.png
2025-05-06 11:38:05,297 - INFO - Konvertiere QAT-Modell zu quantisiertem Inferenzmodell...
2025-05-06 11:38:05,320 - INFO - Quantisiertes Modell gespeichert als: models_optimized/pizza_model_int8_qat.pth
2025-05-06 11:38:05,320 - INFO - Quantisierte Modellgröße: 126.08 KB
2025-05-06 11:38:05,320 - INFO - Evaluiere quantisiertes Modell...
2025-05-06 11:38:05,381 - WARNING - Fehler bei der Evaluierung des quantisierten Modells: 'FakeQuantize' object has no attribute 'activation_post_process'
2025-05-06 11:38:05,381 - INFO - Fahre mit der Speicherung des Modells fort ohne Evaluierung...
2025-05-06 11:38:05,381 - INFO - Vergleiche Modelle: Standard vs. QAT vs. Quantisiert...
2025-05-06 11:40:17,720 - INFO - Verwende Gerät: cuda
2025-05-06 11:40:17,720 - INFO - ================================================================================
2025-05-06 11:40:17,720 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:40:17,720 - INFO - ================================================================================
2025-05-06 11:40:17,720 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:40:17,720 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:40:17,720 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:40:17,720 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:40:17,720 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:40:17,720 - INFO - ================================================================================
2025-05-06 11:40:17,721 - INFO - Preparing optimized data loaders...
2025-05-06 11:40:17,721 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:40:17,776 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:40:17,776 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:40:17,776 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:40:17,776 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:40:17,776 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:40:17,776 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:40:17,776 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:40:17,778 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:40:17,778 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:40:17,779 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:40:17,942 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:40:18,478 - INFO - Speicheranalyse:
2025-05-06 11:40:18,478 - INFO -   Modellgröße (Float32): 309.99 KB
2025-05-06 11:40:18,478 - INFO -   Modellgröße (Int8): 77.50 KB (3.8% des Flash)
2025-05-06 11:40:18,478 - INFO -   Aktivierungsspeicher: 834.67 KB
2025-05-06 11:40:18,478 - INFO -   Gesamter Laufzeitspeicher: 912.17 KB (345.5% des RAM)
2025-05-06 11:40:18,478 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (912.17KB > 100KB)
2025-05-06 11:40:18,534 - INFO - Klassengewichte für Loss-Funktion: [0.68, 0.94, 0.62, 0.54, 1.0, 1.0]
2025-05-06 11:40:18,535 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:40:19,085 - INFO - Epoch 1/30 - Train Loss: 1.7831, Train Acc: 11.11% - Val Loss: 1.7859, Val Acc: 25.00%
2025-05-06 11:40:19,086 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:19,086 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:40:19,086 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:40:19,086 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:19,107 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch1.pth
2025-05-06 11:40:19,108 - INFO - Epoche 2: Observer-Learning deaktiviert
2025-05-06 11:40:19,238 - INFO - Epoch 2/30 - Train Loss: 1.7641, Train Acc: 31.11% - Val Loss: 1.7809, Val Acc: 25.00%
2025-05-06 11:40:19,238 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:19,238 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:40:19,238 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:40:19,238 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:19,243 - INFO - Epoche 3: Observer-Learning deaktiviert
2025-05-06 11:40:19,245 - INFO - Epoche 3: Fake-Quantisierung aktiviert
2025-05-06 11:40:19,384 - INFO - Epoch 3/30 - Train Loss: 1.7510, Train Acc: 31.11% - Val Loss: 1.7743, Val Acc: 25.00%
2025-05-06 11:40:19,384 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:19,384 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:40:19,384 - INFO -   combined: 100.00% (3/3)
2025-05-06 11:40:19,384 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:19,388 - INFO - Epoche 4: Observer-Learning deaktiviert
2025-05-06 11:40:19,389 - INFO - Epoche 4: Fake-Quantisierung aktiviert
2025-05-06 11:40:19,521 - INFO - Epoch 4/30 - Train Loss: 1.7512, Train Acc: 28.89% - Val Loss: 1.7629, Val Acc: 0.00%
2025-05-06 11:40:19,521 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:19,521 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:40:19,521 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:40:19,521 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:19,525 - INFO - Epoche 5: Observer-Learning aktiviert
2025-05-06 11:40:19,526 - INFO - Epoche 5: Fake-Quantisierung aktiviert
2025-05-06 11:40:19,686 - INFO - Epoch 5/30 - Train Loss: 1.7383, Train Acc: 28.89% - Val Loss: 1.7506, Val Acc: 0.00%
2025-05-06 11:40:19,686 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:19,686 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:40:19,686 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:40:19,686 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:19,699 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch5.pth
2025-05-06 11:40:19,699 - INFO - Epoche 6: Observer-Learning deaktiviert
2025-05-06 11:40:19,700 - INFO - Epoche 6: Fake-Quantisierung aktiviert
2025-05-06 11:40:19,833 - INFO - Epoch 6/30 - Train Loss: 1.7075, Train Acc: 28.89% - Val Loss: 1.7228, Val Acc: 0.00%
2025-05-06 11:40:19,833 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:19,833 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:40:19,833 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:40:19,833 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:19,839 - INFO - Epoche 7: Observer-Learning deaktiviert
2025-05-06 11:40:19,841 - INFO - Epoche 7: Fake-Quantisierung aktiviert
2025-05-06 11:40:19,980 - INFO - Epoch 7/30 - Train Loss: 1.5990, Train Acc: 40.00% - Val Loss: 1.6921, Val Acc: 0.00%
2025-05-06 11:40:19,981 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:19,981 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:40:19,981 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:40:19,981 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:19,985 - INFO - Epoche 8: Observer-Learning deaktiviert
2025-05-06 11:40:19,986 - INFO - Epoche 8: Fake-Quantisierung aktiviert
2025-05-06 11:40:20,124 - INFO - Epoch 8/30 - Train Loss: 1.5256, Train Acc: 44.44% - Val Loss: 1.6891, Val Acc: 0.00%
2025-05-06 11:40:20,124 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:20,124 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:40:20,124 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:40:20,124 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:20,128 - INFO - Epoche 9: Observer-Learning aktiviert
2025-05-06 11:40:20,129 - INFO - Epoche 9: Fake-Quantisierung aktiviert
2025-05-06 11:40:20,286 - INFO - Epoch 9/30 - Train Loss: 1.5283, Train Acc: 37.78% - Val Loss: 1.6898, Val Acc: 0.00%
2025-05-06 11:40:20,286 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:20,286 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:40:20,286 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:40:20,286 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:20,286 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:40:20,286 - INFO - Epoche 10: Observer-Learning deaktiviert
2025-05-06 11:40:20,287 - INFO - Epoche 10: Fake-Quantisierung aktiviert
2025-05-06 11:40:20,418 - INFO - Epoch 10/30 - Train Loss: 1.4925, Train Acc: 24.44% - Val Loss: 1.6664, Val Acc: 0.00%
2025-05-06 11:40:20,418 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:20,418 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:40:20,418 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:40:20,418 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:20,431 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch10.pth
2025-05-06 11:40:20,431 - INFO - Epoche 11: Observer-Learning deaktiviert
2025-05-06 11:40:20,432 - INFO - Epoche 11: Fake-Quantisierung aktiviert
2025-05-06 11:40:20,569 - INFO - Epoch 11/30 - Train Loss: 1.4478, Train Acc: 28.89% - Val Loss: 1.6476, Val Acc: 0.00%
2025-05-06 11:40:20,569 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:20,569 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:40:20,569 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:40:20,569 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:20,573 - INFO - Epoche 12: Observer-Learning deaktiviert
2025-05-06 11:40:20,574 - INFO - Epoche 12: Fake-Quantisierung aktiviert
2025-05-06 11:40:20,707 - INFO - Epoch 12/30 - Train Loss: 1.3863, Train Acc: 33.33% - Val Loss: 1.6155, Val Acc: 0.00%
2025-05-06 11:40:20,708 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:20,708 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:40:20,708 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:40:20,708 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:20,711 - INFO - Epoche 13: Observer-Learning aktiviert
2025-05-06 11:40:20,712 - INFO - Epoche 13: Fake-Quantisierung aktiviert
2025-05-06 11:40:20,869 - INFO - Epoch 13/30 - Train Loss: 1.3475, Train Acc: 31.11% - Val Loss: 1.5615, Val Acc: 16.67%
2025-05-06 11:40:20,870 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:20,870 - INFO -   basic: 12.50% (1/8)
2025-05-06 11:40:20,870 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:40:20,870 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:20,873 - INFO - Epoche 14: Observer-Learning deaktiviert
2025-05-06 11:40:20,874 - INFO - Epoche 14: Fake-Quantisierung aktiviert
2025-05-06 11:40:21,010 - INFO - Epoch 14/30 - Train Loss: 1.3187, Train Acc: 37.78% - Val Loss: 1.5254, Val Acc: 33.33%
2025-05-06 11:40:21,010 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:21,010 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:40:21,010 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:40:21,010 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:21,028 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch14.pth
2025-05-06 11:40:21,028 - INFO - Epoche 15: Observer-Learning deaktiviert
2025-05-06 11:40:21,029 - INFO - Epoche 15: Fake-Quantisierung aktiviert
2025-05-06 11:40:21,159 - INFO - Epoch 15/30 - Train Loss: 1.3428, Train Acc: 35.56% - Val Loss: 1.5121, Val Acc: 41.67%
2025-05-06 11:40:21,159 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:21,159 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:40:21,159 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:40:21,159 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:21,172 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch15.pth
2025-05-06 11:40:21,172 - INFO - Epoche 16: Observer-Learning deaktiviert
2025-05-06 11:40:21,173 - INFO - Epoche 16: Fake-Quantisierung aktiviert
2025-05-06 11:40:21,303 - INFO - Epoch 16/30 - Train Loss: 1.3239, Train Acc: 35.56% - Val Loss: 1.5191, Val Acc: 33.33%
2025-05-06 11:40:21,303 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:21,303 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:40:21,303 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:40:21,303 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:21,303 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:40:21,303 - INFO - Epoche 17: Observer-Learning aktiviert
2025-05-06 11:40:21,304 - INFO - Epoche 17: Fake-Quantisierung aktiviert
2025-05-06 11:40:21,462 - INFO - Epoch 17/30 - Train Loss: 1.2552, Train Acc: 40.00% - Val Loss: 1.5246, Val Acc: 25.00%
2025-05-06 11:40:21,462 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:21,462 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:40:21,462 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:40:21,462 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:21,462 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:40:21,462 - INFO - Epoche 18: Observer-Learning deaktiviert
2025-05-06 11:40:21,463 - INFO - Epoche 18: Fake-Quantisierung aktiviert
2025-05-06 11:40:21,593 - INFO - Epoch 18/30 - Train Loss: 1.0992, Train Acc: 66.67% - Val Loss: 1.4887, Val Acc: 33.33%
2025-05-06 11:40:21,593 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:21,593 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:40:21,593 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:40:21,593 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:21,598 - INFO - Epoche 19: Observer-Learning deaktiviert
2025-05-06 11:40:21,599 - INFO - Epoche 19: Fake-Quantisierung aktiviert
2025-05-06 11:40:21,733 - INFO - Epoch 19/30 - Train Loss: 1.2271, Train Acc: 40.00% - Val Loss: 1.4846, Val Acc: 33.33%
2025-05-06 11:40:21,734 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:21,734 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:40:21,734 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:40:21,734 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:21,738 - INFO - Epoche 20: Observer-Learning deaktiviert
2025-05-06 11:40:21,739 - INFO - Epoche 20: Fake-Quantisierung aktiviert
2025-05-06 11:40:21,878 - INFO - Epoch 20/30 - Train Loss: 1.1127, Train Acc: 42.22% - Val Loss: 1.4894, Val Acc: 33.33%
2025-05-06 11:40:21,879 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:21,879 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:40:21,879 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:40:21,879 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:21,879 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:40:21,888 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch20.pth
2025-05-06 11:40:21,888 - INFO - Epoche 21: Observer-Learning aktiviert
2025-05-06 11:40:21,889 - INFO - Epoche 21: Fake-Quantisierung aktiviert
2025-05-06 11:40:22,046 - INFO - Epoch 21/30 - Train Loss: 1.1149, Train Acc: 55.56% - Val Loss: 1.5241, Val Acc: 25.00%
2025-05-06 11:40:22,046 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:22,046 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:40:22,046 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:40:22,046 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:22,046 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:40:22,046 - INFO - Epoche 22: Observer-Learning deaktiviert
2025-05-06 11:40:22,047 - INFO - Epoche 22: Fake-Quantisierung aktiviert
2025-05-06 11:40:22,181 - INFO - Epoch 22/30 - Train Loss: 1.0566, Train Acc: 64.44% - Val Loss: 1.5130, Val Acc: 33.33%
2025-05-06 11:40:22,181 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:22,181 - INFO -   basic: 37.50% (3/8)
2025-05-06 11:40:22,181 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:40:22,181 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:22,181 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:40:22,181 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:40:22,181 - INFO - Epoche 23: Observer-Learning deaktiviert
2025-05-06 11:40:22,182 - INFO - Epoche 23: Fake-Quantisierung aktiviert
2025-05-06 11:40:22,313 - INFO - Epoch 23/30 - Train Loss: 1.2249, Train Acc: 46.67% - Val Loss: 1.5555, Val Acc: 25.00%
2025-05-06 11:40:22,314 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:22,314 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:40:22,314 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:40:22,314 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:22,314 - INFO - EarlyStopping counter: 9/10
2025-05-06 11:40:22,314 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:40:22,314 - INFO - Epoche 24: Observer-Learning deaktiviert
2025-05-06 11:40:22,315 - INFO - Epoche 24: Fake-Quantisierung aktiviert
2025-05-06 11:40:22,447 - INFO - Epoch 24/30 - Train Loss: 1.2630, Train Acc: 44.44% - Val Loss: 1.5787, Val Acc: 25.00%
2025-05-06 11:40:22,447 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:40:22,447 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:40:22,447 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:40:22,447 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:40:22,447 - INFO - EarlyStopping counter: 10/10
2025-05-06 11:40:22,447 - INFO - Early Stopping in Epoche 24
2025-05-06 11:40:22,447 - INFO - Training abgeschlossen in 3.91 Sekunden
2025-05-06 11:40:22,454 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 11:40:22,463 - INFO - Modell gespeichert als: models_optimized/qat_pizza_model.pth
2025-05-06 11:40:22,826 - INFO - Trainingshistorie gespeichert unter output/quantization_aware_training/qat_training_history.png
2025-05-06 11:40:22,827 - INFO - Konvertiere QAT-Modell zu quantisiertem Inferenzmodell...
2025-05-06 11:40:22,868 - INFO - Quantisiertes Modell gespeichert als: models_optimized/pizza_model_int8_qat.pth
2025-05-06 11:40:22,869 - INFO - Quantisierte Modellgröße: 126.08 KB
2025-05-06 11:40:22,869 - INFO - Evaluiere quantisiertes Modell...
2025-05-06 11:40:22,926 - WARNING - Fehler bei der Evaluierung des quantisierten Modells: 'FakeQuantize' object has no attribute 'activation_post_process'
2025-05-06 11:40:22,926 - INFO - Fahre mit der Speicherung des Modells fort ohne Evaluierung...
2025-05-06 11:40:22,926 - INFO - Vergleiche Modelle: Standard vs. QAT vs. Quantisiert...
2025-05-06 11:44:08,198 - INFO - Verwende Gerät: cpu
2025-05-06 11:44:08,198 - INFO - ================================================================================
2025-05-06 11:44:08,198 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:44:08,198 - INFO - ================================================================================
2025-05-06 11:44:08,198 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:44:08,198 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:44:08,198 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:44:08,198 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:44:08,198 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:44:08,198 - INFO - ================================================================================
2025-05-06 11:44:08,198 - INFO - Preparing optimized data loaders...
2025-05-06 11:44:08,199 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:44:08,235 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:44:08,235 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:44:08,235 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:44:08,235 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:44:08,235 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:44:08,235 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:44:08,235 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:44:08,236 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:44:08,236 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:44:08,236 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:44:08,266 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:44:08,326 - INFO - Speicheranalyse:
2025-05-06 11:44:08,326 - INFO -   Modellgröße (Float32): 309.99 KB
2025-05-06 11:44:08,326 - INFO -   Modellgröße (Int8): 77.50 KB (3.8% des Flash)
2025-05-06 11:44:08,326 - INFO -   Aktivierungsspeicher: 834.67 KB
2025-05-06 11:44:08,326 - INFO -   Gesamter Laufzeitspeicher: 912.17 KB (345.5% des RAM)
2025-05-06 11:44:08,326 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (912.17KB > 100KB)
2025-05-06 11:44:08,492 - INFO - Klassengewichte für Loss-Funktion: [1.07, 0.62, 0.75, 0.47, 1.0, 1.0]
2025-05-06 11:44:08,493 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:44:08,610 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:08,610 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:08,674 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:08,675 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:08,713 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:08,713 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:08,792 - INFO - Epoch 1/30 - Train Loss: 1.7812, Train Acc: 24.44% - Val Loss: 1.7813, Val Acc: 33.33%
2025-05-06 11:44:08,793 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:08,793 - INFO -   basic: 25.00% (2/8)
2025-05-06 11:44:08,793 - INFO -   combined: 66.67% (2/3)
2025-05-06 11:44:08,793 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:08,806 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch1.pth
2025-05-06 11:44:08,806 - INFO - Epoche 2: Observer-Learning deaktiviert
2025-05-06 11:44:08,848 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:08,848 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:08,874 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:08,874 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:08,898 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:08,898 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:08,976 - INFO - Epoch 2/30 - Train Loss: 1.7784, Train Acc: 20.00% - Val Loss: 1.7708, Val Acc: 66.67%
2025-05-06 11:44:08,976 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:08,976 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:44:08,976 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:08,976 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:08,984 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch2.pth
2025-05-06 11:44:08,984 - INFO - Epoche 3: Observer-Learning deaktiviert
2025-05-06 11:44:08,984 - INFO - Epoche 3: Fake-Quantisierung aktiviert
2025-05-06 11:44:09,026 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:09,026 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,052 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:09,052 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,072 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:09,072 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,137 - INFO - Epoch 3/30 - Train Loss: 1.7630, Train Acc: 40.00% - Val Loss: 1.7611, Val Acc: 66.67%
2025-05-06 11:44:09,137 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:09,137 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:44:09,138 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:09,138 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:09,141 - INFO - Epoche 4: Observer-Learning deaktiviert
2025-05-06 11:44:09,141 - INFO - Epoche 4: Fake-Quantisierung aktiviert
2025-05-06 11:44:09,187 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:09,187 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,242 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:09,242 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,272 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:09,272 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,350 - INFO - Epoch 4/30 - Train Loss: 1.7462, Train Acc: 33.33% - Val Loss: 1.7434, Val Acc: 66.67%
2025-05-06 11:44:09,351 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:09,351 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:44:09,351 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:09,351 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:09,354 - INFO - Epoche 5: Observer-Learning aktiviert
2025-05-06 11:44:09,355 - INFO - Epoche 5: Fake-Quantisierung aktiviert
2025-05-06 11:44:09,403 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:09,403 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,440 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:09,440 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,483 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:09,483 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,566 - INFO - Epoch 5/30 - Train Loss: 1.7022, Train Acc: 42.22% - Val Loss: 1.7179, Val Acc: 50.00%
2025-05-06 11:44:09,566 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:09,567 - INFO -   basic: 75.00% (6/8)
2025-05-06 11:44:09,567 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:09,567 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:09,574 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch5.pth
2025-05-06 11:44:09,574 - INFO - Epoche 6: Observer-Learning deaktiviert
2025-05-06 11:44:09,575 - INFO - Epoche 6: Fake-Quantisierung aktiviert
2025-05-06 11:44:09,626 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:09,626 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,650 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:09,650 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,668 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:09,668 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,735 - INFO - Epoch 6/30 - Train Loss: 1.7064, Train Acc: 31.11% - Val Loss: 1.6928, Val Acc: 50.00%
2025-05-06 11:44:09,736 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:09,736 - INFO -   basic: 75.00% (6/8)
2025-05-06 11:44:09,736 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:09,736 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:09,740 - INFO - Epoche 7: Observer-Learning deaktiviert
2025-05-06 11:44:09,740 - INFO - Epoche 7: Fake-Quantisierung aktiviert
2025-05-06 11:44:09,787 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:09,787 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,815 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:09,815 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,833 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:09,833 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,903 - INFO - Epoch 7/30 - Train Loss: 1.6565, Train Acc: 31.11% - Val Loss: 1.6631, Val Acc: 41.67%
2025-05-06 11:44:09,903 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:09,903 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:44:09,903 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:09,903 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:09,905 - INFO - Epoche 8: Observer-Learning deaktiviert
2025-05-06 11:44:09,906 - INFO - Epoche 8: Fake-Quantisierung aktiviert
2025-05-06 11:44:09,949 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:09,949 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,972 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:09,972 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:09,991 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:09,991 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:10,057 - INFO - Epoch 8/30 - Train Loss: 1.6526, Train Acc: 31.11% - Val Loss: 1.6257, Val Acc: 66.67%
2025-05-06 11:44:10,057 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:10,057 - INFO -   basic: 87.50% (7/8)
2025-05-06 11:44:10,057 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:44:10,057 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:10,059 - INFO - Epoche 9: Observer-Learning aktiviert
2025-05-06 11:44:10,059 - INFO - Epoche 9: Fake-Quantisierung aktiviert
2025-05-06 11:44:10,103 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:10,103 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:10,150 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:10,150 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:10,192 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:10,193 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:10,288 - INFO - Epoch 9/30 - Train Loss: 1.5361, Train Acc: 33.33% - Val Loss: 1.5535, Val Acc: 66.67%
2025-05-06 11:44:10,288 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:10,288 - INFO -   basic: 87.50% (7/8)
2025-05-06 11:44:10,289 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:44:10,289 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:10,291 - INFO - Epoche 10: Observer-Learning deaktiviert
2025-05-06 11:44:10,292 - INFO - Epoche 10: Fake-Quantisierung aktiviert
2025-05-06 11:44:10,334 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:10,334 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:10,363 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:10,363 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:10,393 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:10,393 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:10,467 - INFO - Epoch 10/30 - Train Loss: 1.5279, Train Acc: 40.00% - Val Loss: 1.4691, Val Acc: 66.67%
2025-05-06 11:44:10,467 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:10,467 - INFO -   basic: 87.50% (7/8)
2025-05-06 11:44:10,468 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:44:10,468 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:10,476 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch10.pth
2025-05-06 11:44:10,476 - INFO - Epoche 11: Observer-Learning deaktiviert
2025-05-06 11:44:10,476 - INFO - Epoche 11: Fake-Quantisierung aktiviert
2025-05-06 11:44:10,520 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:10,520 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:10,545 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:10,545 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:10,563 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:10,563 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:10,645 - INFO - Epoch 11/30 - Train Loss: 1.4786, Train Acc: 51.11% - Val Loss: 1.4230, Val Acc: 75.00%
2025-05-06 11:44:10,645 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:10,645 - INFO -   basic: 100.00% (8/8)
2025-05-06 11:44:10,646 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:44:10,646 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:10,664 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch11.pth
2025-05-06 11:44:10,664 - INFO - Epoche 12: Observer-Learning deaktiviert
2025-05-06 11:44:10,665 - INFO - Epoche 12: Fake-Quantisierung aktiviert
2025-05-06 11:44:10,708 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:10,709 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:10,733 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:10,733 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:10,753 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:10,753 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:10,823 - INFO - Epoch 12/30 - Train Loss: 1.4616, Train Acc: 37.78% - Val Loss: 1.3638, Val Acc: 66.67%
2025-05-06 11:44:10,823 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:10,823 - INFO -   basic: 87.50% (7/8)
2025-05-06 11:44:10,823 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:44:10,823 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:10,825 - INFO - Epoche 13: Observer-Learning aktiviert
2025-05-06 11:44:10,826 - INFO - Epoche 13: Fake-Quantisierung aktiviert
2025-05-06 11:44:10,874 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:10,874 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:10,911 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:10,911 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:10,932 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:10,932 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,014 - INFO - Epoch 13/30 - Train Loss: 1.4398, Train Acc: 35.56% - Val Loss: 1.3624, Val Acc: 50.00%
2025-05-06 11:44:11,014 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:11,014 - INFO -   basic: 75.00% (6/8)
2025-05-06 11:44:11,014 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:11,014 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:11,016 - INFO - Epoche 14: Observer-Learning deaktiviert
2025-05-06 11:44:11,016 - INFO - Epoche 14: Fake-Quantisierung aktiviert
2025-05-06 11:44:11,064 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:11,064 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,094 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:11,094 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,121 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:11,122 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,205 - INFO - Epoch 14/30 - Train Loss: 1.4016, Train Acc: 42.22% - Val Loss: 1.3467, Val Acc: 50.00%
2025-05-06 11:44:11,205 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:11,205 - INFO -   basic: 75.00% (6/8)
2025-05-06 11:44:11,205 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:11,205 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:11,207 - INFO - Epoche 15: Observer-Learning deaktiviert
2025-05-06 11:44:11,208 - INFO - Epoche 15: Fake-Quantisierung aktiviert
2025-05-06 11:44:11,259 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:11,259 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,285 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:11,285 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,305 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:11,306 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,378 - INFO - Epoch 15/30 - Train Loss: 1.3806, Train Acc: 37.78% - Val Loss: 1.3807, Val Acc: 33.33%
2025-05-06 11:44:11,378 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:11,378 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:44:11,378 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:11,378 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:11,378 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:44:11,384 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch15.pth
2025-05-06 11:44:11,385 - INFO - Epoche 16: Observer-Learning deaktiviert
2025-05-06 11:44:11,385 - INFO - Epoche 16: Fake-Quantisierung aktiviert
2025-05-06 11:44:11,430 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:11,430 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,456 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:11,456 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,479 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:11,479 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,554 - INFO - Epoch 16/30 - Train Loss: 1.2535, Train Acc: 60.00% - Val Loss: 1.3615, Val Acc: 50.00%
2025-05-06 11:44:11,554 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:11,554 - INFO -   basic: 75.00% (6/8)
2025-05-06 11:44:11,554 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:11,554 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:11,554 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:44:11,554 - INFO - Epoche 17: Observer-Learning aktiviert
2025-05-06 11:44:11,554 - INFO - Epoche 17: Fake-Quantisierung aktiviert
2025-05-06 11:44:11,600 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:11,600 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,634 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:11,635 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,659 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:11,660 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,743 - INFO - Epoch 17/30 - Train Loss: 1.2806, Train Acc: 37.78% - Val Loss: 1.3485, Val Acc: 50.00%
2025-05-06 11:44:11,743 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:11,743 - INFO -   basic: 75.00% (6/8)
2025-05-06 11:44:11,743 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:11,743 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:11,743 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:44:11,743 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:44:11,743 - INFO - Epoche 18: Observer-Learning deaktiviert
2025-05-06 11:44:11,744 - INFO - Epoche 18: Fake-Quantisierung aktiviert
2025-05-06 11:44:11,793 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:11,793 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,818 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:11,818 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,836 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:11,836 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,908 - INFO - Epoch 18/30 - Train Loss: 1.1508, Train Acc: 55.56% - Val Loss: 1.3245, Val Acc: 50.00%
2025-05-06 11:44:11,908 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:11,908 - INFO -   basic: 75.00% (6/8)
2025-05-06 11:44:11,908 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:11,908 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:11,911 - INFO - Epoche 19: Observer-Learning deaktiviert
2025-05-06 11:44:11,911 - INFO - Epoche 19: Fake-Quantisierung aktiviert
2025-05-06 11:44:11,957 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:11,957 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:11,999 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:12,000 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:12,028 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:12,028 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:12,106 - INFO - Epoch 19/30 - Train Loss: 1.2136, Train Acc: 42.22% - Val Loss: 1.2770, Val Acc: 58.33%
2025-05-06 11:44:12,106 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:12,106 - INFO -   basic: 87.50% (7/8)
2025-05-06 11:44:12,106 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:12,106 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:12,110 - INFO - Epoche 20: Observer-Learning deaktiviert
2025-05-06 11:44:12,110 - INFO - Epoche 20: Fake-Quantisierung aktiviert
2025-05-06 11:44:12,159 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:12,159 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:12,186 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:12,186 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:12,206 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:12,206 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:12,282 - INFO - Epoch 20/30 - Train Loss: 1.0985, Train Acc: 48.89% - Val Loss: 1.2367, Val Acc: 58.33%
2025-05-06 11:44:12,282 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:12,282 - INFO -   basic: 87.50% (7/8)
2025-05-06 11:44:12,283 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:12,283 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:12,290 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch20.pth
2025-05-06 11:44:12,291 - INFO - Epoche 21: Observer-Learning aktiviert
2025-05-06 11:44:12,291 - INFO - Epoche 21: Fake-Quantisierung aktiviert
2025-05-06 11:44:12,335 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:12,335 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:12,387 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:12,388 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:12,431 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:12,431 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:12,531 - INFO - Epoch 21/30 - Train Loss: 1.1438, Train Acc: 51.11% - Val Loss: 1.2264, Val Acc: 58.33%
2025-05-06 11:44:12,531 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:12,531 - INFO -   basic: 87.50% (7/8)
2025-05-06 11:44:12,531 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:12,531 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:12,534 - INFO - Epoche 22: Observer-Learning deaktiviert
2025-05-06 11:44:12,535 - INFO - Epoche 22: Fake-Quantisierung aktiviert
2025-05-06 11:44:12,586 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:12,586 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:12,614 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:12,614 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:12,633 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:12,633 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:12,701 - INFO - Epoch 22/30 - Train Loss: 1.2954, Train Acc: 44.44% - Val Loss: 1.3021, Val Acc: 33.33%
2025-05-06 11:44:12,702 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:12,702 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:44:12,702 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:12,702 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:12,702 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:44:12,702 - INFO - Epoche 23: Observer-Learning deaktiviert
2025-05-06 11:44:12,702 - INFO - Epoche 23: Fake-Quantisierung aktiviert
2025-05-06 11:44:12,746 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:12,746 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:12,771 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:12,771 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:12,788 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:12,788 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:12,857 - INFO - Epoch 23/30 - Train Loss: 1.1655, Train Acc: 46.67% - Val Loss: 1.3005, Val Acc: 41.67%
2025-05-06 11:44:12,858 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:12,858 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:44:12,858 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:44:12,858 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:12,858 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:44:12,858 - INFO - Epoche 24: Observer-Learning deaktiviert
2025-05-06 11:44:12,858 - INFO - Epoche 24: Fake-Quantisierung aktiviert
2025-05-06 11:44:12,900 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:12,900 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:12,925 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:12,925 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:12,949 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:12,949 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:13,025 - INFO - Epoch 24/30 - Train Loss: 1.1986, Train Acc: 51.11% - Val Loss: 1.3228, Val Acc: 41.67%
2025-05-06 11:44:13,025 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:13,025 - INFO -   basic: 50.00% (4/8)
2025-05-06 11:44:13,025 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:44:13,025 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:13,025 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:44:13,025 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:44:13,025 - INFO - Epoche 25: Observer-Learning aktiviert
2025-05-06 11:44:13,026 - INFO - Epoche 25: Fake-Quantisierung aktiviert
2025-05-06 11:44:13,077 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:13,078 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:13,131 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:13,131 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:13,174 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:13,174 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:13,258 - INFO - Epoch 25/30 - Train Loss: 1.2123, Train Acc: 51.11% - Val Loss: 1.2999, Val Acc: 50.00%
2025-05-06 11:44:13,258 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:13,258 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:44:13,258 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:44:13,258 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:13,258 - INFO - EarlyStopping counter: 9/10
2025-05-06 11:44:13,266 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch25.pth
2025-05-06 11:44:13,266 - INFO - Epoche 26: Observer-Learning deaktiviert
2025-05-06 11:44:13,267 - INFO - Epoche 26: Fake-Quantisierung aktiviert
2025-05-06 11:44:13,311 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:44:13,311 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:13,342 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:13,342 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:13,374 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:44:13,374 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:44:13,460 - INFO - Epoch 26/30 - Train Loss: 1.1887, Train Acc: 48.89% - Val Loss: 1.2755, Val Acc: 41.67%
2025-05-06 11:44:13,460 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:44:13,460 - INFO -   basic: 62.50% (5/8)
2025-05-06 11:44:13,460 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:44:13,460 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:44:13,460 - INFO - EarlyStopping counter: 10/10
2025-05-06 11:44:13,460 - INFO - Early Stopping in Epoche 26
2025-05-06 11:44:13,460 - INFO - Training abgeschlossen in 4.97 Sekunden
2025-05-06 11:44:13,464 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 11:44:13,483 - INFO - Modell gespeichert als: models_optimized/qat_pizza_model.pth
2025-05-06 11:44:13,800 - INFO - Trainingshistorie gespeichert unter output/quantization_aware_training/qat_training_history.png
2025-05-06 11:44:13,801 - INFO - Konvertiere QAT-Modell zu quantisiertem Inferenzmodell...
2025-05-06 11:44:13,827 - INFO - Quantisiertes Modell gespeichert als: models_optimized/pizza_model_int8_qat.pth
2025-05-06 11:44:13,827 - INFO - Quantisierte Modellgröße: 126.08 KB
2025-05-06 11:44:13,827 - INFO - Evaluiere quantisiertes Modell...
2025-05-06 11:44:13,869 - WARNING - Fehler bei der Evaluierung des quantisierten Modells: 'FakeQuantize' object has no attribute 'activation_post_process'
2025-05-06 11:44:13,869 - INFO - Fahre mit der Speicherung des Modells fort ohne Evaluierung...
2025-05-06 11:44:13,869 - INFO - Vergleiche Modelle: Standard vs. QAT vs. Quantisiert...
2025-05-06 11:46:04,363 - INFO - Verwende Gerät: cpu
2025-05-06 11:46:04,363 - INFO - ================================================================================
2025-05-06 11:46:04,363 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 11:46:04,363 - INFO - ================================================================================
2025-05-06 11:46:04,363 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 11:46:04,363 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 11:46:04,363 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 11:46:04,363 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 11:46:04,363 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 11:46:04,363 - INFO - ================================================================================
2025-05-06 11:46:04,364 - INFO - Preparing optimized data loaders...
2025-05-06 11:46:04,364 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 11:46:04,403 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 11:46:04,403 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 11:46:04,403 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 11:46:04,403 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 11:46:04,403 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 11:46:04,403 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 11:46:04,403 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 11:46:04,404 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 11:46:04,404 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:46:04,404 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 11:46:04,435 - INFO - Starte Quantization-Aware Training für qat_pizza_model...
2025-05-06 11:46:04,450 - INFO - Speicheranalyse:
2025-05-06 11:46:04,450 - INFO -   Modellgröße (Float32): 309.99 KB
2025-05-06 11:46:04,450 - INFO -   Modellgröße (Int8): 77.50 KB (3.8% des Flash)
2025-05-06 11:46:04,450 - INFO -   Aktivierungsspeicher: 834.67 KB
2025-05-06 11:46:04,450 - INFO -   Gesamter Laufzeitspeicher: 912.17 KB (345.5% des RAM)
2025-05-06 11:46:04,451 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (912.17KB > 100KB)
2025-05-06 11:46:04,619 - INFO - Klassengewichte für Loss-Funktion: [0.62, 0.83, 0.44, 1.07, 1.0, 1.0]
2025-05-06 11:46:04,620 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 11:46:04,703 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:04,704 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:04,746 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:04,746 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:04,790 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:04,790 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:04,892 - INFO - Epoch 1/30 - Train Loss: 1.7929, Train Acc: 22.22% - Val Loss: 1.8135, Val Acc: 0.00%
2025-05-06 11:46:04,892 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:04,892 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:04,893 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:04,893 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:04,894 - INFO - Epoche 2: Observer-Learning deaktiviert
2025-05-06 11:46:04,942 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:04,942 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:04,968 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:04,968 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:04,997 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:04,997 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:05,078 - INFO - Epoch 2/30 - Train Loss: 1.8123, Train Acc: 15.56% - Val Loss: 1.8266, Val Acc: 0.00%
2025-05-06 11:46:05,078 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:05,078 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:05,078 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:05,078 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:05,078 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:46:05,078 - INFO - Epoche 3: Observer-Learning deaktiviert
2025-05-06 11:46:05,079 - INFO - Epoche 3: Fake-Quantisierung aktiviert
2025-05-06 11:46:05,125 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:05,125 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:05,152 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:05,152 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:05,181 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:05,182 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:05,275 - INFO - Epoch 3/30 - Train Loss: 1.7928, Train Acc: 20.00% - Val Loss: 1.8305, Val Acc: 0.00%
2025-05-06 11:46:05,275 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:05,275 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:05,275 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:05,275 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:05,275 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:46:05,275 - INFO - Epoche 4: Observer-Learning deaktiviert
2025-05-06 11:46:05,276 - INFO - Epoche 4: Fake-Quantisierung aktiviert
2025-05-06 11:46:05,320 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:05,320 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:05,353 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:05,353 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:05,384 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:05,384 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:05,464 - INFO - Epoch 4/30 - Train Loss: 1.7665, Train Acc: 37.78% - Val Loss: 1.8274, Val Acc: 0.00%
2025-05-06 11:46:05,464 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:05,465 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:05,465 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:05,465 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:05,465 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:46:05,465 - INFO - Epoche 5: Observer-Learning aktiviert
2025-05-06 11:46:05,466 - INFO - Epoche 5: Fake-Quantisierung aktiviert
2025-05-06 11:46:05,514 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:05,514 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:05,563 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:05,563 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:05,608 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:05,609 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:05,708 - INFO - Epoch 5/30 - Train Loss: 1.7362, Train Acc: 35.56% - Val Loss: 1.8232, Val Acc: 0.00%
2025-05-06 11:46:05,708 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:05,708 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:05,708 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:05,708 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:05,708 - INFO - EarlyStopping counter: 4/10
2025-05-06 11:46:05,714 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch5.pth
2025-05-06 11:46:05,714 - INFO - Epoche 6: Observer-Learning deaktiviert
2025-05-06 11:46:05,715 - INFO - Epoche 6: Fake-Quantisierung aktiviert
2025-05-06 11:46:05,759 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:05,759 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:05,785 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:05,785 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:05,814 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:05,814 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:05,901 - INFO - Epoch 6/30 - Train Loss: 1.6912, Train Acc: 35.56% - Val Loss: 1.8062, Val Acc: 0.00%
2025-05-06 11:46:05,901 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:05,901 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:05,901 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:05,901 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:05,905 - INFO - Epoche 7: Observer-Learning deaktiviert
2025-05-06 11:46:05,906 - INFO - Epoche 7: Fake-Quantisierung aktiviert
2025-05-06 11:46:05,954 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:05,954 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:05,981 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:05,981 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:06,016 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:06,016 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:06,097 - INFO - Epoch 7/30 - Train Loss: 1.6843, Train Acc: 28.89% - Val Loss: 1.7899, Val Acc: 0.00%
2025-05-06 11:46:06,097 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:06,097 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:06,097 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:06,097 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:06,101 - INFO - Epoche 8: Observer-Learning deaktiviert
2025-05-06 11:46:06,102 - INFO - Epoche 8: Fake-Quantisierung aktiviert
2025-05-06 11:46:06,150 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:06,150 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:06,190 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:06,190 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:06,221 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:06,221 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:06,313 - INFO - Epoch 8/30 - Train Loss: 1.6362, Train Acc: 33.33% - Val Loss: 1.7689, Val Acc: 0.00%
2025-05-06 11:46:06,313 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:06,313 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:06,313 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:06,313 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:06,316 - INFO - Epoche 9: Observer-Learning aktiviert
2025-05-06 11:46:06,316 - INFO - Epoche 9: Fake-Quantisierung aktiviert
2025-05-06 11:46:06,362 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:06,362 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:06,412 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:06,412 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:06,458 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:06,458 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:06,563 - INFO - Epoch 9/30 - Train Loss: 1.5450, Train Acc: 31.11% - Val Loss: 1.7397, Val Acc: 0.00%
2025-05-06 11:46:06,563 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:06,563 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:06,563 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:06,563 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:06,565 - INFO - Epoche 10: Observer-Learning deaktiviert
2025-05-06 11:46:06,565 - INFO - Epoche 10: Fake-Quantisierung aktiviert
2025-05-06 11:46:06,613 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:06,613 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:06,655 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:06,656 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:06,676 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:06,676 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:06,752 - INFO - Epoch 10/30 - Train Loss: 1.5005, Train Acc: 37.78% - Val Loss: 1.7222, Val Acc: 0.00%
2025-05-06 11:46:06,752 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:06,752 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:06,752 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:06,752 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:06,762 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch10.pth
2025-05-06 11:46:06,762 - INFO - Epoche 11: Observer-Learning deaktiviert
2025-05-06 11:46:06,762 - INFO - Epoche 11: Fake-Quantisierung aktiviert
2025-05-06 11:46:06,810 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:06,811 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:06,840 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:06,840 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:06,862 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:06,862 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:06,935 - INFO - Epoch 11/30 - Train Loss: 1.4609, Train Acc: 40.00% - Val Loss: 1.7168, Val Acc: 0.00%
2025-05-06 11:46:06,935 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:06,935 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:06,935 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:06,935 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:06,938 - INFO - Epoche 12: Observer-Learning deaktiviert
2025-05-06 11:46:06,939 - INFO - Epoche 12: Fake-Quantisierung aktiviert
2025-05-06 11:46:06,986 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:06,986 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,011 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:07,012 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,034 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:07,034 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,106 - INFO - Epoch 12/30 - Train Loss: 1.4690, Train Acc: 46.67% - Val Loss: 1.7199, Val Acc: 0.00%
2025-05-06 11:46:07,107 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:07,107 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:07,107 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:07,107 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:07,107 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:46:07,107 - INFO - Epoche 13: Observer-Learning aktiviert
2025-05-06 11:46:07,107 - INFO - Epoche 13: Fake-Quantisierung aktiviert
2025-05-06 11:46:07,163 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:07,163 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,203 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:07,203 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,229 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:07,230 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,315 - INFO - Epoch 13/30 - Train Loss: 1.4298, Train Acc: 42.22% - Val Loss: 1.7089, Val Acc: 8.33%
2025-05-06 11:46:07,315 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:07,315 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:07,315 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:07,315 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:46:07,326 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch13.pth
2025-05-06 11:46:07,326 - INFO - Epoche 14: Observer-Learning deaktiviert
2025-05-06 11:46:07,326 - INFO - Epoche 14: Fake-Quantisierung aktiviert
2025-05-06 11:46:07,372 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:07,372 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,408 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:07,408 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,439 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:07,439 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,524 - INFO - Epoch 14/30 - Train Loss: 1.3289, Train Acc: 57.78% - Val Loss: 1.6855, Val Acc: 8.33%
2025-05-06 11:46:07,524 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:07,524 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:07,524 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:07,525 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:46:07,528 - INFO - Epoche 15: Observer-Learning deaktiviert
2025-05-06 11:46:07,529 - INFO - Epoche 15: Fake-Quantisierung aktiviert
2025-05-06 11:46:07,578 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:07,578 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,609 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:07,609 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,629 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:07,629 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,708 - INFO - Epoch 15/30 - Train Loss: 1.2741, Train Acc: 53.33% - Val Loss: 1.6871, Val Acc: 8.33%
2025-05-06 11:46:07,708 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:07,708 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:07,708 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:07,708 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:46:07,708 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:46:07,714 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch15.pth
2025-05-06 11:46:07,714 - INFO - Epoche 16: Observer-Learning deaktiviert
2025-05-06 11:46:07,714 - INFO - Epoche 16: Fake-Quantisierung aktiviert
2025-05-06 11:46:07,759 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:07,759 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,785 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:07,785 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,809 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:07,810 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,890 - INFO - Epoch 16/30 - Train Loss: 1.2715, Train Acc: 46.67% - Val Loss: 1.6919, Val Acc: 8.33%
2025-05-06 11:46:07,891 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:07,891 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:07,891 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:07,891 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:46:07,891 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:46:07,891 - INFO - Epoche 17: Observer-Learning aktiviert
2025-05-06 11:46:07,892 - INFO - Epoche 17: Fake-Quantisierung aktiviert
2025-05-06 11:46:07,939 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:07,939 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,969 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:07,969 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:07,994 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:07,994 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:08,074 - INFO - Epoch 17/30 - Train Loss: 1.2823, Train Acc: 42.22% - Val Loss: 1.6913, Val Acc: 8.33%
2025-05-06 11:46:08,074 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:08,074 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:08,074 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:08,074 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:46:08,074 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:46:08,074 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:46:08,074 - INFO - Epoche 18: Observer-Learning deaktiviert
2025-05-06 11:46:08,075 - INFO - Epoche 18: Fake-Quantisierung aktiviert
2025-05-06 11:46:08,118 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:08,119 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:08,165 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:08,166 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:08,197 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:08,197 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:08,273 - INFO - Epoch 18/30 - Train Loss: 1.3616, Train Acc: 31.11% - Val Loss: 1.6782, Val Acc: 8.33%
2025-05-06 11:46:08,273 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:08,274 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:08,274 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:08,274 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:46:08,277 - INFO - Epoche 19: Observer-Learning deaktiviert
2025-05-06 11:46:08,278 - INFO - Epoche 19: Fake-Quantisierung aktiviert
2025-05-06 11:46:08,328 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:08,328 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:08,368 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:08,368 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:08,400 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:08,400 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:08,484 - INFO - Epoch 19/30 - Train Loss: 1.3015, Train Acc: 42.22% - Val Loss: 1.6142, Val Acc: 8.33%
2025-05-06 11:46:08,484 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:08,484 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:08,485 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:08,485 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:46:08,488 - INFO - Epoche 20: Observer-Learning deaktiviert
2025-05-06 11:46:08,489 - INFO - Epoche 20: Fake-Quantisierung aktiviert
2025-05-06 11:46:08,540 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:08,540 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:08,566 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:08,566 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:08,586 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:08,586 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:08,652 - INFO - Epoch 20/30 - Train Loss: 1.2165, Train Acc: 44.44% - Val Loss: 1.6447, Val Acc: 0.00%
2025-05-06 11:46:08,652 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:08,652 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:08,652 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:08,652 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:08,652 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:46:08,658 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch20.pth
2025-05-06 11:46:08,658 - INFO - Epoche 21: Observer-Learning aktiviert
2025-05-06 11:46:08,659 - INFO - Epoche 21: Fake-Quantisierung aktiviert
2025-05-06 11:46:08,704 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:08,704 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:08,751 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:08,751 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:08,798 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:08,798 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:08,890 - INFO - Epoch 21/30 - Train Loss: 1.1430, Train Acc: 51.11% - Val Loss: 1.6115, Val Acc: 8.33%
2025-05-06 11:46:08,891 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:08,891 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:08,891 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:46:08,891 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:08,893 - INFO - Epoche 22: Observer-Learning deaktiviert
2025-05-06 11:46:08,893 - INFO - Epoche 22: Fake-Quantisierung aktiviert
2025-05-06 11:46:08,947 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:08,947 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:08,977 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:08,978 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:08,998 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:08,998 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:09,078 - INFO - Epoch 22/30 - Train Loss: 1.2464, Train Acc: 46.67% - Val Loss: 1.5945, Val Acc: 8.33%
2025-05-06 11:46:09,078 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:09,078 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:09,078 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:09,079 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:46:09,081 - INFO - Epoche 23: Observer-Learning deaktiviert
2025-05-06 11:46:09,082 - INFO - Epoche 23: Fake-Quantisierung aktiviert
2025-05-06 11:46:09,135 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:09,136 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:09,191 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:09,191 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:09,223 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:09,223 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:09,305 - INFO - Epoch 23/30 - Train Loss: 1.1976, Train Acc: 48.89% - Val Loss: 1.6089, Val Acc: 0.00%
2025-05-06 11:46:09,305 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:09,305 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:09,305 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:09,305 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:09,305 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:46:09,305 - INFO - Epoche 24: Observer-Learning deaktiviert
2025-05-06 11:46:09,306 - INFO - Epoche 24: Fake-Quantisierung aktiviert
2025-05-06 11:46:09,354 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:09,354 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:09,389 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:09,389 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:09,420 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:09,420 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:09,503 - INFO - Epoch 24/30 - Train Loss: 1.2242, Train Acc: 46.67% - Val Loss: 1.5897, Val Acc: 8.33%
2025-05-06 11:46:09,503 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:09,503 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:09,503 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:09,503 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:46:09,507 - INFO - Epoche 25: Observer-Learning aktiviert
2025-05-06 11:46:09,508 - INFO - Epoche 25: Fake-Quantisierung aktiviert
2025-05-06 11:46:09,560 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:09,560 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:09,595 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:09,595 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:09,643 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:09,644 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:09,747 - INFO - Epoch 25/30 - Train Loss: 1.1557, Train Acc: 44.44% - Val Loss: 1.5997, Val Acc: 8.33%
2025-05-06 11:46:09,747 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:09,748 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:09,748 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:46:09,748 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:09,748 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:46:09,755 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch25.pth
2025-05-06 11:46:09,755 - INFO - Epoche 26: Observer-Learning deaktiviert
2025-05-06 11:46:09,755 - INFO - Epoche 26: Fake-Quantisierung aktiviert
2025-05-06 11:46:09,801 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:09,801 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:09,837 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:09,837 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:09,867 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:09,867 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:09,946 - INFO - Epoch 26/30 - Train Loss: 1.1924, Train Acc: 48.89% - Val Loss: 1.5863, Val Acc: 16.67%
2025-05-06 11:46:09,946 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:09,946 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:09,946 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:46:09,946 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:46:09,954 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch26.pth
2025-05-06 11:46:09,954 - INFO - Epoche 27: Observer-Learning deaktiviert
2025-05-06 11:46:09,955 - INFO - Epoche 27: Fake-Quantisierung aktiviert
2025-05-06 11:46:10,007 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:10,008 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:10,040 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:10,040 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:10,061 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:10,061 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:10,138 - INFO - Epoch 27/30 - Train Loss: 1.1843, Train Acc: 44.44% - Val Loss: 1.6083, Val Acc: 8.33%
2025-05-06 11:46:10,138 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:10,138 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:10,138 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:46:10,138 - INFO -   mixed: 0.00% (0/1)
2025-05-06 11:46:10,138 - INFO - EarlyStopping counter: 1/10
2025-05-06 11:46:10,138 - INFO - Epoche 28: Observer-Learning deaktiviert
2025-05-06 11:46:10,139 - INFO - Epoche 28: Fake-Quantisierung aktiviert
2025-05-06 11:46:10,183 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:10,183 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:10,212 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:10,213 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:10,244 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:10,244 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:10,324 - INFO - Epoch 28/30 - Train Loss: 1.1379, Train Acc: 48.89% - Val Loss: 1.5970, Val Acc: 8.33%
2025-05-06 11:46:10,324 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:10,324 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:10,324 - INFO -   combined: 0.00% (0/3)
2025-05-06 11:46:10,325 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:46:10,325 - INFO - EarlyStopping counter: 2/10
2025-05-06 11:46:10,325 - INFO - Epoche 29: Observer-Learning aktiviert
2025-05-06 11:46:10,325 - INFO - Epoche 29: Fake-Quantisierung aktiviert
2025-05-06 11:46:10,373 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:10,374 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:10,408 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:10,408 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:10,436 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:10,436 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:10,515 - INFO - Epoch 29/30 - Train Loss: 1.0994, Train Acc: 62.22% - Val Loss: 1.5914, Val Acc: 16.67%
2025-05-06 11:46:10,515 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:10,515 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:10,515 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:46:10,515 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:46:10,515 - INFO - EarlyStopping counter: 3/10
2025-05-06 11:46:10,515 - INFO - Plateau oder steigender Validierungsverlust erkannt
2025-05-06 11:46:10,515 - INFO - Epoche 30: Observer-Learning deaktiviert
2025-05-06 11:46:10,516 - INFO - Epoche 30: Fake-Quantisierung aktiviert
2025-05-06 11:46:10,562 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument scale in method wrapper_CUDA___fake_quantize_per_tensor_affine_cachemask_tensor_qparams)
2025-05-06 11:46:10,562 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:10,613 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:10,613 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:10,645 - ERROR - Geräte-Fehler: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)
2025-05-06 11:46:10,645 - INFO - Versuche alle Tensor auf CPU zu verschieben und fortfahren...
2025-05-06 11:46:10,727 - INFO - Epoch 30/30 - Train Loss: 1.1912, Train Acc: 51.11% - Val Loss: 1.5968, Val Acc: 16.67%
2025-05-06 11:46:10,727 - INFO - Klassenweise Genauigkeiten:
2025-05-06 11:46:10,727 - INFO -   basic: 0.00% (0/8)
2025-05-06 11:46:10,727 - INFO -   combined: 33.33% (1/3)
2025-05-06 11:46:10,727 - INFO -   mixed: 100.00% (1/1)
2025-05-06 11:46:10,727 - INFO - EarlyStopping counter: 9/10
2025-05-06 11:46:10,735 - INFO - Checkpoint gespeichert: models_optimized/qat_pizza_model_epoch30.pth
2025-05-06 11:46:10,735 - INFO - Training abgeschlossen in 6.12 Sekunden
2025-05-06 11:46:10,738 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 11:46:10,752 - INFO - Modell gespeichert als: models_optimized/qat_pizza_model.pth
2025-05-06 11:46:11,085 - INFO - Trainingshistorie gespeichert unter output/quantization_aware_training/qat_training_history.png
2025-05-06 11:46:11,085 - INFO - Konvertiere QAT-Modell zu quantisiertem Inferenzmodell...
2025-05-06 11:46:11,107 - INFO - Quantisiertes Modell gespeichert als: models_optimized/pizza_model_int8_qat.pth
2025-05-06 11:46:11,108 - INFO - Quantisierte Modellgröße: 126.08 KB
2025-05-06 11:46:11,108 - INFO - Evaluiere quantisiertes Modell...
2025-05-06 11:46:11,154 - WARNING - Fehler bei der Evaluierung des quantisierten Modells: 'FakeQuantize' object has no attribute 'activation_post_process'
2025-05-06 11:46:11,154 - INFO - Fahre mit der Speicherung des Modells fort ohne Evaluierung...
2025-05-06 11:46:11,154 - INFO - Vergleiche Modelle: Standard vs. QAT vs. Quantisiert...
2025-05-06 11:46:11,210 - ERROR - Fehler bei der Auswertung des quantisierten Modells: 'FakeQuantize' object has no attribute 'activation_post_process'
2025-05-06 11:46:11,211 - INFO - Setze Nullwerte für das quantisierte Modell ein
2025-05-06 11:46:11,226 - INFO - 
============================================================
2025-05-06 11:46:11,226 - INFO - MODELLVERGLEICH: STANDARD vs. QAT vs. QUANTISIERT
2025-05-06 11:46:11,226 - INFO - ============================================================
2025-05-06 11:46:11,226 - INFO - STANDARD Modell:
2025-05-06 11:46:11,226 - INFO -   - Genauigkeit: 0.00%
2025-05-06 11:46:11,226 - INFO -   - Inferenzzeit: 3.86 ms
2025-05-06 11:46:11,226 - INFO - 
QAT Modell:
2025-05-06 11:46:11,226 - INFO -   - Genauigkeit: 16.67%
2025-05-06 11:46:11,226 - INFO -   - Inferenzzeit: 16.60 ms
2025-05-06 11:46:11,226 - INFO - 
QUANTISIERTES Modell:
2025-05-06 11:46:11,226 - INFO -   - Genauigkeit: 0.00%
2025-05-06 11:46:11,226 - INFO -   - Inferenzzeit: 0.00 ms
2025-05-06 11:46:11,226 - WARNING - Das quantisierte Modell konnte nicht korrekt evaluiert werden.
2025-05-06 11:46:11,226 - WARNING - Möglicherweise gibt es ein Problem mit der Konvertierung.
2025-05-06 11:46:11,226 - INFO - 
VERBESSERUNG (Quantisiert vs. Standard):
2025-05-06 11:46:11,226 - INFO -   - Genauigkeitsänderung: 0.00%
2025-05-06 11:46:11,227 - INFO -   - Beschleunigung: 0.00x
2025-05-06 11:46:11,227 - INFO - ============================================================
2025-05-06 11:46:11,227 - INFO - Vergleichsbericht gespeichert unter output/quantization_aware_training/model_comparison.json
2025-05-06 11:46:11,585 - INFO - Vergleichsvisualisierung gespeichert unter output/quantization_aware_training/model_comparison.png
2025-05-06 11:46:11,585 - INFO - 
==================================================
2025-05-06 11:46:11,585 - INFO - QUANTIZATION-AWARE TRAINING ABGESCHLOSSEN
2025-05-06 11:46:11,585 - INFO - ==================================================
2025-05-06 11:46:11,585 - INFO - Standard-Modell Pfad: models/micro_pizza_model.pth
2025-05-06 11:46:11,585 - INFO - QAT-Modell Pfad: models_optimized/qat_pizza_model.pth
2025-05-06 11:46:11,585 - INFO - Quantisiertes Modell Pfad: models_optimized/pizza_model_int8_qat.pth
2025-05-06 11:46:11,585 - INFO - Quantisierte Modellgröße: 126.08 KB
2025-05-06 11:46:11,585 - INFO - Quantisiertes Modell Genauigkeit: 0.00%
2025-05-06 11:46:11,585 - INFO - Modell und Berichte gespeichert unter: output/quantization_aware_training
2025-05-06 12:00:41,715 - INFO - Verwende Gerät: cpu
2025-05-06 12:00:41,715 - INFO - Lade vortrainiertes Modell von: models/micro_pizza_model.pth
2025-05-06 12:02:41,443 - INFO - Verwende Gerät: cpu
2025-05-06 12:02:41,443 - INFO - Anzahl Klassen: 6
2025-05-06 12:02:41,443 - INFO - Lade vortrainiertes Modell von: models/micro_pizza_model.pth
2025-05-06 12:02:41,445 - INFO - Preparing optimized data loaders...
2025-05-06 12:02:41,445 - INFO - Analysiere Datensatz in data...
2025-05-06 12:02:45,717 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 12:02:45,717 - INFO - Gesamtzahl der Bilder: 1377
2025-05-06 12:02:45,717 - INFO - Klassenverteilung: {'videos': 0, 'synthetic': 1223, 'augmented': 142, 'raw': 12, 'classified': 0, 'processed': 0}
2025-05-06 12:02:45,717 - INFO - Durchschnittliche Bildgröße: 288.5 x 282.5
2025-05-06 12:02:45,717 - INFO - RGB-Mittelwerte: [0.2891, 0.2389, 0.2074]
2025-05-06 12:02:45,718 - INFO - RGB-Standardabweichungen: [0.2989, 0.2844, 0.2719]
2025-05-06 12:02:45,722 - INFO - Using dataset-specific normalization: mean=[0.289, 0.239, 0.207], std=[0.299, 0.284, 0.272]
2025-05-06 12:02:45,724 - INFO - Data loaders created: 1101 training images, 276 validation images
2025-05-06 12:02:45,724 - INFO - Classes: ['augmented', 'classified', 'processed', 'raw', 'synthetic', 'videos']
2025-05-06 12:02:45,724 - INFO - Evaluiere Basis-Modell vor Optimierung
2025-05-06 12:02:46,437 - INFO - Modell-Evaluation abgeschlossen:
2025-05-06 12:02:46,437 - INFO -   Genauigkeit: 0.00%
2025-05-06 12:02:46,437 - INFO -   Durchschnittliche Inferenzzeit: 0.75 ms
2025-05-06 12:02:46,437 - INFO -   Klasse augmented: 0.00% (0/29)
2025-05-06 12:02:46,437 - INFO -   Klasse raw: 0.00% (0/3)
2025-05-06 12:02:46,437 - INFO -   Klasse synthetic: 0.00% (0/244)
2025-05-06 12:02:46,438 - INFO - Starte Pruning mit Prune-Ratio=0.3, Structured-Ratio=0.2
2025-05-06 12:02:46,438 - INFO - Starte unstrukturiertes Pruning mit Ratio 0.3...
2025-05-06 12:02:46,446 - INFO -   Layer block1.0: 65/216 Parameter entfernt (30.09%)
2025-05-06 12:02:46,447 - INFO -   Layer block2.0: 11/72 Parameter entfernt (15.28%)
2025-05-06 12:02:46,447 - INFO -   Layer block2.3: 39/128 Parameter entfernt (30.47%)
2025-05-06 12:02:46,447 - INFO -   Layer classifier.2: 29/96 Parameter entfernt (30.21%)
2025-05-06 12:02:46,448 - INFO - Unstrukturiertes Pruning abgeschlossen. Entfernt: 144 Parameter (24.74%)
2025-05-06 12:02:46,448 - INFO - Starte strukturelles Pruning mit Ratio 0.2...
2025-05-06 12:02:46,450 - INFO -   Layer block1.0: 1/8 Kanäle für Pruning ausgewählt
2025-05-06 12:02:46,450 - INFO -   Layer block2.3: 3/16 Kanäle für Pruning ausgewählt
2025-05-06 12:05:48,801 - INFO - Verwende Gerät: cpu
2025-05-06 12:05:48,801 - INFO - Anzahl Klassen: 6
2025-05-06 12:05:48,801 - INFO - Lade vortrainiertes Modell von: models/micro_pizza_model.pth
2025-05-06 12:05:48,803 - INFO - Preparing optimized data loaders...
2025-05-06 12:05:48,803 - INFO - Analysiere Datensatz in data...
2025-05-06 12:05:52,879 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 12:05:52,879 - INFO - Gesamtzahl der Bilder: 1377
2025-05-06 12:05:52,879 - INFO - Klassenverteilung: {'videos': 0, 'synthetic': 1223, 'augmented': 142, 'raw': 12, 'classified': 0, 'processed': 0}
2025-05-06 12:05:52,879 - INFO - Durchschnittliche Bildgröße: 288.5 x 282.5
2025-05-06 12:05:52,879 - INFO - RGB-Mittelwerte: [0.2891, 0.2389, 0.2074]
2025-05-06 12:05:52,879 - INFO - RGB-Standardabweichungen: [0.2989, 0.2844, 0.2719]
2025-05-06 12:05:52,885 - INFO - Using dataset-specific normalization: mean=[0.289, 0.239, 0.207], std=[0.299, 0.284, 0.272]
2025-05-06 12:05:52,887 - INFO - Data loaders created: 1101 training images, 276 validation images
2025-05-06 12:05:52,887 - INFO - Classes: ['augmented', 'classified', 'processed', 'raw', 'synthetic', 'videos']
2025-05-06 12:05:52,887 - INFO - Evaluiere Basis-Modell vor Optimierung
2025-05-06 12:05:53,598 - INFO - Modell-Evaluation abgeschlossen:
2025-05-06 12:05:53,598 - INFO -   Genauigkeit: 0.00%
2025-05-06 12:05:53,598 - INFO -   Durchschnittliche Inferenzzeit: 0.74 ms
2025-05-06 12:05:53,598 - INFO -   Klasse augmented: 0.00% (0/29)
2025-05-06 12:05:53,598 - INFO -   Klasse raw: 0.00% (0/3)
2025-05-06 12:05:53,598 - INFO -   Klasse synthetic: 0.00% (0/244)
2025-05-06 12:05:53,599 - INFO - Starte Pruning mit Prune-Ratio=0.3, Structured-Ratio=0.2
2025-05-06 12:05:53,599 - INFO - Starte unstrukturiertes Pruning mit Ratio 0.3...
2025-05-06 12:05:53,600 - INFO -   Layer block1.0: 65/216 Parameter entfernt (30.09%)
2025-05-06 12:05:53,600 - INFO -   Layer block2.0: 11/72 Parameter entfernt (15.28%)
2025-05-06 12:05:53,600 - INFO -   Layer block2.3: 39/128 Parameter entfernt (30.47%)
2025-05-06 12:05:53,600 - INFO -   Layer classifier.2: 29/96 Parameter entfernt (30.21%)
2025-05-06 12:05:53,600 - INFO - Unstrukturiertes Pruning abgeschlossen. Entfernt: 144 Parameter (24.74%)
2025-05-06 12:05:53,600 - INFO - Starte strukturelles Pruning mit Ratio 0.2...
2025-05-06 12:05:53,600 - INFO -   Layer block1.0: 1/8 Kanäle für Pruning ausgewählt
2025-05-06 12:05:53,600 - INFO -   Layer block2.3: 3/16 Kanäle für Pruning ausgewählt
2025-05-06 12:05:53,601 - INFO -   Keine gültigen Indizes für Layer block1.0 gefunden, überspringe
2025-05-06 12:05:53,601 - INFO - Strukturelles Pruning abgeschlossen. 4 Kanäle entfernt.
2025-05-06 12:05:53,601 - INFO - Finale Pruning-Statistik: 171 Parameter entfernt (29.38%)
2025-05-06 12:05:53,601 - INFO - Modellgröße reduziert von 582 auf 411 Parameter
2025-05-06 12:05:53,601 - INFO - Starte optimiertes Training für Mikrocontroller-Modell...
2025-05-06 12:05:53,602 - INFO - Speicheranalyse:
2025-05-06 12:05:53,602 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-06 12:05:53,602 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-06 12:05:53,602 - INFO -   Aktivierungsspeicher: 101.46 KB
2025-05-06 12:05:53,602 - INFO -   Gesamter Laufzeitspeicher: 102.09 KB (38.7% des RAM)
2025-05-06 12:05:53,602 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.09KB > 100KB)
2025-05-06 12:06:23,369 - INFO - Klassengewichte für Loss-Funktion: [0.49, 1.0, 1.0, 0.51, 0.5, 1.0]
2025-05-06 12:06:52,706 - INFO - Epoch 1/10 - Train Loss: 2.2234, Train Acc: 0.18% - Val Loss: 3.0598, Val Acc: 0.00%
2025-05-06 12:06:52,706 - INFO - Klassenweise Genauigkeiten:
2025-05-06 12:06:52,706 - INFO -   augmented: 0.00% (0/29)
2025-05-06 12:06:52,706 - INFO -   raw: 0.00% (0/3)
2025-05-06 12:06:52,706 - INFO -   synthetic: 0.00% (0/244)
2025-05-06 12:07:24,512 - INFO - Epoch 2/10 - Train Loss: 2.1392, Train Acc: 1.18% - Val Loss: 2.8390, Val Acc: 0.36%
2025-05-06 12:07:24,512 - INFO - Klassenweise Genauigkeiten:
2025-05-06 12:07:24,512 - INFO -   augmented: 3.45% (1/29)
2025-05-06 12:07:24,513 - INFO -   raw: 0.00% (0/3)
2025-05-06 12:07:24,513 - INFO -   synthetic: 0.00% (0/244)
2025-05-06 12:07:24,513 - INFO - Checkpoint gespeichert: models/pruned_pizza_model_epoch2.pth
2025-05-06 12:07:54,569 - INFO - Epoch 3/10 - Train Loss: 1.9148, Train Acc: 10.45% - Val Loss: 2.5707, Val Acc: 7.25%
2025-05-06 12:07:54,569 - INFO - Klassenweise Genauigkeiten:
2025-05-06 12:07:54,569 - INFO -   augmented: 68.97% (20/29)
2025-05-06 12:07:54,569 - INFO -   raw: 0.00% (0/3)
2025-05-06 12:07:54,569 - INFO -   synthetic: 0.00% (0/244)
2025-05-06 12:07:54,571 - INFO - Checkpoint gespeichert: models/pruned_pizza_model_epoch3.pth
2025-05-06 12:08:25,065 - INFO - Epoch 4/10 - Train Loss: 1.6661, Train Acc: 33.61% - Val Loss: 2.3457, Val Acc: 10.51%
2025-05-06 12:08:25,065 - INFO - Klassenweise Genauigkeiten:
2025-05-06 12:08:25,065 - INFO -   augmented: 100.00% (29/29)
2025-05-06 12:08:25,066 - INFO -   raw: 0.00% (0/3)
2025-05-06 12:08:25,066 - INFO -   synthetic: 0.00% (0/244)
2025-05-06 12:08:25,067 - INFO - Checkpoint gespeichert: models/pruned_pizza_model_epoch4.pth
2025-05-06 12:08:56,524 - INFO - Epoch 5/10 - Train Loss: 1.5886, Train Acc: 33.51% - Val Loss: 2.2048, Val Acc: 8.33%
2025-05-06 12:08:56,524 - INFO - Klassenweise Genauigkeiten:
2025-05-06 12:08:56,524 - INFO -   augmented: 72.41% (21/29)
2025-05-06 12:08:56,524 - INFO -   raw: 66.67% (2/3)
2025-05-06 12:08:56,524 - INFO -   synthetic: 0.00% (0/244)
2025-05-06 12:08:56,525 - INFO - Checkpoint gespeichert: models/pruned_pizza_model_epoch5.pth
2025-05-06 12:09:27,909 - INFO - Epoch 6/10 - Train Loss: 1.4454, Train Acc: 36.69% - Val Loss: 2.0862, Val Acc: 5.43%
2025-05-06 12:09:27,910 - INFO - Klassenweise Genauigkeiten:
2025-05-06 12:09:27,910 - INFO -   augmented: 48.28% (14/29)
2025-05-06 12:09:27,910 - INFO -   raw: 33.33% (1/3)
2025-05-06 12:09:27,910 - INFO -   synthetic: 0.00% (0/244)
2025-05-06 12:10:00,095 - INFO - Epoch 7/10 - Train Loss: 1.4032, Train Acc: 36.78% - Val Loss: 2.0579, Val Acc: 3.99%
2025-05-06 12:10:00,095 - INFO - Klassenweise Genauigkeiten:
2025-05-06 12:10:00,095 - INFO -   augmented: 27.59% (8/29)
2025-05-06 12:10:00,095 - INFO -   raw: 100.00% (3/3)
2025-05-06 12:10:00,095 - INFO -   synthetic: 0.00% (0/244)
2025-05-06 12:10:29,442 - INFO - Epoch 8/10 - Train Loss: 1.3832, Train Acc: 35.24% - Val Loss: 2.0071, Val Acc: 3.99%
2025-05-06 12:10:29,442 - INFO - Klassenweise Genauigkeiten:
2025-05-06 12:10:29,442 - INFO -   augmented: 27.59% (8/29)
2025-05-06 12:10:29,442 - INFO -   raw: 100.00% (3/3)
2025-05-06 12:10:29,442 - INFO -   synthetic: 0.00% (0/244)
2025-05-06 12:10:59,586 - INFO - Epoch 9/10 - Train Loss: 1.3632, Train Acc: 34.06% - Val Loss: 1.9754, Val Acc: 5.07%
2025-05-06 12:10:59,586 - INFO - Klassenweise Genauigkeiten:
2025-05-06 12:10:59,586 - INFO -   augmented: 37.93% (11/29)
2025-05-06 12:10:59,586 - INFO -   raw: 100.00% (3/3)
2025-05-06 12:10:59,586 - INFO -   synthetic: 0.00% (0/244)
2025-05-06 12:11:31,172 - INFO - Epoch 10/10 - Train Loss: 1.3671, Train Acc: 37.15% - Val Loss: 1.9748, Val Acc: 5.07%
2025-05-06 12:11:31,172 - INFO - Klassenweise Genauigkeiten:
2025-05-06 12:11:31,172 - INFO -   augmented: 37.93% (11/29)
2025-05-06 12:11:31,172 - INFO -   raw: 100.00% (3/3)
2025-05-06 12:11:31,172 - INFO -   synthetic: 0.00% (0/244)
2025-05-06 12:11:31,172 - INFO - EarlyStopping counter: 1/5
2025-05-06 12:11:31,173 - INFO - Checkpoint gespeichert: models/pruned_pizza_model_epoch10.pth
2025-05-06 12:11:31,173 - INFO - Training abgeschlossen in 307.80 Sekunden
2025-05-06 12:11:31,174 - INFO - Beste Modellgewichte wiederhergestellt
2025-05-06 12:11:31,175 - INFO - Modell gespeichert als: models/pruned_pizza_model.pth
2025-05-06 12:11:31,175 - INFO - Starte Weight-Clustering mit 32 Clustern
2025-05-06 12:11:31,175 - INFO - Starte Gewichts-Clustering mit 32 Clustern...
2025-05-06 12:11:32,133 - INFO -   Layer block1.0: Eindeutige Werte reduziert von 190 auf 8 (95.79% Reduktion)
2025-05-06 12:11:32,136 - INFO -   Layer block2.0: Eindeutige Werte reduziert von 62 auf 8 (87.10% Reduktion)
2025-05-06 12:11:32,139 - INFO -   Layer block2.3: Eindeutige Werte reduziert von 105 auf 8 (92.38% Reduktion)
2025-05-06 12:11:32,142 - INFO -   Layer classifier.2: Eindeutige Werte reduziert von 68 auf 8 (88.24% Reduktion)
2025-05-06 12:11:32,142 - INFO - Clustering abgeschlossen. Eindeutige Werte reduziert von 425 auf 32 (92.47% Reduktion)
2025-05-06 12:11:32,144 - INFO - Optimiertes Modell gespeichert unter: output/pruned_model/pruned_clustered_model.pth
2025-05-06 12:11:32,144 - INFO - Evaluiere optimiertes Modell
2025-05-06 12:11:32,837 - INFO - Modell-Evaluation abgeschlossen:
2025-05-06 12:11:32,837 - INFO -   Genauigkeit: 10.51%
2025-05-06 12:11:32,837 - INFO -   Durchschnittliche Inferenzzeit: 0.79 ms
2025-05-06 12:11:32,837 - INFO -   Klasse augmented: 100.00% (29/29)
2025-05-06 12:11:32,837 - INFO -   Klasse raw: 0.00% (0/3)
2025-05-06 12:11:32,837 - INFO -   Klasse synthetic: 0.00% (0/244)
2025-05-06 12:11:32,838 - INFO - Vergleichsbericht erstellt unter: output/pruned_model/optimization_report.html
2025-05-06 12:11:33,079 - INFO - Visualisierung erstellt unter: output/pruned_model/optimization_comparison.png
2025-05-06 12:27:41,944 - INFO - Verwende Gerät: cuda
2025-05-06 12:27:41,944 - INFO - ================================================================================
2025-05-06 12:27:41,944 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 12:27:41,944 - INFO - ================================================================================
2025-05-06 12:27:41,944 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 12:27:41,944 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 12:27:41,944 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 12:27:41,944 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 12:27:41,944 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 12:27:41,944 - INFO - ================================================================================
2025-05-06 12:27:41,944 - INFO - Preparing optimized data loaders...
2025-05-06 12:27:41,945 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 12:27:41,983 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 12:27:41,984 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 12:27:41,984 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 12:27:41,984 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 12:27:41,984 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 12:27:41,984 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 12:27:41,984 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 12:27:41,985 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 12:27:41,985 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 12:27:41,985 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 12:27:41,985 - INFO - Lade Teacher-Modell von models_optimized/micropizzanetv2_(inverted_residual).pth
2025-05-06 12:27:42,104 - INFO - Teacher-Modell als MicroPizzaNetV2 geladen
2025-05-06 12:27:42,106 - INFO - Student-Modell: CustomMicroPizzaNet (extra klein)
2025-05-06 12:27:42,106 - INFO - Teacher-Modell: 2,142 Parameter
2025-05-06 12:27:42,106 - INFO - Student-Modell: 414 Parameter
2025-05-06 12:27:42,106 - INFO - Parameterreduktion: 80.67%
2025-05-06 12:27:42,106 - INFO - Evaluiere Modell...
2025-05-06 12:27:42,264 - INFO - Genauigkeit für Klasse 'basic': 50.00%
2025-05-06 12:27:42,264 - INFO - Genauigkeit für Klasse 'burnt': 0.00%
2025-05-06 12:27:42,264 - INFO - Genauigkeit für Klasse 'combined': 33.33%
2025-05-06 12:27:42,264 - INFO - Genauigkeit für Klasse 'mixed': 100.00%
2025-05-06 12:27:42,264 - INFO - Genauigkeit für Klasse 'progression': 0.00%
2025-05-06 12:27:42,264 - INFO - Genauigkeit für Klasse 'segment': 0.00%
2025-05-06 12:27:42,264 - INFO - Gesamtgenauigkeit: 50.00%
2025-05-06 12:27:42,264 - INFO - Teacher-Modell Genauigkeit: 50.00%
2025-05-06 12:27:42,264 - INFO - Starte Training mit Knowledge Distillation (alpha=0.5, temp=4.0)
2025-05-06 12:27:42,527 - INFO - Epoch 1/30: Train Loss: 0.8821, Train Acc: 24.44% - Hard Loss: 1.7629, Soft Loss: 0.0001 - Val Loss: 0.8954, Val Acc: 25.00%
2025-05-06 12:27:42,527 - INFO - Neues bestes Modell in Epoch 1 mit Validation Accuracy: 25.00%
2025-05-06 12:27:42,656 - INFO - Epoch 2/30: Train Loss: 0.8776, Train Acc: 20.00% - Hard Loss: 1.7524, Soft Loss: 0.0002 - Val Loss: 0.8955, Val Acc: 8.33%
2025-05-06 12:27:42,775 - INFO - Epoch 3/30: Train Loss: 0.8686, Train Acc: 28.89% - Hard Loss: 1.7323, Soft Loss: 0.0003 - Val Loss: 0.8947, Val Acc: 16.67%
2025-05-06 12:27:42,889 - INFO - Epoch 4/30: Train Loss: 0.8527, Train Acc: 26.67% - Hard Loss: 1.6977, Soft Loss: 0.0005 - Val Loss: 0.8941, Val Acc: 25.00%
2025-05-06 12:27:43,005 - INFO - Epoch 5/30: Train Loss: 0.8611, Train Acc: 24.44% - Hard Loss: 1.7105, Soft Loss: 0.0007 - Val Loss: 0.8929, Val Acc: 25.00%
2025-05-06 12:27:43,122 - INFO - Epoch 6/30: Train Loss: 0.8498, Train Acc: 26.67% - Hard Loss: 1.6849, Soft Loss: 0.0009 - Val Loss: 0.8913, Val Acc: 25.00%
2025-05-06 12:27:43,243 - INFO - Epoch 7/30: Train Loss: 0.8467, Train Acc: 20.00% - Hard Loss: 1.6732, Soft Loss: 0.0013 - Val Loss: 0.8892, Val Acc: 25.00%
2025-05-06 12:27:43,356 - INFO - Epoch 8/30: Train Loss: 0.8476, Train Acc: 24.44% - Hard Loss: 1.6700, Soft Loss: 0.0016 - Val Loss: 0.8860, Val Acc: 25.00%
2025-05-06 12:27:43,490 - INFO - Epoch 9/30: Train Loss: 0.8369, Train Acc: 20.00% - Hard Loss: 1.6437, Soft Loss: 0.0019 - Val Loss: 0.8825, Val Acc: 25.00%
2025-05-06 12:27:43,613 - INFO - Epoch 10/30: Train Loss: 0.8405, Train Acc: 24.44% - Hard Loss: 1.6469, Soft Loss: 0.0021 - Val Loss: 0.8791, Val Acc: 0.00%
2025-05-06 12:27:43,733 - INFO - Epoch 11/30: Train Loss: 0.8274, Train Acc: 28.89% - Hard Loss: 1.6174, Soft Loss: 0.0023 - Val Loss: 0.8756, Val Acc: 0.00%
2025-05-06 12:27:43,733 - INFO - Early Stopping in Epoch 11
2025-05-06 12:27:43,734 - INFO - Beste Modellgewichte aus Epoch 1 geladen
2025-05-06 12:27:43,735 - INFO - Student-Modell gespeichert unter output/knowledge_distillation/student_model.pth
2025-05-06 12:27:44,069 - INFO - Trainingshistorie gespeichert unter output/knowledge_distillation/training_history.png
2025-05-06 12:27:44,069 - INFO - Evaluiere Modell...
2025-05-06 12:27:44,120 - INFO - Genauigkeit für Klasse 'basic': 0.00%
2025-05-06 12:27:44,120 - INFO - Genauigkeit für Klasse 'burnt': 0.00%
2025-05-06 12:27:44,120 - INFO - Genauigkeit für Klasse 'combined': 0.00%
2025-05-06 12:27:44,120 - INFO - Genauigkeit für Klasse 'mixed': 0.00%
2025-05-06 12:27:44,120 - INFO - Genauigkeit für Klasse 'progression': 0.00%
2025-05-06 12:27:44,120 - INFO - Genauigkeit für Klasse 'segment': 0.00%
2025-05-06 12:27:44,120 - INFO - Gesamtgenauigkeit: 0.00%
2025-05-06 12:27:44,120 - INFO - Student-Modell Genauigkeit: 0.00%
2025-05-06 12:27:44,121 - INFO - Vergleiche Student- und Teacher-Modell...
2025-05-06 12:27:44,173 - INFO - 
============================================================
2025-05-06 12:27:44,174 - INFO - MODELLVERGLEICH: TEACHER VS. STUDENT
2025-05-06 12:27:44,174 - INFO - ============================================================
2025-05-06 12:27:44,174 - INFO - TEACHER Modell:
2025-05-06 12:27:44,174 - INFO -   - Parameter: 2,142
2025-05-06 12:27:44,174 - INFO -   - Modellgröße: 17.93 KB
2025-05-06 12:27:44,174 - INFO -   - Genauigkeit: 50.00%
2025-05-06 12:27:44,174 - INFO -   - Inferenzzeit: 0.83 ms
2025-05-06 12:27:44,174 - INFO - 
STUDENT Modell:
2025-05-06 12:27:44,174 - INFO -   - Parameter: 414
2025-05-06 12:27:44,174 - INFO -   - Modellgröße: 8.23 KB
2025-05-06 12:27:44,174 - INFO -   - Genauigkeit: 0.00%
2025-05-06 12:27:44,174 - INFO -   - Inferenzzeit: 0.27 ms
2025-05-06 12:27:44,174 - INFO - 
VERGLEICH:
2025-05-06 12:27:44,174 - INFO -   - Parameterreduktion: 80.67%
2025-05-06 12:27:44,174 - INFO -   - Größenreduktion: 54.12%
2025-05-06 12:27:44,174 - INFO -   - Genauigkeitsänderung: -50.00%
2025-05-06 12:27:44,174 - INFO -   - Beschleunigungsfaktor: 3.12x
2025-05-06 12:27:44,174 - INFO - ============================================================
2025-05-06 12:27:44,174 - INFO - Vergleichsbericht gespeichert unter output/knowledge_distillation/model_comparison.json
2025-05-06 12:27:44,292 - INFO - Vergleichsvisualisierung gespeichert unter output/knowledge_distillation/model_comparison.png
2025-05-06 12:27:44,293 - INFO - 
==================================================
2025-05-06 12:27:44,293 - INFO - KNOWLEDGE DISTILLATION ABGESCHLOSSEN
2025-05-06 12:27:44,293 - INFO - ==================================================
2025-05-06 12:27:44,293 - INFO - Teacher-Genauigkeit: 50.00%
2025-05-06 12:27:44,293 - INFO - Student-Genauigkeit: 0.00%
2025-05-06 12:27:44,293 - INFO - Genauigkeitsänderung: -50.00%
2025-05-06 12:27:44,293 - INFO - Parameterreduktion: 80.67%
2025-05-06 12:27:44,293 - INFO - Modell und Berichte gespeichert unter: output/knowledge_distillation
2025-05-06 22:09:45,099 - INFO - Verwende Gerät: cuda
2025-05-06 22:09:45,099 - INFO - ================================================================================
2025-05-06 22:09:45,099 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 22:09:45,099 - INFO - ================================================================================
2025-05-06 22:09:45,099 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 22:09:45,099 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 22:09:45,100 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 22:09:45,100 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 22:09:45,100 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 22:09:45,100 - INFO - ================================================================================
2025-05-06 22:09:45,100 - INFO - Preparing optimized data loaders...
2025-05-06 22:09:45,100 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 22:09:45,153 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 22:09:45,153 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 22:09:45,153 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 22:09:45,153 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 22:09:45,153 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 22:09:45,153 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 22:09:45,153 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 22:09:45,155 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 22:09:45,156 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 22:09:45,156 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 22:09:45,156 - INFO - Aktiviere Early-Exit-Modell für dynamische Inferenz
2025-05-06 22:09:45,156 - INFO - Lade vortrainiertes Early-Exit-Modell für Evaluierung
2025-05-06 22:09:45,189 - ERROR - Fehler beim Laden des Early-Exit-Modells: [Errno 2] No such file or directory: 'models_optimized/early_exit_pizza_model.pth'
2025-05-06 22:10:28,286 - INFO - Verwende Gerät: cuda
2025-05-06 22:10:28,286 - INFO - ================================================================================
2025-05-06 22:10:28,286 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 22:10:28,286 - INFO - ================================================================================
2025-05-06 22:10:28,286 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 22:10:28,286 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 22:10:28,286 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 22:10:28,286 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 22:10:28,286 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 22:10:28,286 - INFO - ================================================================================
2025-05-06 22:10:28,286 - INFO - Preparing optimized data loaders...
2025-05-06 22:10:28,287 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 22:10:28,325 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 22:10:28,325 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 22:10:28,325 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 22:10:28,325 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 22:10:28,325 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 22:10:28,325 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 22:10:28,325 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 22:10:28,326 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 22:10:28,326 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 22:10:28,326 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 22:10:28,326 - INFO - Aktiviere Early-Exit-Modell für dynamische Inferenz
2025-05-06 22:15:17,561 - INFO - Verwende Gerät: cuda
2025-05-06 22:15:17,562 - INFO - ================================================================================
2025-05-06 22:15:17,562 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 22:15:17,562 - INFO - ================================================================================
2025-05-06 22:15:17,562 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 22:15:17,562 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 22:15:17,562 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 22:15:17,562 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 22:15:17,562 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 22:15:17,562 - INFO - ================================================================================
2025-05-06 22:15:17,562 - INFO - Preparing optimized data loaders...
2025-05-06 22:15:17,562 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 22:15:17,599 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 22:15:17,600 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 22:15:17,600 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 22:15:17,600 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 22:15:17,600 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 22:15:17,600 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 22:15:17,600 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 22:15:17,601 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 22:15:17,601 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 22:15:17,601 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 22:15:17,601 - INFO - Aktiviere Early-Exit-Modell für dynamische Inferenz
2025-05-06 22:15:17,747 - INFO - Starte Training für Early-Exit-Modell early_exit_pizza_model...
2025-05-06 22:15:18,288 - INFO - Speicheranalyse:
2025-05-06 22:15:18,288 - INFO -   Modellgröße (Float32): 311.57 KB
2025-05-06 22:15:18,288 - INFO -   Modellgröße (Int8): 77.89 KB (3.8% des Flash)
2025-05-06 22:15:18,288 - INFO -   Aktivierungsspeicher: 836.97 KB
2025-05-06 22:15:18,288 - INFO -   Gesamter Laufzeitspeicher: 914.86 KB (346.5% des RAM)
2025-05-06 22:15:18,288 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (914.86KB > 100KB)
2025-05-06 22:15:18,288 - INFO - Modell hat 78,892 Parameter
2025-05-06 22:15:18,288 - INFO - Geschätzte Speicheranforderungen: 914.86 KB
2025-05-06 22:15:18,361 - INFO - Klassengewichte für Loss-Funktion: [1.07, 0.38, 0.68, 1.07, 1.0, 1.0]
2025-05-06 22:15:18,362 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 22:16:50,553 - INFO - Verwende Gerät: cuda
2025-05-06 22:16:50,553 - INFO - ================================================================================
2025-05-06 22:16:50,553 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 22:16:50,553 - INFO - ================================================================================
2025-05-06 22:16:50,553 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 22:16:50,553 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 22:16:50,553 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 22:16:50,553 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 22:16:50,553 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 22:16:50,553 - INFO - ================================================================================
2025-05-06 22:16:50,553 - INFO - Preparing optimized data loaders...
2025-05-06 22:16:50,554 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 22:16:50,594 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 22:16:50,594 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 22:16:50,594 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 22:16:50,594 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 22:16:50,594 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 22:16:50,594 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 22:16:50,594 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 22:16:50,595 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 22:16:50,595 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 22:16:50,596 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 22:16:50,596 - INFO - Aktiviere Early-Exit-Modell für dynamische Inferenz
2025-05-06 22:16:50,744 - INFO - Starte Training für Early-Exit-Modell early_exit_pizza_model...
2025-05-06 22:16:50,921 - INFO - Speicheranalyse:
2025-05-06 22:16:50,921 - INFO -   Modellgröße (Float32): 311.57 KB
2025-05-06 22:16:50,921 - INFO -   Modellgröße (Int8): 77.89 KB (3.8% des Flash)
2025-05-06 22:16:50,921 - INFO -   Aktivierungsspeicher: 836.97 KB
2025-05-06 22:16:50,921 - INFO -   Gesamter Laufzeitspeicher: 914.86 KB (346.5% des RAM)
2025-05-06 22:16:50,921 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (914.86KB > 100KB)
2025-05-06 22:16:50,921 - INFO - Modell hat 78,892 Parameter
2025-05-06 22:16:50,921 - INFO - Geschätzte Speicheranforderungen: 914.86 KB
2025-05-06 22:16:50,989 - INFO - Klassengewichte für Loss-Funktion: [0.58, 0.47, 0.94, 0.94, 1.0, 1.0]
2025-05-06 22:16:50,990 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-06 22:24:21,773 - INFO - Verwende Gerät: cuda
2025-05-06 22:24:21,773 - INFO - ================================================================================
2025-05-06 22:24:21,773 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-06 22:24:21,774 - INFO - ================================================================================
2025-05-06 22:24:21,774 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-06 22:24:21,774 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-06 22:24:21,774 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-06 22:24:21,774 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-06 22:24:21,774 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-06 22:24:21,774 - INFO - ================================================================================
2025-05-06 22:24:21,774 - INFO - Preparing optimized data loaders...
2025-05-06 22:24:21,774 - INFO - Analysiere Datensatz in data/augmented...
2025-05-06 22:24:21,811 - INFO - Datensatzanalyse abgeschlossen:
2025-05-06 22:24:21,811 - INFO - Gesamtzahl der Bilder: 57
2025-05-06 22:24:21,811 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-06 22:24:21,811 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-06 22:24:21,811 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-06 22:24:21,811 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-06 22:24:21,811 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-06 22:24:21,812 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-06 22:24:21,813 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 22:24:21,813 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-06 22:24:21,813 - INFO - Aktiviere Early-Exit-Modell für dynamische Inferenz
2025-05-06 22:24:21,957 - INFO - Starte Training für Early-Exit-Modell early_exit_pizza_model...
2025-05-06 22:24:22,135 - INFO - Speicheranalyse:
2025-05-06 22:24:22,135 - INFO -   Modellgröße (Float32): 311.57 KB
2025-05-06 22:24:22,135 - INFO -   Modellgröße (Int8): 77.89 KB (3.8% des Flash)
2025-05-06 22:24:22,135 - INFO -   Aktivierungsspeicher: 836.97 KB
2025-05-06 22:24:22,135 - INFO -   Gesamter Laufzeitspeicher: 914.86 KB (346.5% des RAM)
2025-05-06 22:24:22,135 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (914.86KB > 100KB)
2025-05-06 22:24:22,135 - INFO - Modell hat 78,892 Parameter
2025-05-06 22:24:22,135 - INFO - Geschätzte Speicheranforderungen: 914.86 KB
2025-05-06 22:24:22,205 - INFO - Klassengewichte für Loss-Funktion: [0.94, 0.5, 0.54, 0.94, 1.0, 1.0]
2025-05-06 22:24:22,206 - INFO - Epoche 1: Observer-Learning aktiviert
2025-05-07 02:09:04,446 - INFO - Verwende Gerät: cuda
2025-05-07 02:09:04,447 - INFO - ================================================================================
2025-05-07 02:09:04,447 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-07 02:09:04,447 - INFO - ================================================================================
2025-05-07 02:09:04,447 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-07 02:09:04,447 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-07 02:09:04,447 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-07 02:09:04,447 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-07 02:09:04,447 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-07 02:09:04,447 - INFO - ================================================================================
2025-05-07 02:09:04,447 - INFO - Preparing optimized data loaders...
2025-05-07 02:09:04,447 - INFO - Analysiere Datensatz in data/augmented...
2025-05-07 02:09:04,504 - INFO - Datensatzanalyse abgeschlossen:
2025-05-07 02:09:04,504 - INFO - Gesamtzahl der Bilder: 57
2025-05-07 02:09:04,504 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-07 02:09:04,504 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-07 02:09:04,504 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-07 02:09:04,504 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-07 02:09:04,505 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-07 02:09:04,507 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-07 02:09:04,507 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-07 02:09:04,507 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-07 02:09:04,507 - INFO - Aktiviere Early-Exit-Modell für dynamische Inferenz
2025-05-07 02:09:04,507 - INFO - Lade vortrainiertes Early-Exit-Modell für Evaluierung
2025-05-07 02:09:04,507 - ERROR - Fehler: Das Early-Exit-Modell wurde nicht gefunden: models_optimized/early_exit_pizza_model.pth
2025-05-07 02:09:04,507 - INFO - Sie müssen das Modell zuerst trainieren mit: --early-exit (ohne --run)
2025-05-07 02:09:04,507 - INFO - Oder geben Sie ein anderes vortrainiertes Modell mit --pretrained an
2025-05-08 01:05:38,592 - INFO - Verwende Gerät: cuda
2025-05-08 01:05:38,593 - INFO - Preparing optimized data loaders...
2025-05-08 01:05:38,594 - INFO - Analysiere Datensatz in data...
2025-05-08 01:05:45,339 - INFO - Datensatzanalyse abgeschlossen:
2025-05-08 01:05:45,339 - INFO - Gesamtzahl der Bilder: 1377
2025-05-08 01:05:45,339 - INFO - Klassenverteilung: {'videos': 0, 'synthetic': 1223, 'augmented': 142, 'raw': 12, 'classified': 0, 'processed': 0}
2025-05-08 01:05:45,339 - INFO - Durchschnittliche Bildgröße: 288.5 x 282.5
2025-05-08 01:05:45,340 - INFO - RGB-Mittelwerte: [0.2891, 0.2389, 0.2074]
2025-05-08 01:05:45,340 - INFO - RGB-Standardabweichungen: [0.2989, 0.2844, 0.2719]
2025-05-08 01:05:45,340 - INFO - Using dataset-specific normalization: mean=[0.289, 0.239, 0.207], std=[0.299, 0.284, 0.272]
2025-05-08 01:05:45,344 - INFO - Data loaders created: 1101 training images, 276 validation images
2025-05-08 01:05:45,344 - INFO - Classes: ['augmented', 'classified', 'processed', 'raw', 'synthetic', 'videos']
2025-05-08 01:05:45,344 - INFO - Anzahl Klassen: 6
2025-05-08 01:05:45,344 - INFO - Lade vortrainiertes Modell von: models/micro_pizza_model.pth
2025-05-08 01:05:45,478 - INFO - Evaluiere Basis-Modell vor Optimierung
2025-05-08 01:05:47,346 - INFO - Modell-Evaluation abgeschlossen:
2025-05-08 01:05:47,346 - INFO -   Genauigkeit: 0.00%
2025-05-08 01:05:47,346 - INFO -   Durchschnittliche Inferenzzeit: 44.59 ms
2025-05-08 01:05:47,346 - INFO -   Klasse augmented: 0.00% (0/29)
2025-05-08 01:05:47,346 - INFO -   Klasse raw: 0.00% (0/3)
2025-05-08 01:05:47,346 - INFO -   Klasse synthetic: 0.00% (0/244)
2025-05-08 01:05:47,348 - INFO - Starte Pruning mit Prune-Ratio=0.3, Structured-Ratio=0.2
2025-05-08 01:05:47,348 - INFO - Starte unstrukturiertes Pruning mit Ratio 0.3...
2025-05-08 01:05:47,546 - INFO -   Layer block1.0: 65/216 Parameter entfernt (30.09%)
2025-05-08 01:05:47,547 - INFO -   Layer block2.0: 11/72 Parameter entfernt (15.28%)
2025-05-08 01:05:47,548 - INFO -   Layer block2.3: 39/128 Parameter entfernt (30.47%)
2025-05-08 01:05:47,549 - INFO -   Layer classifier.2: 29/96 Parameter entfernt (30.21%)
2025-05-08 01:05:47,549 - INFO - Unstrukturiertes Pruning abgeschlossen. Entfernt: 144 Parameter (24.74%)
2025-05-08 01:05:47,549 - INFO - Starte strukturelles Pruning mit Ratio 0.2...
2025-05-08 01:05:47,584 - INFO -   Layer block1.0: 1/8 Kanäle für Pruning ausgewählt
2025-05-08 01:05:47,584 - INFO -   Layer block2.3: 3/16 Kanäle für Pruning ausgewählt
2025-05-08 01:05:47,597 - INFO -   Keine gültigen Indizes für Layer block1.0 gefunden, überspringe
2025-05-08 01:05:47,598 - INFO - Strukturelles Pruning abgeschlossen. 4 Kanäle entfernt.
2025-05-08 01:05:47,598 - INFO - Finale Pruning-Statistik: 171 Parameter entfernt (29.38%)
2025-05-08 01:05:47,598 - INFO - Modellgröße reduziert von 582 auf 411 Parameter
2025-05-08 01:05:47,598 - INFO - Starte Fine-Tuning für 10 Epochen
2025-05-08 01:05:47,598 - INFO - Starte Feintuning des geprunten Modells für 10 Epochen...
2025-05-08 01:05:47,598 - INFO - Starte optimiertes Training für Mikrocontroller-Modell...
2025-05-08 01:05:47,633 - INFO - Speicheranalyse:
2025-05-08 01:05:47,633 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-08 01:05:47,633 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-08 01:05:47,633 - INFO -   Aktivierungsspeicher: 101.46 KB
2025-05-08 01:05:47,633 - INFO -   Gesamter Laufzeitspeicher: 102.09 KB (38.7% des RAM)
2025-05-08 01:05:47,634 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.09KB > 100KB)
2025-05-08 01:10:08,909 - INFO - Verwende Gerät: cpu
2025-05-08 01:10:08,909 - INFO - Preparing optimized data loaders...
2025-05-08 01:10:08,909 - INFO - Analysiere Datensatz in data...
2025-05-08 01:10:12,831 - INFO - Datensatzanalyse abgeschlossen:
2025-05-08 01:10:12,831 - INFO - Gesamtzahl der Bilder: 1377
2025-05-08 01:10:12,831 - INFO - Klassenverteilung: {'videos': 0, 'synthetic': 1223, 'augmented': 142, 'raw': 12, 'classified': 0, 'processed': 0}
2025-05-08 01:10:12,831 - INFO - Durchschnittliche Bildgröße: 288.5 x 282.5
2025-05-08 01:10:12,831 - INFO - RGB-Mittelwerte: [0.2891, 0.2389, 0.2074]
2025-05-08 01:10:12,831 - INFO - RGB-Standardabweichungen: [0.2989, 0.2844, 0.2719]
2025-05-08 01:10:12,832 - INFO - Using dataset-specific normalization: mean=[0.289, 0.239, 0.207], std=[0.299, 0.284, 0.272]
2025-05-08 01:10:12,835 - INFO - Data loaders created: 1101 training images, 276 validation images
2025-05-08 01:10:12,835 - INFO - Classes: ['augmented', 'classified', 'processed', 'raw', 'synthetic', 'videos']
2025-05-08 01:10:12,835 - INFO - Anzahl Klassen: 6
2025-05-08 01:10:12,835 - INFO - Lade vortrainiertes Modell von: models/micro_pizza_model.pth
2025-05-08 01:10:12,837 - INFO - Evaluiere Basis-Modell vor Optimierung
2025-05-08 01:10:13,792 - INFO - Modell-Evaluation abgeschlossen:
2025-05-08 01:10:13,792 - INFO -   Genauigkeit: 0.00%
2025-05-08 01:10:13,792 - INFO -   Durchschnittliche Inferenzzeit: 4.05 ms
2025-05-08 01:10:13,792 - INFO -   Klasse augmented: 0.00% (0/29)
2025-05-08 01:10:13,792 - INFO -   Klasse raw: 0.00% (0/3)
2025-05-08 01:10:13,792 - INFO -   Klasse synthetic: 0.00% (0/244)
2025-05-08 01:10:13,793 - INFO - Starte Pruning mit Prune-Ratio=0.3, Structured-Ratio=0.2
2025-05-08 01:10:13,793 - INFO - Starte unstrukturiertes Pruning mit Ratio 0.3...
2025-05-08 01:10:13,795 - INFO -   Layer block1.0: 65/216 Parameter entfernt (30.09%)
2025-05-08 01:10:13,795 - INFO -   Layer block2.0: 11/72 Parameter entfernt (15.28%)
2025-05-08 01:10:13,795 - INFO -   Layer block2.3: 39/128 Parameter entfernt (30.47%)
2025-05-08 01:10:13,795 - INFO -   Layer classifier.2: 29/96 Parameter entfernt (30.21%)
2025-05-08 01:10:13,796 - INFO - Unstrukturiertes Pruning abgeschlossen. Entfernt: 144 Parameter (24.74%)
2025-05-08 01:10:13,796 - INFO - Starte strukturelles Pruning mit Ratio 0.2...
2025-05-08 01:10:13,798 - INFO -   Layer block1.0: 1/8 Kanäle für Pruning ausgewählt
2025-05-08 01:10:13,798 - INFO -   Layer block2.3: 3/16 Kanäle für Pruning ausgewählt
2025-05-08 01:10:13,799 - INFO -   Keine gültigen Indizes für Layer block1.0 gefunden, überspringe
2025-05-08 01:10:13,799 - INFO - Strukturelles Pruning abgeschlossen. 4 Kanäle entfernt.
2025-05-08 01:10:13,799 - INFO - Finale Pruning-Statistik: 171 Parameter entfernt (29.38%)
2025-05-08 01:10:13,799 - INFO - Modellgröße reduziert von 582 auf 411 Parameter
2025-05-08 01:10:13,799 - INFO - Starte Fine-Tuning für 3 Epochen
2025-05-08 01:10:13,799 - INFO - Starte Feintuning des geprunten Modells für 3 Epochen...
2025-05-08 01:10:13,799 - INFO - Starte optimiertes Training für Mikrocontroller-Modell...
2025-05-08 01:10:13,803 - INFO - Speicheranalyse:
2025-05-08 01:10:13,803 - INFO -   Modellgröße (Float32): 2.54 KB
2025-05-08 01:10:13,803 - INFO -   Modellgröße (Int8): 0.63 KB (0.0% des Flash)
2025-05-08 01:10:13,803 - INFO -   Aktivierungsspeicher: 101.46 KB
2025-05-08 01:10:13,803 - INFO -   Gesamter Laufzeitspeicher: 102.09 KB (38.7% des RAM)
2025-05-08 01:10:13,803 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (102.09KB > 100KB)
2025-05-08 01:14:15,482 - INFO - Verwende Gerät: cuda
2025-05-08 01:14:15,482 - INFO - ================================================================================
2025-05-08 01:14:15,482 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-08 01:14:15,482 - INFO - ================================================================================
2025-05-08 01:14:15,482 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-08 01:14:15,482 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-08 01:14:15,482 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-08 01:14:15,482 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-08 01:14:15,482 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-08 01:14:15,482 - INFO - ================================================================================
2025-05-08 01:14:15,482 - INFO - Preparing optimized data loaders...
2025-05-08 01:14:15,483 - INFO - Analysiere Datensatz in data/augmented...
2025-05-08 01:14:15,557 - INFO - Datensatzanalyse abgeschlossen:
2025-05-08 01:14:15,557 - INFO - Gesamtzahl der Bilder: 57
2025-05-08 01:14:15,557 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-08 01:14:15,557 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-08 01:14:15,557 - INFO - RGB-Mittelwerte: [0.4839, 0.4021, 0.3328]
2025-05-08 01:14:15,557 - INFO - RGB-Standardabweichungen: [0.2349, 0.2528, 0.2663]
2025-05-08 01:14:15,557 - INFO - Using dataset-specific normalization: mean=[0.484, 0.402, 0.333], std=[0.235, 0.253, 0.266]
2025-05-08 01:14:15,559 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-08 01:14:15,559 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-08 01:14:15,559 - INFO - Klassenamen: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-08 01:14:15,559 - INFO - Lade Teacher-Modell von models_optimized/micropizzanetv2_(inverted_residual).pth
2025-05-08 01:14:15,765 - INFO - Teacher-Modell als MicroPizzaNetV2 geladen
2025-05-08 01:14:15,769 - INFO - Student-Modell: Standard MicroPizzaNet
2025-05-08 01:14:15,770 - INFO - Teacher-Modell: 2,142 Parameter
2025-05-08 01:14:15,770 - INFO - Student-Modell: 582 Parameter
2025-05-08 01:14:15,770 - INFO - Parameterreduktion: 72.83%
2025-05-08 01:14:15,770 - INFO - Evaluiere Modell...
2025-05-08 01:14:16,085 - INFO - Genauigkeit für Klasse 'basic': 50.00%
2025-05-08 01:14:16,085 - INFO - Genauigkeit für Klasse 'burnt': 0.00%
2025-05-08 01:14:16,085 - INFO - Genauigkeit für Klasse 'combined': 33.33%
2025-05-08 01:14:16,085 - INFO - Genauigkeit für Klasse 'mixed': 100.00%
2025-05-08 01:14:16,085 - INFO - Genauigkeit für Klasse 'progression': 0.00%
2025-05-08 01:14:16,085 - INFO - Genauigkeit für Klasse 'segment': 0.00%
2025-05-08 01:14:16,085 - INFO - Gesamtgenauigkeit: 50.00%
2025-05-08 01:14:16,085 - INFO - Teacher-Modell Genauigkeit: 50.00%
2025-05-08 01:14:16,085 - INFO - Starte Training mit Knowledge Distillation (alpha=0.5, temp=4.0)
2025-05-08 01:14:17,314 - INFO - Epoch 1/50: Train Loss: 0.9039, Train Acc: 11.11% - Hard Loss: 1.8052, Soft Loss: 0.0002 - Val Loss: 0.8974, Val Acc: 8.33%
2025-05-08 01:14:17,316 - INFO - Neues bestes Modell in Epoch 1 mit Validation Accuracy: 8.33%
2025-05-08 01:14:17,744 - INFO - Epoch 2/50: Train Loss: 0.8907, Train Acc: 31.11% - Hard Loss: 1.7791, Soft Loss: 0.0001 - Val Loss: 0.8956, Val Acc: 0.00%
2025-05-08 01:14:18,197 - INFO - Epoch 3/50: Train Loss: 0.8781, Train Acc: 28.89% - Hard Loss: 1.7528, Soft Loss: 0.0002 - Val Loss: 0.8923, Val Acc: 0.00%
2025-05-08 01:14:18,681 - INFO - Epoch 4/50: Train Loss: 0.8679, Train Acc: 24.44% - Hard Loss: 1.7304, Soft Loss: 0.0003 - Val Loss: 0.8890, Val Acc: 0.00%
2025-05-08 01:14:19,161 - INFO - Epoch 5/50: Train Loss: 0.8600, Train Acc: 35.56% - Hard Loss: 1.7115, Soft Loss: 0.0005 - Val Loss: 0.8855, Val Acc: 0.00%
2025-05-08 01:14:19,638 - INFO - Epoch 6/50: Train Loss: 0.8609, Train Acc: 24.44% - Hard Loss: 1.7098, Soft Loss: 0.0008 - Val Loss: 0.8800, Val Acc: 8.33%
2025-05-08 01:14:20,086 - INFO - Epoch 7/50: Train Loss: 0.8478, Train Acc: 24.44% - Hard Loss: 1.6796, Soft Loss: 0.0010 - Val Loss: 0.8745, Val Acc: 16.67%
2025-05-08 01:14:20,086 - INFO - Neues bestes Modell in Epoch 7 mit Validation Accuracy: 16.67%
2025-05-08 01:14:20,564 - INFO - Epoch 8/50: Train Loss: 0.8421, Train Acc: 31.11% - Hard Loss: 1.6640, Soft Loss: 0.0013 - Val Loss: 0.8687, Val Acc: 16.67%
2025-05-08 01:14:21,014 - INFO - Epoch 9/50: Train Loss: 0.8379, Train Acc: 24.44% - Hard Loss: 1.6496, Soft Loss: 0.0016 - Val Loss: 0.8637, Val Acc: 16.67%
2025-05-08 01:14:21,428 - INFO - Epoch 10/50: Train Loss: 0.8279, Train Acc: 40.00% - Hard Loss: 1.6259, Soft Loss: 0.0019 - Val Loss: 0.8623, Val Acc: 8.33%
2025-05-08 01:14:21,906 - INFO - Epoch 11/50: Train Loss: 0.8381, Train Acc: 33.33% - Hard Loss: 1.6386, Soft Loss: 0.0023 - Val Loss: 0.8602, Val Acc: 8.33%
2025-05-08 01:14:22,398 - INFO - Epoch 12/50: Train Loss: 0.8388, Train Acc: 28.89% - Hard Loss: 1.6353, Soft Loss: 0.0027 - Val Loss: 0.8567, Val Acc: 8.33%
2025-05-08 01:14:22,882 - INFO - Epoch 13/50: Train Loss: 0.8260, Train Acc: 37.78% - Hard Loss: 1.6001, Soft Loss: 0.0032 - Val Loss: 0.8519, Val Acc: 8.33%
2025-05-08 01:14:23,346 - INFO - Epoch 14/50: Train Loss: 0.8284, Train Acc: 24.44% - Hard Loss: 1.6024, Soft Loss: 0.0034 - Val Loss: 0.8488, Val Acc: 8.33%
2025-05-08 01:14:23,694 - INFO - Epoch 15/50: Train Loss: 0.8265, Train Acc: 35.56% - Hard Loss: 1.5927, Soft Loss: 0.0038 - Val Loss: 0.8476, Val Acc: 8.33%
2025-05-08 01:14:24,203 - INFO - Epoch 16/50: Train Loss: 0.8220, Train Acc: 40.00% - Hard Loss: 1.5887, Soft Loss: 0.0035 - Val Loss: 0.8479, Val Acc: 8.33%
2025-05-08 01:14:24,638 - INFO - Epoch 17/50: Train Loss: 0.8322, Train Acc: 24.44% - Hard Loss: 1.6006, Soft Loss: 0.0040 - Val Loss: 0.8506, Val Acc: 8.33%
2025-05-08 01:14:24,638 - INFO - Early Stopping in Epoch 17
2025-05-08 01:14:24,640 - INFO - Beste Modellgewichte aus Epoch 7 geladen
2025-05-08 01:14:24,645 - INFO - Student-Modell gespeichert unter output/knowledge_distillation/student_model.pth
2025-05-08 01:14:25,349 - INFO - Trainingshistorie gespeichert unter output/knowledge_distillation/training_history.png
2025-05-08 01:14:25,349 - INFO - Evaluiere Modell...
2025-05-08 01:14:25,479 - INFO - Genauigkeit für Klasse 'basic': 0.00%
2025-05-08 01:14:25,479 - INFO - Genauigkeit für Klasse 'burnt': 0.00%
2025-05-08 01:14:25,480 - INFO - Genauigkeit für Klasse 'combined': 33.33%
2025-05-08 01:14:25,480 - INFO - Genauigkeit für Klasse 'mixed': 0.00%
2025-05-08 01:14:25,480 - INFO - Genauigkeit für Klasse 'progression': 0.00%
2025-05-08 01:14:25,480 - INFO - Genauigkeit für Klasse 'segment': 0.00%
2025-05-08 01:14:25,480 - INFO - Gesamtgenauigkeit: 8.33%
2025-05-08 01:14:25,481 - INFO - Student-Modell Genauigkeit: 8.33%
2025-05-08 01:14:25,483 - INFO - Vergleiche Student- und Teacher-Modell...
2025-05-08 01:14:25,699 - INFO - 
============================================================
2025-05-08 01:14:25,700 - INFO - MODELLVERGLEICH: TEACHER VS. STUDENT
2025-05-08 01:14:25,700 - INFO - ============================================================
2025-05-08 01:14:25,700 - INFO - TEACHER Modell:
2025-05-08 01:14:25,700 - INFO -   - Parameter: 2,142
2025-05-08 01:14:25,700 - INFO -   - Modellgröße: 17.93 KB
2025-05-08 01:14:25,700 - INFO -   - Genauigkeit: 50.00%
2025-05-08 01:14:25,700 - INFO -   - Inferenzzeit: 3.37 ms
2025-05-08 01:14:25,701 - INFO - 
STUDENT Modell:
2025-05-08 01:14:25,701 - INFO -   - Parameter: 582
2025-05-08 01:14:25,701 - INFO -   - Modellgröße: 9.10 KB
2025-05-08 01:14:25,701 - INFO -   - Genauigkeit: 8.33%
2025-05-08 01:14:25,701 - INFO -   - Inferenzzeit: 1.15 ms
2025-05-08 01:14:25,701 - INFO - 
VERGLEICH:
2025-05-08 01:14:25,701 - INFO -   - Parameterreduktion: 72.83%
2025-05-08 01:14:25,701 - INFO -   - Größenreduktion: 49.24%
2025-05-08 01:14:25,701 - INFO -   - Genauigkeitsänderung: -41.67%
2025-05-08 01:14:25,701 - INFO -   - Beschleunigungsfaktor: 2.93x
2025-05-08 01:14:25,701 - INFO - ============================================================
2025-05-08 01:14:25,702 - INFO - Vergleichsbericht gespeichert unter output/knowledge_distillation/model_comparison.json
2025-05-08 01:14:26,032 - INFO - Vergleichsvisualisierung gespeichert unter output/knowledge_distillation/model_comparison.png
2025-05-08 01:14:26,032 - INFO - 
==================================================
2025-05-08 01:14:26,032 - INFO - KNOWLEDGE DISTILLATION ABGESCHLOSSEN
2025-05-08 01:14:26,032 - INFO - ==================================================
2025-05-08 01:14:26,032 - INFO - Teacher-Genauigkeit: 50.00%
2025-05-08 01:14:26,032 - INFO - Student-Genauigkeit: 8.33%
2025-05-08 01:14:26,032 - INFO - Genauigkeitsänderung: -41.67%
2025-05-08 01:14:26,032 - INFO - Parameterreduktion: 72.83%
2025-05-08 01:14:26,032 - INFO - Modell und Berichte gespeichert unter: output/knowledge_distillation
2025-05-08 01:22:27,756 - INFO - ================================================================================
2025-05-08 01:22:27,756 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-08 01:22:27,756 - INFO - ================================================================================
2025-05-08 01:22:27,756 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-08 01:22:27,756 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-08 01:22:27,756 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-08 01:22:27,756 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-08 01:22:27,756 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-08 01:22:27,756 - INFO - ================================================================================
2025-05-08 01:22:27,756 - INFO - Analysiere Datensatz...
2025-05-08 01:23:18,519 - INFO - ================================================================================
2025-05-08 01:23:18,519 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-08 01:23:18,519 - INFO - ================================================================================
2025-05-08 01:23:18,519 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-08 01:23:18,519 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-08 01:23:18,519 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-08 01:23:18,519 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-08 01:23:18,519 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-08 01:23:18,519 - INFO - ================================================================================
2025-05-08 01:23:18,519 - INFO - Analysiere Datensatz...
2025-05-08 01:23:18,519 - INFO - Analysiere Datensatz in data/augmented...
2025-05-08 01:23:18,631 - INFO - Datensatzanalyse abgeschlossen:
2025-05-08 01:23:18,632 - INFO - Gesamtzahl der Bilder: 57
2025-05-08 01:23:18,632 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-08 01:23:18,632 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-08 01:23:18,632 - INFO - RGB-Mittelwerte: [0.4855, 0.4032, 0.3342]
2025-05-08 01:23:18,632 - INFO - RGB-Standardabweichungen: [0.2323, 0.2506, 0.2648]
2025-05-08 01:23:18,633 - INFO - Erstelle DataLoader...
2025-05-08 01:23:18,633 - INFO - Preparing optimized data loaders...
2025-05-08 01:23:18,634 - INFO - Using dataset-specific normalization: mean=[0.48547589 0.40321967 0.3341802 ], std=[0.23232426 0.25061423 0.26477952]
2025-05-08 01:23:18,640 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-08 01:23:18,640 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-08 01:23:18,641 - INFO - Lade vortrainiertes Modell: models_optimized/micropizzanetv2_(inverted_residual).pth
2025-05-08 01:23:44,026 - INFO - ================================================================================
2025-05-08 01:23:44,026 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-08 01:23:44,026 - INFO - ================================================================================
2025-05-08 01:23:44,026 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-08 01:23:44,026 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-08 01:23:44,026 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-08 01:23:44,026 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-08 01:23:44,026 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-08 01:23:44,026 - INFO - ================================================================================
2025-05-08 01:23:44,026 - INFO - Analysiere Datensatz...
2025-05-08 01:23:44,026 - INFO - Analysiere Datensatz in data/augmented...
2025-05-08 01:23:44,058 - INFO - Datensatzanalyse abgeschlossen:
2025-05-08 01:23:44,058 - INFO - Gesamtzahl der Bilder: 57
2025-05-08 01:23:44,058 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-08 01:23:44,058 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-08 01:23:44,058 - INFO - RGB-Mittelwerte: [0.4877, 0.4070, 0.3392]
2025-05-08 01:23:44,058 - INFO - RGB-Standardabweichungen: [0.2313, 0.2507, 0.2664]
2025-05-08 01:23:44,059 - INFO - Erstelle DataLoader...
2025-05-08 01:23:44,059 - INFO - Preparing optimized data loaders...
2025-05-08 01:23:44,059 - INFO - Using dataset-specific normalization: mean=[0.48767595 0.40696518 0.33917782], std=[0.23127509 0.25071025 0.26639748]
2025-05-08 01:23:44,060 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-08 01:23:44,060 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-08 01:23:44,060 - INFO - Erstelle Early-Exit-Modell...
2025-05-08 01:23:44,061 - INFO - Modell erstellt mit 1,532 Parametern
2025-05-08 01:23:44,071 - INFO - Speicheranalyse:
2025-05-08 01:23:44,071 - INFO -   Modellgröße (Float32): 6.63 KB
2025-05-08 01:23:44,071 - INFO -   Modellgröße (Int8): 1.66 KB (0.1% des Flash)
2025-05-08 01:23:44,071 - INFO -   Aktivierungsspeicher: 123.23 KB
2025-05-08 01:23:44,071 - INFO -   Gesamter Laufzeitspeicher: 124.89 KB (47.3% des RAM)
2025-05-08 01:23:44,071 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (124.89KB > 100KB)
2025-05-08 01:23:44,071 - INFO - Starte Training von micropizzanet_early_exit mit Early Exit (λ=0.3)...
2025-05-08 01:24:42,989 - INFO - ================================================================================
2025-05-08 01:24:42,989 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-08 01:24:42,989 - INFO - ================================================================================
2025-05-08 01:24:42,989 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-08 01:24:42,989 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-08 01:24:42,989 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-08 01:24:42,989 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-08 01:24:42,989 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-08 01:24:42,989 - INFO - ================================================================================
2025-05-08 01:24:42,989 - INFO - Analysiere Datensatz...
2025-05-08 01:24:42,989 - INFO - Analysiere Datensatz in data/augmented...
2025-05-08 01:24:43,023 - INFO - Datensatzanalyse abgeschlossen:
2025-05-08 01:24:43,024 - INFO - Gesamtzahl der Bilder: 57
2025-05-08 01:24:43,024 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-08 01:24:43,024 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-08 01:24:43,024 - INFO - RGB-Mittelwerte: [0.4868, 0.4007, 0.3314]
2025-05-08 01:24:43,024 - INFO - RGB-Standardabweichungen: [0.2326, 0.2519, 0.2646]
2025-05-08 01:24:43,024 - INFO - Erstelle DataLoader...
2025-05-08 01:24:43,024 - INFO - Preparing optimized data loaders...
2025-05-08 01:24:43,024 - INFO - Using dataset-specific normalization: mean=[0.48680342 0.40074547 0.33141976], std=[0.23263349 0.25187778 0.26463509]
2025-05-08 01:24:43,025 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-08 01:24:43,025 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-08 01:24:43,025 - INFO - Erstelle Early-Exit-Modell...
2025-05-08 01:24:43,026 - INFO - Modell erstellt mit 1,532 Parametern
2025-05-08 01:24:43,029 - INFO - Speicheranalyse:
2025-05-08 01:24:43,029 - INFO -   Modellgröße (Float32): 6.63 KB
2025-05-08 01:24:43,029 - INFO -   Modellgröße (Int8): 1.66 KB (0.1% des Flash)
2025-05-08 01:24:43,029 - INFO -   Aktivierungsspeicher: 123.23 KB
2025-05-08 01:24:43,029 - INFO -   Gesamter Laufzeitspeicher: 124.89 KB (47.3% des RAM)
2025-05-08 01:24:43,029 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (124.89KB > 100KB)
2025-05-08 01:24:43,029 - INFO - Starte Training von micropizzanet_early_exit mit Early Exit (λ=0.3)...
2025-05-08 01:24:43,890 - INFO - Epoch 1/5:
2025-05-08 01:24:43,890 - INFO -   Train Loss: 1.7842 (Main: 1.7804, Early: 1.7932)
2025-05-08 01:24:43,891 - INFO -   Train Acc: 20.00% (Early Exit: 4.44%)
2025-05-08 01:24:43,891 - INFO -   Val Loss: 1.7919, Val Acc: 0.00%
2025-05-08 01:24:43,891 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:24:43,891 - INFO -   Validierungsverlust verbessert: inf -> 1.7919
2025-05-08 01:24:43,905 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:24:44,293 - INFO - Epoch 2/5:
2025-05-08 01:24:44,294 - INFO -   Train Loss: 1.7480 (Main: 1.7333, Early: 1.7823)
2025-05-08 01:24:44,294 - INFO -   Train Acc: 37.78% (Early Exit: 17.78%)
2025-05-08 01:24:44,295 - INFO -   Val Loss: 1.7852, Val Acc: 0.00%
2025-05-08 01:24:44,295 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:24:44,295 - INFO -   Validierungsverlust verbessert: 1.7919 -> 1.7852
2025-05-08 01:24:44,303 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:24:44,779 - INFO - Epoch 3/5:
2025-05-08 01:24:44,780 - INFO -   Train Loss: 1.6867 (Main: 1.6636, Early: 1.7405)
2025-05-08 01:24:44,780 - INFO -   Train Acc: 35.56% (Early Exit: 26.67%)
2025-05-08 01:24:44,780 - INFO -   Val Loss: 1.7746, Val Acc: 0.00%
2025-05-08 01:24:44,780 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:24:44,780 - INFO -   Validierungsverlust verbessert: 1.7852 -> 1.7746
2025-05-08 01:24:44,789 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:24:45,288 - INFO - Epoch 4/5:
2025-05-08 01:24:45,289 - INFO -   Train Loss: 1.6606 (Main: 1.6361, Early: 1.7176)
2025-05-08 01:24:45,289 - INFO -   Train Acc: 33.33% (Early Exit: 33.33%)
2025-05-08 01:24:45,289 - INFO -   Val Loss: 1.7646, Val Acc: 0.00%
2025-05-08 01:24:45,289 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:24:45,290 - INFO -   Validierungsverlust verbessert: 1.7746 -> 1.7646
2025-05-08 01:24:45,299 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:24:45,708 - INFO - Epoch 5/5:
2025-05-08 01:24:45,709 - INFO -   Train Loss: 1.6416 (Main: 1.6102, Early: 1.7148)
2025-05-08 01:24:45,709 - INFO -   Train Acc: 35.56% (Early Exit: 35.56%)
2025-05-08 01:24:45,709 - INFO -   Val Loss: 1.7593, Val Acc: 0.00%
2025-05-08 01:24:45,709 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:24:45,709 - INFO -   Validierungsverlust verbessert: 1.7646 -> 1.7593
2025-05-08 01:24:45,719 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:24:45,722 - INFO - Beste Modellgewichte aus Epoche 5 wiederhergestellt.
2025-05-08 01:24:45,728 - INFO - Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:25:09,248 - INFO - ================================================================================
2025-05-08 01:25:09,249 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-08 01:25:09,249 - INFO - ================================================================================
2025-05-08 01:25:09,249 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-08 01:25:09,249 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-08 01:25:09,249 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-08 01:25:09,249 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-08 01:25:09,249 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-08 01:25:09,249 - INFO - ================================================================================
2025-05-08 01:25:09,249 - INFO - Analysiere Datensatz...
2025-05-08 01:25:09,250 - INFO - Analysiere Datensatz in data/augmented...
2025-05-08 01:25:09,444 - INFO - Datensatzanalyse abgeschlossen:
2025-05-08 01:25:09,445 - INFO - Gesamtzahl der Bilder: 57
2025-05-08 01:25:09,445 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-08 01:25:09,445 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-08 01:25:09,445 - INFO - RGB-Mittelwerte: [0.4744, 0.3923, 0.3223]
2025-05-08 01:25:09,445 - INFO - RGB-Standardabweichungen: [0.2281, 0.2476, 0.2643]
2025-05-08 01:25:09,446 - INFO - Erstelle DataLoader...
2025-05-08 01:25:09,446 - INFO - Preparing optimized data loaders...
2025-05-08 01:25:09,447 - INFO - Using dataset-specific normalization: mean=[0.4743659  0.39226563 0.32232916], std=[0.22810418 0.24757316 0.26431652]
2025-05-08 01:25:09,452 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-08 01:25:09,452 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-08 01:25:09,452 - INFO - Lade vortrainiertes Modell: models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:25:09,706 - INFO - Evaluiere Early-Exit-Modell mit verschiedenen Konfidenz-Schwellenwerten...
2025-05-08 01:25:10,061 - INFO - Baseline Accuracy (ohne Early Exit): 0.00%
2025-05-08 01:25:10,061 - INFO - Early Exit Branch Accuracy: 16.67%
2025-05-08 01:25:10,371 - INFO - Schwellenwert 0.50:
2025-05-08 01:25:10,371 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:25:10,372 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:10,372 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:25:10,372 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:25:10,560 - INFO - Schwellenwert 0.60:
2025-05-08 01:25:10,560 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:25:10,560 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:10,561 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:25:10,561 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:25:10,747 - INFO - Schwellenwert 0.70:
2025-05-08 01:25:10,748 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:25:10,748 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:10,748 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:25:10,748 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:25:10,937 - INFO - Schwellenwert 0.80:
2025-05-08 01:25:10,937 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:25:10,937 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:10,937 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:25:10,938 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:25:11,121 - INFO - Schwellenwert 0.90:
2025-05-08 01:25:11,122 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:25:11,122 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:11,122 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:25:11,122 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:25:11,316 - INFO - Schwellenwert 0.95:
2025-05-08 01:25:11,317 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:25:11,317 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:11,317 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:25:11,317 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:25:11,497 - INFO - Schwellenwert 0.99:
2025-05-08 01:25:11,498 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:25:11,498 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:11,498 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:25:11,498 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:25:49,965 - INFO - ================================================================================
2025-05-08 01:25:49,965 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-08 01:25:49,965 - INFO - ================================================================================
2025-05-08 01:25:49,965 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-08 01:25:49,965 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-08 01:25:49,965 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-08 01:25:49,965 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-08 01:25:49,965 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-08 01:25:49,966 - INFO - ================================================================================
2025-05-08 01:25:49,966 - INFO - Analysiere Datensatz...
2025-05-08 01:25:49,966 - INFO - Analysiere Datensatz in data/augmented...
2025-05-08 01:25:49,999 - INFO - Datensatzanalyse abgeschlossen:
2025-05-08 01:25:49,999 - INFO - Gesamtzahl der Bilder: 57
2025-05-08 01:25:49,999 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-08 01:25:49,999 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-08 01:25:49,999 - INFO - RGB-Mittelwerte: [0.4778, 0.3953, 0.3275]
2025-05-08 01:25:49,999 - INFO - RGB-Standardabweichungen: [0.2344, 0.2506, 0.2648]
2025-05-08 01:25:49,999 - INFO - Erstelle DataLoader...
2025-05-08 01:25:49,999 - INFO - Preparing optimized data loaders...
2025-05-08 01:25:49,999 - INFO - Using dataset-specific normalization: mean=[0.47780734 0.39531793 0.32752891], std=[0.23439627 0.25060932 0.26482685]
2025-05-08 01:25:50,000 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-08 01:25:50,000 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-08 01:25:50,000 - INFO - Erstelle Early-Exit-Modell...
2025-05-08 01:25:50,002 - INFO - Modell erstellt mit 1,532 Parametern
2025-05-08 01:25:50,004 - INFO - Speicheranalyse:
2025-05-08 01:25:50,004 - INFO -   Modellgröße (Float32): 6.63 KB
2025-05-08 01:25:50,004 - INFO -   Modellgröße (Int8): 1.66 KB (0.1% des Flash)
2025-05-08 01:25:50,004 - INFO -   Aktivierungsspeicher: 123.23 KB
2025-05-08 01:25:50,004 - INFO -   Gesamter Laufzeitspeicher: 124.89 KB (47.3% des RAM)
2025-05-08 01:25:50,004 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (124.89KB > 100KB)
2025-05-08 01:25:50,004 - INFO - Starte Training von micropizzanet_early_exit mit Early Exit (λ=0.3)...
2025-05-08 01:25:50,980 - INFO - Epoch 1/15:
2025-05-08 01:25:50,980 - INFO -   Train Loss: 1.8021 (Main: 1.8025, Early: 1.8013)
2025-05-08 01:25:50,980 - INFO -   Train Acc: 8.89% (Early Exit: 8.89%)
2025-05-08 01:25:50,980 - INFO -   Val Loss: 1.7947, Val Acc: 25.00%
2025-05-08 01:25:50,981 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:50,981 - INFO -   Validierungsverlust verbessert: inf -> 1.7947
2025-05-08 01:25:50,990 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:25:51,498 - INFO - Epoch 2/15:
2025-05-08 01:25:51,498 - INFO -   Train Loss: 1.7892 (Main: 1.7899, Early: 1.7874)
2025-05-08 01:25:51,499 - INFO -   Train Acc: 17.78% (Early Exit: 35.56%)
2025-05-08 01:25:51,499 - INFO -   Val Loss: 1.7945, Val Acc: 25.00%
2025-05-08 01:25:51,499 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:51,499 - INFO -   Validierungsverlust verbessert: 1.7947 -> 1.7945
2025-05-08 01:25:51,514 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:25:52,013 - INFO - Epoch 3/15:
2025-05-08 01:25:52,014 - INFO -   Train Loss: 1.7797 (Main: 1.7773, Early: 1.7854)
2025-05-08 01:25:52,014 - INFO -   Train Acc: 17.78% (Early Exit: 26.67%)
2025-05-08 01:25:52,014 - INFO -   Val Loss: 1.7873, Val Acc: 25.00%
2025-05-08 01:25:52,014 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:52,014 - INFO -   Validierungsverlust verbessert: 1.7945 -> 1.7873
2025-05-08 01:25:52,023 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:25:52,514 - INFO - Epoch 4/15:
2025-05-08 01:25:52,514 - INFO -   Train Loss: 1.7365 (Main: 1.7229, Early: 1.7682)
2025-05-08 01:25:52,514 - INFO -   Train Acc: 28.89% (Early Exit: 20.00%)
2025-05-08 01:25:52,514 - INFO -   Val Loss: 1.7758, Val Acc: 25.00%
2025-05-08 01:25:52,515 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:52,515 - INFO -   Validierungsverlust verbessert: 1.7873 -> 1.7758
2025-05-08 01:25:52,530 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:25:52,993 - INFO - Epoch 5/15:
2025-05-08 01:25:52,993 - INFO -   Train Loss: 1.6996 (Main: 1.6852, Early: 1.7332)
2025-05-08 01:25:52,994 - INFO -   Train Acc: 26.67% (Early Exit: 20.00%)
2025-05-08 01:25:52,994 - INFO -   Val Loss: 1.7494, Val Acc: 0.00%
2025-05-08 01:25:52,994 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:52,994 - INFO -   Validierungsverlust verbessert: 1.7758 -> 1.7494
2025-05-08 01:25:53,008 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:25:53,396 - INFO - Epoch 6/15:
2025-05-08 01:25:53,397 - INFO -   Train Loss: 1.6392 (Main: 1.6092, Early: 1.7094)
2025-05-08 01:25:53,397 - INFO -   Train Acc: 28.89% (Early Exit: 15.56%)
2025-05-08 01:25:53,397 - INFO -   Val Loss: 1.7243, Val Acc: 0.00%
2025-05-08 01:25:53,397 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:53,397 - INFO -   Validierungsverlust verbessert: 1.7494 -> 1.7243
2025-05-08 01:25:53,406 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:25:53,915 - INFO - Epoch 7/15:
2025-05-08 01:25:53,916 - INFO -   Train Loss: 1.5884 (Main: 1.5523, Early: 1.6725)
2025-05-08 01:25:53,917 - INFO -   Train Acc: 26.67% (Early Exit: 15.56%)
2025-05-08 01:25:53,917 - INFO -   Val Loss: 1.7054, Val Acc: 0.00%
2025-05-08 01:25:53,917 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:53,917 - INFO -   Validierungsverlust verbessert: 1.7243 -> 1.7054
2025-05-08 01:25:53,925 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:25:54,420 - INFO - Epoch 8/15:
2025-05-08 01:25:54,421 - INFO -   Train Loss: 1.5641 (Main: 1.5305, Early: 1.6425)
2025-05-08 01:25:54,421 - INFO -   Train Acc: 33.33% (Early Exit: 28.89%)
2025-05-08 01:25:54,422 - INFO -   Val Loss: 1.6923, Val Acc: 0.00%
2025-05-08 01:25:54,422 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:54,422 - INFO -   Validierungsverlust verbessert: 1.7054 -> 1.6923
2025-05-08 01:25:54,432 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:25:54,921 - INFO - Epoch 9/15:
2025-05-08 01:25:54,921 - INFO -   Train Loss: 1.5590 (Main: 1.5298, Early: 1.6272)
2025-05-08 01:25:54,922 - INFO -   Train Acc: 35.56% (Early Exit: 24.44%)
2025-05-08 01:25:54,922 - INFO -   Val Loss: 1.6815, Val Acc: 0.00%
2025-05-08 01:25:54,922 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:54,922 - INFO -   Validierungsverlust verbessert: 1.6923 -> 1.6815
2025-05-08 01:25:54,932 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:25:55,429 - INFO - Epoch 10/15:
2025-05-08 01:25:55,430 - INFO -   Train Loss: 1.5274 (Main: 1.4920, Early: 1.6100)
2025-05-08 01:25:55,431 - INFO -   Train Acc: 26.67% (Early Exit: 33.33%)
2025-05-08 01:25:55,431 - INFO -   Val Loss: 1.6714, Val Acc: 0.00%
2025-05-08 01:25:55,431 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:55,431 - INFO -   Validierungsverlust verbessert: 1.6815 -> 1.6714
2025-05-08 01:25:55,439 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:25:55,926 - INFO - Epoch 11/15:
2025-05-08 01:25:55,927 - INFO -   Train Loss: 1.5071 (Main: 1.4715, Early: 1.5901)
2025-05-08 01:25:55,928 - INFO -   Train Acc: 35.56% (Early Exit: 28.89%)
2025-05-08 01:25:55,928 - INFO -   Val Loss: 1.6635, Val Acc: 0.00%
2025-05-08 01:25:55,929 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:55,929 - INFO -   Validierungsverlust verbessert: 1.6714 -> 1.6635
2025-05-08 01:25:55,941 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:25:56,425 - INFO - Epoch 12/15:
2025-05-08 01:25:56,426 - INFO -   Train Loss: 1.5129 (Main: 1.4805, Early: 1.5883)
2025-05-08 01:25:56,426 - INFO -   Train Acc: 31.11% (Early Exit: 28.89%)
2025-05-08 01:25:56,426 - INFO -   Val Loss: 1.6647, Val Acc: 0.00%
2025-05-08 01:25:56,426 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:56,426 - INFO -   Keine Verbesserung. Early Stopping Counter: 1/10
2025-05-08 01:25:56,923 - INFO - Epoch 13/15:
2025-05-08 01:25:56,924 - INFO -   Train Loss: 1.4796 (Main: 1.4417, Early: 1.5680)
2025-05-08 01:25:56,924 - INFO -   Train Acc: 31.11% (Early Exit: 31.11%)
2025-05-08 01:25:56,924 - INFO -   Val Loss: 1.6648, Val Acc: 0.00%
2025-05-08 01:25:56,924 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:56,924 - INFO -   Keine Verbesserung. Early Stopping Counter: 2/10
2025-05-08 01:25:57,386 - INFO - Epoch 14/15:
2025-05-08 01:25:57,387 - INFO -   Train Loss: 1.4782 (Main: 1.4415, Early: 1.5640)
2025-05-08 01:25:57,387 - INFO -   Train Acc: 33.33% (Early Exit: 35.56%)
2025-05-08 01:25:57,387 - INFO -   Val Loss: 1.6630, Val Acc: 0.00%
2025-05-08 01:25:57,387 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:57,387 - INFO -   Validierungsverlust verbessert: 1.6635 -> 1.6630
2025-05-08 01:25:57,396 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:25:57,922 - INFO - Epoch 15/15:
2025-05-08 01:25:57,922 - INFO -   Train Loss: 1.4906 (Main: 1.4510, Early: 1.5831)
2025-05-08 01:25:57,923 - INFO -   Train Acc: 42.22% (Early Exit: 28.89%)
2025-05-08 01:25:57,923 - INFO -   Val Loss: 1.6632, Val Acc: 0.00%
2025-05-08 01:25:57,923 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:57,923 - INFO -   Keine Verbesserung. Early Stopping Counter: 1/10
2025-05-08 01:25:57,926 - INFO - Beste Modellgewichte aus Epoche 14 wiederhergestellt.
2025-05-08 01:25:57,933 - INFO - Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:25:57,934 - INFO - Evaluiere Early-Exit-Modell mit verschiedenen Konfidenz-Schwellenwerten...
2025-05-08 01:25:58,142 - INFO - Baseline Accuracy (ohne Early Exit): 0.00%
2025-05-08 01:25:58,142 - INFO - Early Exit Branch Accuracy: 0.00%
2025-05-08 01:25:58,446 - INFO - Schwellenwert 0.50:
2025-05-08 01:25:58,447 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:25:58,447 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:58,447 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:25:58,447 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:25:58,666 - INFO - Schwellenwert 0.60:
2025-05-08 01:25:58,667 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:25:58,667 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:58,667 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:25:58,667 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:25:58,834 - INFO - Schwellenwert 0.70:
2025-05-08 01:25:58,835 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:25:58,835 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:58,835 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:25:58,835 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:25:59,056 - INFO - Schwellenwert 0.80:
2025-05-08 01:25:59,056 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:25:59,056 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:59,056 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:25:59,057 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:25:59,267 - INFO - Schwellenwert 0.90:
2025-05-08 01:25:59,269 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:25:59,269 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:59,269 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:25:59,269 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:25:59,478 - INFO - Schwellenwert 0.95:
2025-05-08 01:25:59,478 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:25:59,478 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:59,478 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:25:59,479 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:25:59,696 - INFO - Schwellenwert 0.99:
2025-05-08 01:25:59,697 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:25:59,697 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:25:59,697 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:25:59,697 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:31:37,834 - INFO - ================================================================================
2025-05-08 01:31:37,834 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-08 01:31:37,834 - INFO - ================================================================================
2025-05-08 01:31:37,834 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-08 01:31:37,834 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-08 01:31:37,834 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-08 01:31:37,834 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-08 01:31:37,834 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-08 01:31:37,834 - INFO - ================================================================================
2025-05-08 01:31:37,834 - INFO - Analysiere Datensatz...
2025-05-08 01:31:37,835 - INFO - Analysiere Datensatz in data/augmented...
2025-05-08 01:31:37,867 - INFO - Datensatzanalyse abgeschlossen:
2025-05-08 01:31:37,867 - INFO - Gesamtzahl der Bilder: 57
2025-05-08 01:31:37,867 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-08 01:31:37,867 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-08 01:31:37,867 - INFO - RGB-Mittelwerte: [0.4849, 0.4020, 0.3324]
2025-05-08 01:31:37,867 - INFO - RGB-Standardabweichungen: [0.2335, 0.2522, 0.2667]
2025-05-08 01:31:37,867 - INFO - Erstelle DataLoader...
2025-05-08 01:31:37,867 - INFO - Preparing optimized data loaders...
2025-05-08 01:31:37,868 - INFO - Using dataset-specific normalization: mean=[0.48487373 0.4019733  0.3323595 ], std=[0.23346732 0.25224087 0.26665817]
2025-05-08 01:31:37,869 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-08 01:31:37,869 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-08 01:31:37,869 - INFO - Erstelle Early-Exit-Modell...
2025-05-08 01:31:37,870 - INFO - Modell erstellt mit 1,532 Parametern
2025-05-08 01:31:37,873 - INFO - Speicheranalyse:
2025-05-08 01:31:37,873 - INFO -   Modellgröße (Float32): 6.63 KB
2025-05-08 01:31:37,873 - INFO -   Modellgröße (Int8): 1.66 KB (0.1% des Flash)
2025-05-08 01:31:37,873 - INFO -   Aktivierungsspeicher: 123.23 KB
2025-05-08 01:31:37,873 - INFO -   Gesamter Laufzeitspeicher: 124.89 KB (47.3% des RAM)
2025-05-08 01:31:37,873 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (124.89KB > 100KB)
2025-05-08 01:31:37,873 - INFO - Starte Training von micropizzanet_early_exit mit Early Exit (λ=0.3)...
2025-05-08 01:31:38,998 - INFO - Epoch 1/3:
2025-05-08 01:31:38,999 - INFO -   Train Loss: 1.7795 (Main: 1.7743, Early: 1.7917)
2025-05-08 01:31:38,999 - INFO -   Train Acc: 13.33% (Early Exit: 22.22%)
2025-05-08 01:31:38,999 - INFO -   Val Loss: 1.7849, Val Acc: 8.33%
2025-05-08 01:31:38,999 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:31:38,999 - INFO -   Validierungsverlust verbessert: inf -> 1.7849
2025-05-08 01:31:39,009 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:31:39,374 - INFO - Epoch 2/3:
2025-05-08 01:31:39,375 - INFO -   Train Loss: 1.7401 (Main: 1.7275, Early: 1.7694)
2025-05-08 01:31:39,375 - INFO -   Train Acc: 26.67% (Early Exit: 15.56%)
2025-05-08 01:31:39,375 - INFO -   Val Loss: 1.7764, Val Acc: 8.33%
2025-05-08 01:31:39,375 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:31:39,376 - INFO -   Validierungsverlust verbessert: 1.7849 -> 1.7764
2025-05-08 01:31:39,384 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:31:39,866 - INFO - Epoch 3/3:
2025-05-08 01:31:39,867 - INFO -   Train Loss: 1.6951 (Main: 1.6753, Early: 1.7413)
2025-05-08 01:31:39,867 - INFO -   Train Acc: 31.11% (Early Exit: 31.11%)
2025-05-08 01:31:39,867 - INFO -   Val Loss: 1.7694, Val Acc: 8.33%
2025-05-08 01:31:39,867 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:31:39,867 - INFO -   Validierungsverlust verbessert: 1.7764 -> 1.7694
2025-05-08 01:31:39,877 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:31:39,881 - INFO - Beste Modellgewichte aus Epoche 3 wiederhergestellt.
2025-05-08 01:31:39,888 - INFO - Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:32:02,824 - INFO - ================================================================================
2025-05-08 01:32:02,824 - INFO - RP2040 PIZZA-ERKENNUNGSSYSTEM - DETAILLIERTE KONFIGURATION
2025-05-08 01:32:02,824 - INFO - ================================================================================
2025-05-08 01:32:02,824 - INFO - Hardware: RP2040 - 133MHz, 264KB RAM, 2048KB Flash
2025-05-08 01:32:02,824 - INFO - Kamera: OV2640 - 320x240, 7 FPS
2025-05-08 01:32:02,824 - INFO - Stromversorgung: CR123A - 1500mAh, 8.33h aktiv, 3000.00h standby
2025-05-08 01:32:02,824 - INFO - Modellparameter: 48x48 Eingabegröße, 8-Bit Quantisierung
2025-05-08 01:32:02,824 - INFO - Speicherbeschränkungen: Max. 180KB Modellgröße, 100KB Laufzeit-RAM
2025-05-08 01:32:02,824 - INFO - ================================================================================
2025-05-08 01:32:02,824 - INFO - Analysiere Datensatz...
2025-05-08 01:32:02,824 - INFO - Analysiere Datensatz in data/augmented...
2025-05-08 01:32:02,856 - INFO - Datensatzanalyse abgeschlossen:
2025-05-08 01:32:02,857 - INFO - Gesamtzahl der Bilder: 57
2025-05-08 01:32:02,857 - INFO - Klassenverteilung: {'progression': 0, 'mixed': 7, 'basic': 29, 'segment': 0, 'combined': 17, 'burnt': 4}
2025-05-08 01:32:02,857 - INFO - Durchschnittliche Bildgröße: 224.0 x 224.0
2025-05-08 01:32:02,857 - INFO - RGB-Mittelwerte: [0.4843, 0.4016, 0.3333]
2025-05-08 01:32:02,857 - INFO - RGB-Standardabweichungen: [0.2407, 0.2570, 0.2707]
2025-05-08 01:32:02,857 - INFO - Erstelle DataLoader...
2025-05-08 01:32:02,857 - INFO - Preparing optimized data loaders...
2025-05-08 01:32:02,857 - INFO - Using dataset-specific normalization: mean=[0.48432587 0.40160235 0.33330707], std=[0.24074653 0.25698288 0.27067237]
2025-05-08 01:32:02,858 - INFO - Data loaders created: 45 training images, 12 validation images
2025-05-08 01:32:02,858 - INFO - Classes: ['basic', 'burnt', 'combined', 'mixed', 'progression', 'segment']
2025-05-08 01:32:02,858 - INFO - Erstelle Early-Exit-Modell...
2025-05-08 01:32:02,859 - INFO - Modell erstellt mit 1,532 Parametern
2025-05-08 01:32:02,862 - INFO - Speicheranalyse:
2025-05-08 01:32:02,862 - INFO -   Modellgröße (Float32): 6.63 KB
2025-05-08 01:32:02,862 - INFO -   Modellgröße (Int8): 1.66 KB (0.1% des Flash)
2025-05-08 01:32:02,862 - INFO -   Aktivierungsspeicher: 123.23 KB
2025-05-08 01:32:02,862 - INFO -   Gesamter Laufzeitspeicher: 124.89 KB (47.3% des RAM)
2025-05-08 01:32:02,862 - WARNING - Warnung: Laufzeitspeicher überschreitet RAM-Beschränkung (124.89KB > 100KB)
2025-05-08 01:32:02,862 - INFO - Starte Training von micropizzanet_early_exit mit Early Exit (λ=0.3)...
2025-05-08 01:32:04,031 - INFO - Epoch 1/3:
2025-05-08 01:32:04,031 - INFO -   Train Loss: 1.8013 (Main: 1.8083, Early: 1.7852)
2025-05-08 01:32:04,031 - INFO -   Train Acc: 15.56% (Early Exit: 17.78%)
2025-05-08 01:32:04,031 - INFO -   Val Loss: 1.7939, Val Acc: 0.00%
2025-05-08 01:32:04,031 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:32:04,031 - INFO -   Validierungsverlust verbessert: inf -> 1.7939
2025-05-08 01:32:04,041 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:32:04,550 - INFO - Epoch 2/3:
2025-05-08 01:32:04,551 - INFO -   Train Loss: 1.7484 (Main: 1.7469, Early: 1.7520)
2025-05-08 01:32:04,551 - INFO -   Train Acc: 24.44% (Early Exit: 22.22%)
2025-05-08 01:32:04,551 - INFO -   Val Loss: 1.7843, Val Acc: 0.00%
2025-05-08 01:32:04,551 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:32:04,551 - INFO -   Validierungsverlust verbessert: 1.7939 -> 1.7843
2025-05-08 01:32:04,561 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:32:05,017 - INFO - Epoch 3/3:
2025-05-08 01:32:05,018 - INFO -   Train Loss: 1.7164 (Main: 1.7061, Early: 1.7402)
2025-05-08 01:32:05,018 - INFO -   Train Acc: 33.33% (Early Exit: 33.33%)
2025-05-08 01:32:05,018 - INFO -   Val Loss: 1.7793, Val Acc: 0.00%
2025-05-08 01:32:05,018 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:32:05,018 - INFO -   Validierungsverlust verbessert: 1.7843 -> 1.7793
2025-05-08 01:32:05,028 - INFO -   Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:32:05,031 - INFO - Beste Modellgewichte aus Epoche 3 wiederhergestellt.
2025-05-08 01:32:05,037 - INFO - Modell gespeichert: /home/emilio/Documents/ai/pizza/models_optimized/micropizzanet_early_exit.pth
2025-05-08 01:32:05,038 - INFO - Evaluiere Early-Exit-Modell mit verschiedenen Konfidenz-Schwellenwerten...
2025-05-08 01:32:05,221 - INFO - Baseline Accuracy (ohne Early Exit): 0.00%
2025-05-08 01:32:05,221 - INFO - Early Exit Branch Accuracy: 0.00%
2025-05-08 01:32:05,554 - INFO - Schwellenwert 0.50:
2025-05-08 01:32:05,555 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:32:05,555 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:32:05,555 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:32:05,555 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:32:05,762 - INFO - Schwellenwert 0.60:
2025-05-08 01:32:05,762 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:32:05,763 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:32:05,763 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:32:05,763 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:32:05,986 - INFO - Schwellenwert 0.70:
2025-05-08 01:32:05,987 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:32:05,987 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:32:05,987 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:32:05,987 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:32:06,199 - INFO - Schwellenwert 0.80:
2025-05-08 01:32:06,199 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:32:06,199 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:32:06,200 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:32:06,200 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:32:06,419 - INFO - Schwellenwert 0.90:
2025-05-08 01:32:06,419 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:32:06,420 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:32:06,420 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:32:06,420 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:32:06,635 - INFO - Schwellenwert 0.95:
2025-05-08 01:32:06,635 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:32:06,635 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:32:06,635 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:32:06,636 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:32:06,857 - INFO - Schwellenwert 0.99:
2025-05-08 01:32:06,858 - INFO -   Accuracy: 0.00% (vs. Baseline: 0.00%, Diff: 0.00%)
2025-05-08 01:32:06,858 - INFO -   Early Exit Rate: 0.00%
2025-05-08 01:32:06,858 - INFO -   Early Exit Accuracy: 0.00%
2025-05-08 01:32:06,858 - INFO -   Geschätzte Zeitersparnis: ~0.0%
2025-05-08 01:32:08,674 - INFO - Evaluierungsbericht erstellt: /home/emilio/Documents/ai/pizza/models_optimized/visualizations/early_exit/early_exit_report.html
2025-05-08 01:32:08,674 - INFO - Evaluierung und Visualisierung abgeschlossen. Bericht: /home/emilio/Documents/ai/pizza/models_optimized/visualizations/early_exit/early_exit_report.html
